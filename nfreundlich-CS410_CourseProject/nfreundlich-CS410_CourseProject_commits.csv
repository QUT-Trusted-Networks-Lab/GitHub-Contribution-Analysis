Hash,Commit Message,Author Name,Author Email,Committor Name,Committor Email,Author Date,Author Timezone,Committor Date,Committor Timezone,in_main_branch,merge,modified_files,parents,deletions,insertions,lines,files,dmm_unit_size,dmm_unit_complexity,dmm_unit_interfacing
f42c6c92e530cf0e08e764000384033f212269fb,Initial commit,nfreundlich,norbiein@gmail.com,GitHub,noreply@github.com,2018-10-08 23:22:00+02:00,-7200,2018-10-08 23:22:00+02:00,-7200,True,False,['README.md'],[],0,2,2,1,,,
fceb99fd6e4fd2e732a387c8d257ed78192d441b,Create dummy_comments_nfr.py,nfreundlich,norbiein@gmail.com,GitHub,noreply@github.com,2018-10-08 23:33:37+02:00,-7200,2018-10-08 23:33:37+02:00,-7200,True,False,['dummy_comments_nfr.py'],['f42c6c92e530cf0e08e764000384033f212269fb'],0,9,9,1,,,
3b65a9b4f0cffff5076dcbd36163a16f84032099,Update README.md,nfreundlich,norbiein@gmail.com,GitHub,noreply@github.com,2018-10-18 13:49:03+02:00,-7200,2018-10-18 13:49:03+02:00,-7200,True,False,['README.md'],['fceb99fd6e4fd2e732a387c8d257ed78192d441b'],1,1,2,1,,,
2a353b67e4016befa46155be33013dc5691baac1,Created annotated data folder and readme file,Norbert Freundlich,nofreund@cisco.com,Norbert Freundlich,nofreund@cisco.com,2018-10-18 14:11:55+02:00,-7200,2018-10-18 14:11:55+02:00,-7200,True,False,['readme.md'],['3b65a9b4f0cffff5076dcbd36163a16f84032099'],0,3,3,1,,,
8bfeaec1e56129247bb968852c046a772c7d86d8,H - test commit,hwilder3,hwilder3@illinois.edu,hwilder3,hwilder3@illinois.edu,2018-10-21 19:43:54-04:00,14400,2018-10-21 19:43:54-04:00,14400,True,False,['README.md'],['0033a3cd11cedf54024ad31e3b08d6271d3bda90'],0,2,2,1,,,
63874e075df407e3ffed755785eb6a4b172cd4e3,H test commit 2,hwilder3,hwilder3@illinois.edu,hwilder3,hwilder3@illinois.edu,2018-10-21 19:49:15-04:00,14400,2018-10-21 19:49:15-04:00,14400,True,False,['README.md'],['8bfeaec1e56129247bb968852c046a772c7d86d8'],1,1,2,1,,,
8f9e0e4f52f6746dfb083c4744707ec64b73e2be,Still trying to figure out how to commit.,hewilder,hwilder3@illinois.edu,GitHub,noreply@github.com,2018-10-21 19:59:38-04:00,14400,2018-10-21 19:59:38-04:00,14400,True,False,['README.md'],['63874e075df407e3ffed755785eb6a4b172cd4e3'],1,1,2,1,,,
e7cfb742fc1f7777b56016dfdf4225e6dcbafddd,Testing commit from local,hwilder3,hwilder3@illinois.edu,hwilder3,hwilder3@illinois.edu,2018-10-21 20:01:46-04:00,14400,2018-10-21 20:01:46-04:00,14400,True,False,['README.md'],['8f9e0e4f52f6746dfb083c4744707ec64b73e2be'],0,1,1,1,,,
e263b8e080cd539233f12c2b0377b57ff7f35132,Updated project structure and .gitignore,Norbert Freundlich,nofreund@cisco.com,Norbert Freundlich,nofreund@cisco.com,2018-10-23 11:43:40+02:00,-7200,2018-10-23 11:43:40+02:00,-7200,True,False,"['.gitignore', 'readme.md', 'readme.md', '__init__.py', 'core.py', 'helpers.py', '__init__.py', 'context.py', 'test_advanced.py', 'test_basic.py']",['2a353b67e4016befa46155be33013dc5691baac1'],0,142,142,10,1.0,1.0,1.0
7ee9762b1c007212ce1b22970b74bbc66863cc57,Updated project structure and .gitignore (#4),nfreundlich,norbiein@gmail.com,hewilder,hewample@mtu.edu,2018-10-24 12:31:37+02:00,-7200,2018-10-24 06:31:37-04:00,14400,True,False,"['.gitignore', 'readme.md', 'readme.md', '__init__.py', 'core.py', 'helpers.py', '__init__.py', 'context.py', 'test_advanced.py', 'test_basic.py']",['0033a3cd11cedf54024ad31e3b08d6271d3bda90'],0,142,142,10,1.0,1.0,1.0
1c68e155e9a26720c36f33239338a4880189be04,"Testing pull request to dev (#5)

* H - test commit

* H test commit 2

* Still trying to figure out how to commit.

* Testing commit from local",hewilder,hewample@mtu.edu,nfreundlich,norbiein@gmail.com,2018-10-24 09:25:51-04:00,14400,2018-10-24 15:25:51+02:00,-7200,True,False,['README.md'],['7ee9762b1c007212ce1b22970b74bbc66863cc57'],0,3,3,1,,,
f3243384df0dfd1ece00075e8c872d6a13e30046,Testing commit from PyCharm,hewilder,hwilder3@illinois.edu,hwilder3,hwilder3@illinois.edu,2018-10-29 20:29:57-04:00,14400,2018-10-29 20:29:57-04:00,14400,True,False,['README.md'],['2785d2c951a704a69da58d68557131a074831943'],2,1,3,1,,,
68f4f1d4fbe86b2d2cce9f82048129491d57dab8,Project code tests - Spacy (finally) successfully loaded,hewilder,hwilder3@illinois.edu,hwilder3,hwilder3@illinois.edu,2018-10-29 22:54:46-04:00,14400,2018-10-29 22:54:46-04:00,14400,True,False,['readFiles_test.py'],['f3243384df0dfd1ece00075e8c872d6a13e30046'],0,15,15,1,,,
d4de5646a0f7f910349d863643d8c1e166218887,Project code tests - sentence tokenizing and some basic counting,hewilder,hwilder3@illinois.edu,hwilder3,hwilder3@illinois.edu,2018-10-30 22:03:46-04:00,14400,2018-10-30 22:03:46-04:00,14400,True,False,['readFiles_test.py'],['f3243384df0dfd1ece00075e8c872d6a13e30046'],0,38,38,1,,,
a51438b898128c0ea4c7ed4eea20ef5cb2999fa0,Working counts on sample document set 1,hewilder,hwilder3@illinois.edu,hwilder3,hwilder3@illinois.edu,2018-11-01 20:58:51-04:00,14400,2018-11-01 20:58:51-04:00,14400,True,False,['readFiles_test.py'],['18a9ef904c0b2b00547e33f4dac3cd4714cae66f'],1,42,43,1,,,
cb9e9e07cf03fb4740ec42811797d2efaf2693f6,"Adding sample data and sample background/topic models and sentence counts for testing, will clean up code and add unit tests, but seems to be working for the moment.",hewilder,hwilder3@illinois.edu,hwilder3,hwilder3@illinois.edu,2018-11-03 21:29:01-04:00,14400,2018-11-03 21:29:01-04:00,14400,True,False,['readFiles_test.py'],['a51438b898128c0ea4c7ed4eea20ef5cb2999fa0'],1,88,89,1,,,
b6b5fc7929a1c937fe66df4148a6bb890b1b041e,"Adding sample data and sample background/topic models and sentence counts for testing, will clean up code and add unit tests, but seems to be working for the moment.",hewilder,hwilder3@illinois.edu,hwilder3,hwilder3@illinois.edu,2018-11-03 21:29:02-04:00,14400,2018-11-03 21:29:02-04:00,14400,True,False,"['docCounts.data', 'model_background.data', 'model_topic.data', 'sample_dataset_1_feature_mapping.csv', 'sample_dataset_1_features.csv', 'sample_dataset_1_text.csv']",['18a9ef904c0b2b00547e33f4dac3cd4714cae66f'],0,49,49,6,,,
9fb8f15ee04cb86be6d7c1d2decbe251704e1f9d,Trying to get Pycharm and GitHub to play nice.,hewilder,hwilder3@illinois.edu,hwilder3,hwilder3@illinois.edu,2018-11-03 21:42:14-04:00,14400,2018-11-03 21:42:14-04:00,14400,True,False,['readFiles_test.py'],['c568d682d8b348c843e3cdaac1999a0b881a46ae'],0,1,1,1,,,
43e5c32d847561e91b2b7408331eac2ad0b50a2c,"Topic model building converted to function format and documented (now callable with three required data frames)

Still need to add test cases and separate this code off into a permanent file",hewilder,hwilder3@illinois.edu,hwilder3,hwilder3@illinois.edu,2018-11-04 20:50:20-05:00,18000,2018-11-04 20:50:20-05:00,18000,True,False,"['readFiles_test.py', 'test_basic.py']",['9fb8f15ee04cb86be6d7c1d2decbe251704e1f9d'],21,140,161,2,0.08064516129032258,0.08064516129032258,0.08064516129032258
05c485f5d77f3da4f82a2b5ba66f77bffea47c0a,Rewrote Santu_s original e-step and added tests.,Norbert Freundlich,nofreund@cisco.com,Norbert Freundlich,nofreund@cisco.com,2018-11-05 12:08:33+01:00,-3600,2018-11-05 12:08:33+01:00,-3600,True,False,"['README.md', '__init__.py', 'em.py', 'BackgroundProbability.npy', 'HP.npy', 'HPB.npy', 'HPB_updated.npy', 'HP_updated.npy', 'MY_HPB_updated.npy', 'MY_HP_Updated.npy', 'PI.npy', 'Reviews.npy', 'TopicModel.npy', 'test_advanced.py']",['d7f9f79dc87fcdd6c410297bc88d1fb95f22cd8c'],2,120,122,14,1.0,0.7758620689655172,1.0
5489b886090261b3dd6a9479fb7feaf5035e632c,Vectorized E-Step. HP compute still to be validated. Chain to be validated.,Norbert Freundlich,nofreund@cisco.com,Norbert Freundlich,nofreund@cisco.com,2018-11-06 14:59:27+01:00,-3600,2018-11-06 14:59:27+01:00,-3600,True,False,['em.py'],['05c485f5d77f3da4f82a2b5ba66f77bffea47c0a'],1,89,90,1,0.0,1.0,1.0
e0ebdd240c080c70084c78a1bd9b94533c43f292,"Hannah (#6)

* H - test commit

* H test commit 2

* Still trying to figure out how to commit.

* Testing commit from local

* Testing commit from PyCharm

* Project code tests - Spacy (finally) successfully loaded

* Project code tests - sentence tokenizing and some basic counting

* Working counts on sample document set 1

* Adding sample data and sample background/topic models and sentence counts for testing, will clean up code and add unit tests, but seems to be working for the moment.

* Adding sample data and sample background/topic models and sentence counts for testing, will clean up code and add unit tests, but seems to be working for the moment.

* Trying to get Pycharm and GitHub to play nice.

* Topic model building converted to function format and documented (now callable with three required data frames)

Still need to add test cases and separate this code off into a permanent file",hewilder,hewample@mtu.edu,GitHub,noreply@github.com,2018-11-07 08:42:31-05:00,18000,2018-11-07 08:42:31-05:00,18000,True,False,"['README.md', 'docCounts.data', 'model_background.data', 'model_topic.data', 'sample_dataset_1_feature_mapping.csv', 'sample_dataset_1_features.csv', 'sample_dataset_1_text.csv', 'readFiles_test.py', 'test_basic.py']",['1c68e155e9a26720c36f33239338a4880189be04'],2,336,338,9,0.08064516129032258,0.08064516129032258,0.08064516129032258
502e9098ba7af6869160342cc96a6ff4ec149006,Transform existing data in matrices. Commit before major update of vectorised e-step,Norbert Freundlich,nofreund@cisco.com,Norbert Freundlich,nofreund@cisco.com,2018-11-07 15:11:03+01:00,-3600,2018-11-07 15:11:03+01:00,-3600,True,False,['em.py'],['5489b886090261b3dd6a9479fb7feaf5035e632c'],20,127,147,1,0.0,0.125,1.0
4e85ae8c82c7a92ee57db0e01670a12789ccbfaa,"Problem with huge matrices. Freeze this as is, then start the fix.",Norbert Freundlich,nofreund@cisco.com,Norbert Freundlich,nofreund@cisco.com,2018-11-07 16:00:49+01:00,-3600,2018-11-07 16:00:49+01:00,-3600,True,False,"['em.py', 'MY_HP_Updated.npy']",['502e9098ba7af6869160342cc96a6ff4ec149006'],12,24,36,2,0.7777777777777778,0.7777777777777778,1.0
7c1cdc94747a85372c36968d405bcad982a36923,E-Step sparse matrix implementation for one sentence.,Norbert Freundlich,nofreund@cisco.com,Norbert Freundlich,nofreund@cisco.com,2018-11-08 15:05:27+01:00,-3600,2018-11-08 15:05:27+01:00,-3600,True,False,['em.py'],['4e85ae8c82c7a92ee57db0e01670a12789ccbfaa'],8,54,62,1,0.0,0.975,1.0
9481ed4bb424fdec1dbf2959149b358069c69e7a,Created class structure for EM. Migrated EM_E Original to em_original.,Norbert Freundlich,nofreund@cisco.com,Norbert Freundlich,nofreund@cisco.com,2018-11-08 17:13:24+01:00,-3600,2018-11-08 17:13:24+01:00,-3600,True,False,"['__init__.py', 'em.py', 'em_original.py', 'em_vector.py', 'test_advanced.py']",['7c1cdc94747a85372c36968d405bcad982a36923'],73,176,249,5,0.9714285714285714,0.0,1.0
cec600f5de878ac9980d88e0dff2a0a4fdf84beb,Created class structure for EM. Migrated EM_E Original to em_original.,Norbert Freundlich,nofreund@cisco.com,Norbert Freundlich,nofreund@cisco.com,2018-11-08 17:14:46+01:00,-3600,2018-11-08 17:14:46+01:00,-3600,True,False,"['dummy_comments_nfr.py', 'MY_HPB_updated.npy', 'MY_HP_Updated.npy']",['9481ed4bb424fdec1dbf2959149b358069c69e7a'],9,0,9,3,,,
013f0a9341f22ae7a3ef95f48ca567e9837c9763,Created class structure for EM. Migrated EM_E Original to em_original. Added em_base,Norbert Freundlich,nofreund@cisco.com,Norbert Freundlich,nofreund@cisco.com,2018-11-08 17:15:20+01:00,-3600,2018-11-08 17:15:20+01:00,-3600,True,False,['em_base.py'],['cec600f5de878ac9980d88e0dff2a0a4fdf84beb'],0,73,73,1,0.5952380952380952,1.0,1.0
c608ef0de9bebf633d0bf77b98b25391d59ce0e7,Updated methods structure for em_vector. Updated test_advanced for em_original. Minor cleaning.,Norbert Freundlich,nofreund@cisco.com,Norbert Freundlich,nofreund@cisco.com,2018-11-08 17:22:39+01:00,-3600,2018-11-08 17:22:39+01:00,-3600,True,False,"['em_base.py', 'em_vector.py', 'test_advanced.py']",['013f0a9341f22ae7a3ef95f48ca567e9837c9763'],15,29,44,3,1.0,1.0,1.0
a58124aaeeea78fb46ff2f5f668aa31ba6feb7ab,Implement em_vector e_step.,Norbert Freundlich,nofreund@cisco.com,Norbert Freundlich,nofreund@cisco.com,2018-11-08 21:56:47+01:00,-3600,2018-11-08 21:56:47+01:00,-3600,True,False,"['em.py', 'em_base.py', 'em_vector.py']",['c608ef0de9bebf633d0bf77b98b25391d59ce0e7'],17,192,209,3,0.29347826086956524,0.31521739130434784,1.0
8dfb8a3f7851cb4d0d11ba72db6fe2ea2d2198b9,Update .gitignore with .idea,Norbert Freundlich,nofreund@cisco.com,Norbert Freundlich,nofreund@cisco.com,2018-11-08 21:58:40+01:00,-3600,2018-11-08 21:58:40+01:00,-3600,True,False,['.gitignore'],['a58124aaeeea78fb46ff2f5f668aa31ba6feb7ab'],0,1,1,1,,,
113c9884b8fcfe14e44954f77400287871ed2963,Updated real tests for em_vector. First review OK in e_step.,Norbert Freundlich,nofreund@cisco.com,Norbert Freundlich,nofreund@cisco.com,2018-11-08 22:55:36+01:00,-3600,2018-11-08 22:55:36+01:00,-3600,True,False,"['__init__.py', 'em_base.py', 'em_original.py', 'em_vector.py', 'test_advanced.py']",['8dfb8a3f7851cb4d0d11ba72db6fe2ea2d2198b9'],39,54,93,5,0.0,0.0,1.0
7a286c7cb2878cfd447b8b79c43b1284b1b19da9,"Added two functions:
format_feature_list - takes in a nested list and returns a data frame with ids for each feature

read_annotated_data - reads in Santu's annotated input files, returns DataFrames with the annotation information as well as a somewhat cleaned set of section text, including ids - can be passed into the build_models function",hwilder3,hwilder3@illinois.edu,hwilder3,hwilder3@illinois.edu,2018-11-08 23:06:02-05:00,18000,2018-11-08 23:06:02-05:00,18000,True,False,['readFiles_test.py'],['43e5c32d847561e91b2b7408331eac2ad0b50a2c'],8,168,176,1,0.0,0.0,1.0
5d75bb41556aca66c0697258444a18152b77cc5e,Work in progress for background parameters.,Norbert Freundlich,nofreund@cisco.com,Norbert Freundlich,nofreund@cisco.com,2018-11-09 11:02:52+01:00,-3600,2018-11-09 11:02:52+01:00,-3600,True,False,"['em_original.py', 'em_vector.py', 'test_advanced.py']",['113c9884b8fcfe14e44954f77400287871ed2963'],36,55,91,3,1.0,1.0,0.0
bc4fe361d42a1ead2f683ea23cfeac7bb9b6ab95,E-step background parameters OK (for one sentence).,Norbert Freundlich,nofreund@cisco.com,Norbert Freundlich,nofreund@cisco.com,2018-11-09 11:40:32+01:00,-3600,2018-11-09 11:40:32+01:00,-3600,True,False,"['em_vector.py', 'test_advanced.py']",['5d75bb41556aca66c0697258444a18152b77cc5e'],3,28,31,2,0.0,1.0,1.0
79d6d7e660baa94fe3ce289cfaf7a249054cfd7d,Deleted obsolete em.py.,Norbert Freundlich,nofreund@cisco.com,Norbert Freundlich,nofreund@cisco.com,2018-11-09 11:44:44+01:00,-3600,2018-11-09 11:44:44+01:00,-3600,True,False,"['__init__.py', 'em.py', 'em_vector.py', 'test_advanced.py']",['bc4fe361d42a1ead2f683ea23cfeac7bb9b6ab95'],306,1,307,4,0.8591549295774648,0.5070422535211268,0.0
189917102524d5e5e06fc423a1b791532250fc77,"Nfr (#7)

* Updated project structure and .gitignore

* Rewrote Santu_s original e-step and added tests.

* Vectorized E-Step. HP compute still to be validated. Chain to be validated.

* Transform existing data in matrices. Commit before major update of vectorised e-step

* Problem with huge matrices. Freeze this as is, then start the fix.

* E-Step sparse matrix implementation for one sentence.

* Created class structure for EM. Migrated EM_E Original to em_original.

* Created class structure for EM. Migrated EM_E Original to em_original.

* Created class structure for EM. Migrated EM_E Original to em_original. Added em_base

* Updated methods structure for em_vector. Updated test_advanced for em_original. Minor cleaning.

* Implement em_vector e_step.

* Update .gitignore with .idea

* Updated real tests for em_vector. First review OK in e_step.

* Work in progress for background parameters.

* E-step background parameters OK (for one sentence).

* Deleted obsolete em.py.",nfreundlich,norbiein@gmail.com,hewilder,hewample@mtu.edu,2018-11-10 04:10:01+01:00,-3600,2018-11-09 22:10:01-05:00,18000,True,False,"['.gitignore', 'dummy_comments_nfr.py', '__init__.py', 'em_base.py', 'em_original.py', 'em_vector.py', 'BackgroundProbability.npy', 'HP.npy', 'HPB.npy', 'HPB_updated.npy', 'HP_updated.npy', 'PI.npy', 'Reviews.npy', 'TopicModel.npy', 'test_advanced.py']",['e0ebdd240c080c70084c78a1bd9b94533c43f292'],11,492,503,15,0.44776119402985076,0.5186567164179104,1.0
1e5407fb72d8260bfd7323c3c7e81c4359e62c4c,Renamed nw in v,Norbert Freundlich,nofreund@cisco.com,Norbert Freundlich,nofreund@cisco.com,2018-11-10 14:40:06+01:00,-3600,2018-11-10 14:40:06+01:00,-3600,True,False,"['em_base.py', 'em_vector.py']",['c1e3589a81c0c47fc5438131696e548de9c5f725'],17,17,34,2,,,
7fa25c1055347e6678f392e8c82e8684b86e0ef6,Renamed na in f,Norbert Freundlich,nofreund@cisco.com,Norbert Freundlich,nofreund@cisco.com,2018-11-10 14:45:56+01:00,-3600,2018-11-10 14:45:56+01:00,-3600,True,False,"['em_base.py', 'em_vector.py']",['1e5407fb72d8260bfd7323c3c7e81c4359e62c4c'],5,5,10,2,,,
7f51d73fad95d06782f9313ca0ee69951ff9aaa7,Renamed all aspects to features,Norbert Freundlich,nofreund@cisco.com,Norbert Freundlich,nofreund@cisco.com,2018-11-10 14:56:17+01:00,-3600,2018-11-10 14:56:17+01:00,-3600,True,False,"['em_vector.py', 'test_advanced.py']",['7fa25c1055347e6678f392e8c82e8684b86e0ef6'],28,28,56,2,,,
5964040b8c16f3b346d1b76e855309512161fdc1,Added specific test classes for EM Original and Vector,Norbert Freundlich,nofreund@cisco.com,Norbert Freundlich,nofreund@cisco.com,2018-11-10 15:16:10+01:00,-3600,2018-11-10 15:16:10+01:00,-3600,True,False,"['test_expectationMaximizationOriginal.py', 'test_expectationMaximizationVector.py']",['7f51d73fad95d06782f9313ca0ee69951ff9aaa7'],0,90,90,2,0.5254237288135594,0.5254237288135594,1.0
faeab6b116723d795cb822ce50edbe551693ca53,Deleted unused tests from test_advanced file.,Norbert Freundlich,nofreund@cisco.com,Norbert Freundlich,nofreund@cisco.com,2018-11-10 15:22:23+01:00,-3600,2018-11-10 15:22:23+01:00,-3600,True,False,['test_advanced.py'],['5964040b8c16f3b346d1b76e855309512161fdc1'],73,6,79,1,0.5490196078431373,0.5490196078431373,0.0
0db879ae2b754e5db4e884581031d0406dfb59e0,"Recommitting - didn't get contents of parse_and_model the first time for some reason

Cleaned up code (renamed based on agreed upon collection > document > section > word naming convention)

Moved into separate file

Still to do:
 - Performance issues in model building function, need to investigate and fix
 - Reformat version of output for model building into matrices to be passed off to EM",hewilder,hwilder3@illinois.edu,hwilder3,hwilder3@illinois.edu,2018-11-10 19:05:35-05:00,18000,2018-11-10 19:05:35-05:00,18000,True,False,"['parse_and_model.py', 'readFiles_test.py']",['c39e96af7f6e5acec45de63341ccf8fd2259fa3d'],153,476,629,2,0.0,0.0,1.0
34f00168ec902d227d6d5c6acd183012d10f18cd,"Now included -

Formatting for EM as specified in em_vector.

Note: performance on build_explicit_models is crappy so that's going to need some more work, but it should work for testing EM for the moment.

Also cleaned up readFiles_test, not quite ready to be deleted yet, but it will be eventually.",hewilder,hwilder3@illinois.edu,hwilder3,hwilder3@illinois.edu,2018-11-11 00:48:38-05:00,18000,2018-11-11 00:48:38-05:00,18000,True,False,"['parse_and_model.py', 'readFiles_test.py']",['0db879ae2b754e5db4e884581031d0406dfb59e0'],309,87,396,2,1.0,1.0,0.0
c3c4c11d6d044e429646c1fc6add6ed5466c638d,"Parse and Model w/Matrix Output (#8)

* H - test commit

* H test commit 2

* Still trying to figure out how to commit.

* Testing commit from local

* Testing commit from PyCharm

* Project code tests - Spacy (finally) successfully loaded

* Project code tests - sentence tokenizing and some basic counting

* Working counts on sample document set 1

* Adding sample data and sample background/topic models and sentence counts for testing, will clean up code and add unit tests, but seems to be working for the moment.

* Adding sample data and sample background/topic models and sentence counts for testing, will clean up code and add unit tests, but seems to be working for the moment.

* Trying to get Pycharm and GitHub to play nice.

* Topic model building converted to function format and documented (now callable with three required data frames)

Still need to add test cases and separate this code off into a permanent file

* Added two functions:
format_feature_list - takes in a nested list and returns a data frame with ids for each feature

read_annotated_data - reads in Santu's annotated input files, returns DataFrames with the annotation information as well as a somewhat cleaned set of section text, including ids - can be passed into the build_models function

* Recommitting - didn't get contents of parse_and_model the first time for some reason

Cleaned up code (renamed based on agreed upon collection > document > section > word naming convention)

Moved into separate file

Still to do:
 - Performance issues in model building function, need to investigate and fix
 - Reformat version of output for model building into matrices to be passed off to EM

* Now included -

Formatting for EM as specified in em_vector.

Note: performance on build_explicit_models is crappy so that's going to need some more work, but it should work for testing EM for the moment.

Also cleaned up readFiles_test, not quite ready to be deleted yet, but it will be eventually.",hewilder,hewample@mtu.edu,nfreundlich,norbiein@gmail.com,2018-11-13 08:08:52-05:00,18000,2018-11-13 14:08:52+01:00,-3600,True,False,"['parse_and_model.py', 'readFiles_test.py']",['189917102524d5e5e06fc423a1b791532250fc77'],116,377,493,2,0.0,0.0,0.6273291925465838
2a78059cf79d7944404f12d9a499d43bbc5e36ac,Updated cost and test.,Norbert Freundlich,nofreund@cisco.com,Norbert Freundlich,nofreund@cisco.com,2018-11-13 15:21:22+01:00,-3600,2018-11-13 15:21:22+01:00,-3600,True,False,"['em_original.py', 'BackgroundProbability.npy', 'HP.npy', 'HPB.npy', 'HPB_updated.npy', 'HP_updated.npy', 'PI.npy', 'Reviews.npy', 'TopicModel.npy', 'test_expectationMaximizationOriginal.py']",['faeab6b116723d795cb822ce50edbe551693ca53'],6,91,97,10,0.5,0.5,0.96
4d5098e9e62174e57c5e213fd426ca1083be62d8,Update test files.,Norbert Freundlich,nofreund@cisco.com,Norbert Freundlich,nofreund@cisco.com,2018-11-13 16:01:44+01:00,-3600,2018-11-13 16:01:44+01:00,-3600,True,False,"['DIST.npy', 'MY_DIST.npy', 'MY_HPB_updated.npy', 'MY_HP_Updated.npy', 'MY_PI_updated.npy', 'MY_PREVIOUS_PI.npy', 'PI_updated.npy']",['2a78059cf79d7944404f12d9a499d43bbc5e36ac'],0,0,0,7,,,
bdbb24d9ce79554b7b7388d04d8ef35daea4944d,Added test skeletons for parse_and_model. Test for test_format_feature_list.,Norbert Freundlich,nofreund@cisco.com,Norbert Freundlich,nofreund@cisco.com,2018-11-13 23:41:46+01:00,-3600,2018-11-13 23:41:46+01:00,-3600,True,False,"['context.py', 'test_ParseAndModel.py', 'test_expectationMaximizationVector.py']",['30173ef6e0ae5c3870dc2caad2cbf9b92198fc20'],1,35,36,3,1.0,1.0,1.0
b8c79d704fd6904a2e4b768e47ad0c8386c427d5,"Nfr (#9)

* Updated project structure and .gitignore

* Rewrote Santu_s original e-step and added tests.

* Vectorized E-Step. HP compute still to be validated. Chain to be validated.

* Transform existing data in matrices. Commit before major update of vectorised e-step

* Problem with huge matrices. Freeze this as is, then start the fix.

* E-Step sparse matrix implementation for one sentence.

* Created class structure for EM. Migrated EM_E Original to em_original.

* Created class structure for EM. Migrated EM_E Original to em_original.

* Created class structure for EM. Migrated EM_E Original to em_original. Added em_base

* Updated methods structure for em_vector. Updated test_advanced for em_original. Minor cleaning.

* Implement em_vector e_step.

* Update .gitignore with .idea

* Updated real tests for em_vector. First review OK in e_step.

* Work in progress for background parameters.

* E-step background parameters OK (for one sentence).

* Deleted obsolete em.py.

* Renamed nw in v

* Renamed na in f

* Renamed all aspects to features

* Added specific test classes for EM Original and Vector

* Deleted unused tests from test_advanced file.

* Updated cost and test.

* Update test files.

* Added test skeletons for parse_and_model. Test for test_format_feature_list.",nfreundlich,norbiein@gmail.com,hewilder,hewample@mtu.edu,2018-11-14 02:15:01+01:00,-3600,2018-11-13 20:15:01-05:00,18000,True,False,"['em_base.py', 'em_original.py', 'em_vector.py', 'context.py', 'BackgroundProbability.npy', 'DIST.npy', 'HP.npy', 'HPB.npy', 'HPB_updated.npy', 'HP_updated.npy', 'MY_DIST.npy', 'MY_HPB_updated.npy', 'MY_HP_Updated.npy', 'MY_PI_updated.npy', 'MY_PREVIOUS_PI.npy', 'PI.npy', 'PI_updated.npy', 'Reviews.npy', 'TopicModel.npy', 'test_ParseAndModel.py', 'test_advanced.py', 'test_expectationMaximizationOriginal.py', 'test_expectationMaximizationVector.py']",['c3c4c11d6d044e429646c1fc6add6ed5466c638d'],117,259,376,23,0.6666666666666666,0.6666666666666666,0.9733333333333334
06fc830c5ee0738e328e95a1bc09ce66cc5f3673,"Code from pull request #9 merged into branch.

Wrote tests for feature_list and read_annotated_data.

build_explicit_models still to go.

Found the slow spot in build_explicit_models - the nlp call is to blame. I will try swapping it out with either nltk or metapy to see if I can get better performance.

Also added a ""main"" as requested.",hwilder3,hwilder3@illinois.edu,hwilder3,hwilder3@illinois.edu,2018-11-13 22:20:56-05:00,18000,2018-11-13 22:20:56-05:00,18000,True,False,"['parse_and_model.py', 'iPod.final', 'test_ParseAndModel.py']",['032a0249eb2e8ce7def125273afdf15bbc6599bb'],5,10682,10687,3,0.3333333333333333,0.9361702127659575,0.0425531914893617
837de3afff95b585abb56931939213e39047febf,"Compute m_step 1 sentence, vectorized. Added tests for new methods.",Norbert Freundlich,nofreund@cisco.com,Norbert Freundlich,nofreund@cisco.com,2018-11-14 16:52:22+01:00,-3600,2018-11-14 16:52:22+01:00,-3600,True,False,"['em_original.py', 'em_vector.py', 'test_expectationMaximizationVector.py']",['4fb64d1bab2ffdee0c87cc9d90d9537bdb9331c6'],3,81,84,3,0.6595744680851063,1.0,1.0
3e252c4ca6f9b950f37c2d7e78a6192a7e1ecb97,Start minor optimization.,Norbert Freundlich,nofreund@cisco.com,Norbert Freundlich,nofreund@cisco.com,2018-11-15 16:07:02+01:00,-3600,2018-11-15 16:07:02+01:00,-3600,True,False,"['em_base.py', 'em_vector.py', 'test_expectationMaximizationVector.py']",['837de3afff95b585abb56931939213e39047febf'],22,91,113,3,0.0,0.9473684210526315,1.0
21f3591bdd045832c39e71b10ec7076cce85f0ac,Start minor optimization - slight improvement.,Norbert Freundlich,nofreund@cisco.com,Norbert Freundlich,nofreund@cisco.com,2018-11-15 16:48:12+01:00,-3600,2018-11-15 16:48:12+01:00,-3600,True,False,['em_vector.py'],['3e252c4ca6f9b950f37c2d7e78a6192a7e1ecb97'],2,2,4,1,,,
f245e03e7a89b92493ba74cda9ec2096519d74e7,Update all for passing over e-m code.,Norbert Freundlich,nofreund@cisco.com,Norbert Freundlich,nofreund@cisco.com,2018-11-16 15:46:08+01:00,-3600,2018-11-16 15:46:08+01:00,-3600,True,False,"['em_vector.py', 'test_expectationMaximizationVector.py']",['21f3591bdd045832c39e71b10ec7076cce85f0ac'],44,20,64,2,1.0,0.125,0.0
dff23e7abf77a8ede1df21808a07fe02460b4824,"Nfr (#10)

* H - test commit

* H test commit 2

* Still trying to figure out how to commit.

* Testing commit from local

* Updated project structure and .gitignore

* Testing commit from PyCharm

* Project code tests - Spacy (finally) successfully loaded

* Project code tests - sentence tokenizing and some basic counting

* Working counts on sample document set 1

* Adding sample data and sample background/topic models and sentence counts for testing, will clean up code and add unit tests, but seems to be working for the moment.

* Adding sample data and sample background/topic models and sentence counts for testing, will clean up code and add unit tests, but seems to be working for the moment.

* Trying to get Pycharm and GitHub to play nice.

* Topic model building converted to function format and documented (now callable with three required data frames)

Still need to add test cases and separate this code off into a permanent file

* Rewrote Santu_s original e-step and added tests.

* Vectorized E-Step. HP compute still to be validated. Chain to be validated.

* Transform existing data in matrices. Commit before major update of vectorised e-step

* Problem with huge matrices. Freeze this as is, then start the fix.

* E-Step sparse matrix implementation for one sentence.

* Created class structure for EM. Migrated EM_E Original to em_original.

* Created class structure for EM. Migrated EM_E Original to em_original.

* Created class structure for EM. Migrated EM_E Original to em_original. Added em_base

* Updated methods structure for em_vector. Updated test_advanced for em_original. Minor cleaning.

* Implement em_vector e_step.

* Update .gitignore with .idea

* Updated real tests for em_vector. First review OK in e_step.

* Added two functions:
format_feature_list - takes in a nested list and returns a data frame with ids for each feature

read_annotated_data - reads in Santu's annotated input files, returns DataFrames with the annotation information as well as a somewhat cleaned set of section text, including ids - can be passed into the build_models function

* Work in progress for background parameters.

* E-step background parameters OK (for one sentence).

* Deleted obsolete em.py.

* Renamed nw in v

* Renamed na in f

* Renamed all aspects to features

* Added specific test classes for EM Original and Vector

* Deleted unused tests from test_advanced file.

* Recommitting - didn't get contents of parse_and_model the first time for some reason

Cleaned up code (renamed based on agreed upon collection > document > section > word naming convention)

Moved into separate file

Still to do:
 - Performance issues in model building function, need to investigate and fix
 - Reformat version of output for model building into matrices to be passed off to EM

* Now included -

Formatting for EM as specified in em_vector.

Note: performance on build_explicit_models is crappy so that's going to need some more work, but it should work for testing EM for the moment.

Also cleaned up readFiles_test, not quite ready to be deleted yet, but it will be eventually.

* Updated cost and test.

* Update test files.

* Added test skeletons for parse_and_model. Test for test_format_feature_list.

* Code from pull request #9 merged into branch.

Wrote tests for feature_list and read_annotated_data.

build_explicit_models still to go.

Found the slow spot in build_explicit_models - the nlp call is to blame. I will try swapping it out with either nltk or metapy to see if I can get better performance.

Also added a ""main"" as requested.

* Compute m_step 1 sentence, vectorized. Added tests for new methods.

* Start minor optimization.

* Start minor optimization - slight improvement.

* Update all for passing over e-m code.",nfreundlich,norbiein@gmail.com,hewilder,hewample@mtu.edu,2018-11-17 04:43:39+01:00,-3600,2018-11-16 22:43:39-05:00,18000,True,False,"['em_base.py', 'em_original.py', 'em_vector.py', 'parse_and_model.py', 'iPod.final', 'test_ParseAndModel.py', 'test_expectationMaximizationVector.py']",['b8c79d704fd6904a2e4b768e47ad0c8386c427d5'],48,10848,10896,7,0.457286432160804,0.9547738693467337,0.32160804020100503
46e306361a6bdfe69f944c63e7323959ab166cbd,"Comments from Pull Request #8 have been addressed, including the following:

- Swapped to dense arrays for the return, although not sure those conversions are currently in the optimal place
- section_word_counts has been removed
- renamed all ""array"" variable names to ""matrix"" (at least I think I got all of them)
- main function added

Also -
- bug in lemmatization flag for build_explicit_models found in testing and fixed, currently defaulting to true, but we could easily change that
- basic unit tests for build_explicit_models added but it will probably need some more, I can add them later, they're just a lot of work per test to do the calculations by hand and get them formatted correctly

Known Issues:
- inconsistency in list types being used for counting (need to decided whether to go with Counter or defaultdict and stick with it)
- severe performance issues in build_explicit_models being caused by call to NLP, suggest trying an implementation with metapy or NLTK",hwilder3,hwilder3@illinois.edu,hwilder3,hwilder3@illinois.edu,2018-11-17 01:05:14-05:00,18000,2018-11-17 01:05:14-05:00,18000,True,False,['parse_and_model.py'],['8f19b7507132425545a88dc87d53a7fb020d5d64'],168,63,231,1,0.0,1.0,0.0
a5884034789fb56473677a9241f6e9087617d682,"Used the v1 vectorization implementation as a base and made the following modifications:

- Rearranged looping to be over features instead of sections - results in many fewer loops in most cases

- Pulled a few repetitive steps out of the looping:
	- In E-step, numerator for background hidden parameters is calculated only once as part of initialization (doesn't change throughout optimization)
	- In M-step, c(w,s)*(1-P(z_sw = B)) is calculated only once at beginning of step since it is not depended on the feature

- Using power vectorized function instead of replacing zeros with 1's in E-step, allows us to keep that division in a sparse matrix

- Changed review binary calculation in intialization to

Also added some test logic in import data to use existing parse and model methods, still need to determine best way to integrate those - add in call to constructor? Or make part of class?

Need to make the following changes to parse_and_model:
	- Topic model should be dense array, not sparse

Still need to write some tests also",hwilder3,hwilder3@illinois.edu,hwilder3,hwilder3@illinois.edu,2018-11-18 19:55:36-05:00,18000,2018-11-18 19:55:36-05:00,18000,True,False,"['em_vector.py', 'em_vector_v2.py', 'MY_HPB_updated.npy', 'MY_HP_Updated.npy', 'MY_PI_updated.npy', 'MY_PREVIOUS_PI.npy', 'test_ParseAndModel.py']",['46e306361a6bdfe69f944c63e7323959ab166cbd'],40,482,522,7,0.19806763285024154,0.6666666666666666,1.0
08e6797fe8939a55ed3f84721bf3c1f58e243bea,"Addressed comments from Pull Request #8, Added test cases (#11)

* H - test commit

* H test commit 2

* Still trying to figure out how to commit.

* Testing commit from local

* Testing commit from PyCharm

* Project code tests - Spacy (finally) successfully loaded

* Project code tests - sentence tokenizing and some basic counting

* Working counts on sample document set 1

* Adding sample data and sample background/topic models and sentence counts for testing, will clean up code and add unit tests, but seems to be working for the moment.

* Adding sample data and sample background/topic models and sentence counts for testing, will clean up code and add unit tests, but seems to be working for the moment.

* Trying to get Pycharm and GitHub to play nice.

* Topic model building converted to function format and documented (now callable with three required data frames)

Still need to add test cases and separate this code off into a permanent file

* Added two functions:
format_feature_list - takes in a nested list and returns a data frame with ids for each feature

read_annotated_data - reads in Santu's annotated input files, returns DataFrames with the annotation information as well as a somewhat cleaned set of section text, including ids - can be passed into the build_models function

* Recommitting - didn't get contents of parse_and_model the first time for some reason

Cleaned up code (renamed based on agreed upon collection > document > section > word naming convention)

Moved into separate file

Still to do:
 - Performance issues in model building function, need to investigate and fix
 - Reformat version of output for model building into matrices to be passed off to EM

* Now included -

Formatting for EM as specified in em_vector.

Note: performance on build_explicit_models is crappy so that's going to need some more work, but it should work for testing EM for the moment.

Also cleaned up readFiles_test, not quite ready to be deleted yet, but it will be eventually.

* Code from pull request #9 merged into branch.

Wrote tests for feature_list and read_annotated_data.

build_explicit_models still to go.

Found the slow spot in build_explicit_models - the nlp call is to blame. I will try swapping it out with either nltk or metapy to see if I can get better performance.

Also added a ""main"" as requested.

* Comments from Pull Request #8 have been addressed, including the following:

- Swapped to dense arrays for the return, although not sure those conversions are currently in the optimal place
- section_word_counts has been removed
- renamed all ""array"" variable names to ""matrix"" (at least I think I got all of them)
- main function added

Also -
- bug in lemmatization flag for build_explicit_models found in testing and fixed, currently defaulting to true, but we could easily change that
- basic unit tests for build_explicit_models added but it will probably need some more, I can add them later, they're just a lot of work per test to do the calculations by hand and get them formatted correctly

Known Issues:
- inconsistency in list types being used for counting (need to decided whether to go with Counter or defaultdict and stick with it)
- severe performance issues in build_explicit_models being caused by call to NLP, suggest trying an implementation with metapy or NLTK

* Used the v1 vectorization implementation as a base and made the following modifications:

- Rearranged looping to be over features instead of sections - results in many fewer loops in most cases

- Pulled a few repetitive steps out of the looping:
	- In E-step, numerator for background hidden parameters is calculated only once as part of initialization (doesn't change throughout optimization)
	- In M-step, c(w,s)*(1-P(z_sw = B)) is calculated only once at beginning of step since it is not depended on the feature

- Using power vectorized function instead of replacing zeros with 1's in E-step, allows us to keep that division in a sparse matrix

- Changed review binary calculation in intialization to

Also added some test logic in import data to use existing parse and model methods, still need to determine best way to integrate those - add in call to constructor? Or make part of class?

Need to make the following changes to parse_and_model:
	- Topic model should be dense array, not sparse

Still need to write some tests also",hewilder,hewample@mtu.edu,nfreundlich,norbiein@gmail.com,2018-11-19 15:58:10-05:00,18000,2018-11-19 21:58:10+01:00,-3600,True,False,"['em_vector.py', 'em_vector_v2.py', 'parse_and_model.py', 'MY_HPB_updated.npy', 'MY_HP_Updated.npy', 'MY_PI_updated.npy', 'MY_PREVIOUS_PI.npy', 'test_ParseAndModel.py']",['dff23e7abf77a8ede1df21808a07fe02460b4824'],208,545,753,8,0.16872427983539096,0.720164609053498,0.8518518518518519
5d01a759ec687328289e0424f3dbcbc0eafb7fc2,Created class wrapper around parse_and_model.,Norbert Freundlich,nofreund@cisco.com,Norbert Freundlich,nofreund@cisco.com,2018-11-19 22:20:10+01:00,-3600,2018-11-19 22:20:10+01:00,-3600,True,False,"['__init__.py', 'em_base.py', 'parse_and_model.py', 'test_ParseAndModel.py']",['d1104c0470751750528cc2ff051d354ece8a2b64'],484,551,1035,4,0.7272727272727273,1.0,1.0
3924576a24e0a98d33fd7ddd20cc8514f47e50c0,Improved execution speed for parse_and_model,Norbert Freundlich,nofreund@cisco.com,Norbert Freundlich,nofreund@cisco.com,2018-11-19 23:17:43+01:00,-3600,2018-11-19 23:17:43+01:00,-3600,True,False,['parse_and_model.py'],['5d01a759ec687328289e0424f3dbcbc0eafb7fc2'],11,23,34,1,0.0,0.0,0.0
58cc883a4b0952bc775f99dd9f5aecc7913805ae,"Nfr (#12)

* H - test commit

* H test commit 2

* Still trying to figure out how to commit.

* Testing commit from local

* Updated project structure and .gitignore

* Testing commit from PyCharm

* Project code tests - Spacy (finally) successfully loaded

* Project code tests - sentence tokenizing and some basic counting

* Working counts on sample document set 1

* Adding sample data and sample background/topic models and sentence counts for testing, will clean up code and add unit tests, but seems to be working for the moment.

* Adding sample data and sample background/topic models and sentence counts for testing, will clean up code and add unit tests, but seems to be working for the moment.

* Trying to get Pycharm and GitHub to play nice.

* Topic model building converted to function format and documented (now callable with three required data frames)

Still need to add test cases and separate this code off into a permanent file

* Rewrote Santu_s original e-step and added tests.

* Vectorized E-Step. HP compute still to be validated. Chain to be validated.

* Transform existing data in matrices. Commit before major update of vectorised e-step

* Problem with huge matrices. Freeze this as is, then start the fix.

* E-Step sparse matrix implementation for one sentence.

* Created class structure for EM. Migrated EM_E Original to em_original.

* Created class structure for EM. Migrated EM_E Original to em_original.

* Created class structure for EM. Migrated EM_E Original to em_original. Added em_base

* Updated methods structure for em_vector. Updated test_advanced for em_original. Minor cleaning.

* Implement em_vector e_step.

* Update .gitignore with .idea

* Updated real tests for em_vector. First review OK in e_step.

* Added two functions:
format_feature_list - takes in a nested list and returns a data frame with ids for each feature

read_annotated_data - reads in Santu's annotated input files, returns DataFrames with the annotation information as well as a somewhat cleaned set of section text, including ids - can be passed into the build_models function

* Work in progress for background parameters.

* E-step background parameters OK (for one sentence).

* Deleted obsolete em.py.

* Renamed nw in v

* Renamed na in f

* Renamed all aspects to features

* Added specific test classes for EM Original and Vector

* Deleted unused tests from test_advanced file.

* Recommitting - didn't get contents of parse_and_model the first time for some reason

Cleaned up code (renamed based on agreed upon collection > document > section > word naming convention)

Moved into separate file

Still to do:
 - Performance issues in model building function, need to investigate and fix
 - Reformat version of output for model building into matrices to be passed off to EM

* Now included -

Formatting for EM as specified in em_vector.

Note: performance on build_explicit_models is crappy so that's going to need some more work, but it should work for testing EM for the moment.

Also cleaned up readFiles_test, not quite ready to be deleted yet, but it will be eventually.

* Updated cost and test.

* Update test files.

* Added test skeletons for parse_and_model. Test for test_format_feature_list.

* Code from pull request #9 merged into branch.

Wrote tests for feature_list and read_annotated_data.

build_explicit_models still to go.

Found the slow spot in build_explicit_models - the nlp call is to blame. I will try swapping it out with either nltk or metapy to see if I can get better performance.

Also added a ""main"" as requested.

* Compute m_step 1 sentence, vectorized. Added tests for new methods.

* Start minor optimization.

* Start minor optimization - slight improvement.

* Update all for passing over e-m code.

* Comments from Pull Request #8 have been addressed, including the following:

- Swapped to dense arrays for the return, although not sure those conversions are currently in the optimal place
- section_word_counts has been removed
- renamed all ""array"" variable names to ""matrix"" (at least I think I got all of them)
- main function added

Also -
- bug in lemmatization flag for build_explicit_models found in testing and fixed, currently defaulting to true, but we could easily change that
- basic unit tests for build_explicit_models added but it will probably need some more, I can add them later, they're just a lot of work per test to do the calculations by hand and get them formatted correctly

Known Issues:
- inconsistency in list types being used for counting (need to decided whether to go with Counter or defaultdict and stick with it)
- severe performance issues in build_explicit_models being caused by call to NLP, suggest trying an implementation with metapy or NLTK

* Used the v1 vectorization implementation as a base and made the following modifications:

- Rearranged looping to be over features instead of sections - results in many fewer loops in most cases

- Pulled a few repetitive steps out of the looping:
	- In E-step, numerator for background hidden parameters is calculated only once as part of initialization (doesn't change throughout optimization)
	- In M-step, c(w,s)*(1-P(z_sw = B)) is calculated only once at beginning of step since it is not depended on the feature

- Using power vectorized function instead of replacing zeros with 1's in E-step, allows us to keep that division in a sparse matrix

- Changed review binary calculation in intialization to

Also added some test logic in import data to use existing parse and model methods, still need to determine best way to integrate those - add in call to constructor? Or make part of class?

Need to make the following changes to parse_and_model:
	- Topic model should be dense array, not sparse

Still need to write some tests also

* Created class wrapper around parse_and_model.

* Improved execution speed for parse_and_model",nfreundlich,norbiein@gmail.com,hewilder,hewample@mtu.edu,2018-11-20 03:53:16+01:00,-3600,2018-11-19 21:53:16-05:00,18000,True,False,"['__init__.py', 'em_base.py', 'parse_and_model.py', 'test_ParseAndModel.py']",['08e6797fe8939a55ed3f84721bf3c1f58e243bea'],489,568,1057,4,0.5,0.6875,0.6875
846615f317d4a774c8e341895ef52358a8d43651,Renamed em vector by feature,hwilder3,hwilder3@illinois.edu,hwilder3,hwilder3@illinois.edu,2018-11-19 22:01:38-05:00,18000,2018-11-19 22:01:38-05:00,18000,True,False,"['em_vector_by_feature.py', 'em_vector_v2.py']",['0a9e69fa3a0e7a65860dc30337e7b9e9c1c0f7d2'],1,376,377,2,0.2236842105263158,0.5460526315789473,1.0
3541d62098eb65b20c7b09ed9aeea9bbf7b2a1ad,Removing extra em_vector_v2 file,hwilder3,hwilder3@illinois.edu,hwilder3,hwilder3@illinois.edu,2018-11-19 22:06:27-05:00,18000,2018-11-19 22:06:27-05:00,18000,True,False,['em_vector_v2.py'],['846615f317d4a774c8e341895ef52358a8d43651'],375,0,375,1,0.7763157894736842,0.45394736842105265,0.0
33976e385ffb0dcefffd5c14520735931476d729,"Optimize test for 12 cores; added timing, merged Hannah branch.",nfreundlich,norbert4@illinois.edu,nfreundlich,norbert4@illinois.edu,2018-11-22 17:07:49+01:00,-3600,2018-11-22 17:07:49+01:00,-3600,True,False,['parse_and_model.py'],['b306786a484ec0240bbb2c2c7d31730883c938b7'],2,4,6,1,0.0,0.0,0.0
3a90db184d94f39c6e183a81cfda1487b214b493,"Fixed bug in M-step causing divide by zero error

Added some diagnostic print statements to EM

Reorganized ParseAndModel constructor so that it can handle all three steps given the correct arguments

Copied over the test cases for EM feature - still need to do hand calculations to get test cases",hwilder3,hwilder3@illinois.edu,hwilder3,hwilder3@illinois.edu,2018-12-03 21:58:48-05:00,18000,2018-12-03 21:58:48-05:00,18000,True,False,"['__init__.py', 'em_base.py', 'em_vector_by_feature.py', 'parse_and_model.py', 'test_ParseAndModel.py', 'test_expectationMaximizationVector_feature.py']",['3541d62098eb65b20c7b09ed9aeea9bbf7b2a1ad'],58,191,249,6,0.23809523809523808,0.6428571428571429,0.8571428571428571
37ee7d59c0ac7c9f1704079086e853ed47d931f0,"Added prototype file lines parser, still needs the sentence tokenizer but nltk has a ton of options - potentially try Spacy and see if it's going to be too slow here",hwilder3,hwilder3@illinois.edu,hwilder3,hwilder3@illinois.edu,2018-12-03 22:16:58-05:00,18000,2018-12-03 22:16:58-05:00,18000,True,False,['parse_and_model.py'],['3a90db184d94f39c6e183a81cfda1487b214b493'],0,190,190,1,0.008,0.408,0.0
73df1cf8f8808c4c40bab701702be66fdcc52c07,"Reorganized Parse and Model code back to Object Oriented format, fixed all the unit tests.",hwilder3,hwilder3@illinois.edu,hwilder3,hwilder3@illinois.edu,2018-12-04 21:13:43-05:00,18000,2018-12-04 21:13:43-05:00,18000,True,False,"['parse_and_model.py', 'test_ParseAndModel.py']",['37ee7d59c0ac7c9f1704079086e853ed47d931f0'],77,106,183,2,0.6,1.0,0.65
0643ae690c0ee623b86e16ba4392f7ad8f7f577b,"Added constructor test for parse and model

Fixed model feature matrix to be dense array as it should be

Adjusted em feature to use new constructor

Em feature test skeleton is alive, still needs actual tests",hwilder3,hwilder3@illinois.edu,hwilder3,hwilder3@illinois.edu,2018-12-04 23:30:45-05:00,18000,2018-12-04 23:30:45-05:00,18000,True,False,"['em_vector_by_feature.py', 'parse_and_model.py', 'test_ParseAndModel.py', 'test_expectationMaximizationVector_feature.py']",['73df1cf8f8808c4c40bab701702be66fdcc52c07'],102,97,199,4,0.08695652173913043,1.0,0.08695652173913043
dbd5c5cff34546e261717cf89026a8a87fcd29c4,Added additional parse and model test files,hwilder3,hwilder3@illinois.edu,hwilder3,hwilder3@illinois.edu,2018-12-04 23:32:00-05:00,18000,2018-12-04 23:32:00-05:00,18000,True,False,"['fourLineTest.txt', 'simpleTests.txt', 'threeLineTest.txt', 'twoLineTest.txt']",['0643ae690c0ee623b86e16ba4392f7ad8f7f577b'],0,11,11,4,,,
531234e2a77d9dbb626c350ae83c440b697d768d,Commented TODO. Updated main to run on current configuration.,nfreundlich,norbert4@illinois.edu,nfreundlich,norbert4@illinois.edu,2018-12-05 11:46:27+01:00,-3600,2018-12-05 11:46:27+01:00,-3600,True,False,['parse_and_model.py'],['dbd5c5cff34546e261717cf89026a8a87fcd29c4'],4,11,15,1,0.0,0.0,0.0
20c988e0d284353914a642a959f29243079099cc,"Reworked Parse and Model take 2 (#14)

* H - test commit

* H test commit 2

* Still trying to figure out how to commit.

* Testing commit from local

* Testing commit from PyCharm

* Project code tests - Spacy (finally) successfully loaded

* Project code tests - sentence tokenizing and some basic counting

* Working counts on sample document set 1

* Adding sample data and sample background/topic models and sentence counts for testing, will clean up code and add unit tests, but seems to be working for the moment.

* Adding sample data and sample background/topic models and sentence counts for testing, will clean up code and add unit tests, but seems to be working for the moment.

* Trying to get Pycharm and GitHub to play nice.

* Topic model building converted to function format and documented (now callable with three required data frames)

Still need to add test cases and separate this code off into a permanent file

* Added two functions:
format_feature_list - takes in a nested list and returns a data frame with ids for each feature

read_annotated_data - reads in Santu's annotated input files, returns DataFrames with the annotation information as well as a somewhat cleaned set of section text, including ids - can be passed into the build_models function

* Recommitting - didn't get contents of parse_and_model the first time for some reason

Cleaned up code (renamed based on agreed upon collection > document > section > word naming convention)

Moved into separate file

Still to do:
 - Performance issues in model building function, need to investigate and fix
 - Reformat version of output for model building into matrices to be passed off to EM

* Now included -

Formatting for EM as specified in em_vector.

Note: performance on build_explicit_models is crappy so that's going to need some more work, but it should work for testing EM for the moment.

Also cleaned up readFiles_test, not quite ready to be deleted yet, but it will be eventually.

* Code from pull request #9 merged into branch.

Wrote tests for feature_list and read_annotated_data.

build_explicit_models still to go.

Found the slow spot in build_explicit_models - the nlp call is to blame. I will try swapping it out with either nltk or metapy to see if I can get better performance.

Also added a ""main"" as requested.

* Comments from Pull Request #8 have been addressed, including the following:

- Swapped to dense arrays for the return, although not sure those conversions are currently in the optimal place
- section_word_counts has been removed
- renamed all ""array"" variable names to ""matrix"" (at least I think I got all of them)
- main function added

Also -
- bug in lemmatization flag for build_explicit_models found in testing and fixed, currently defaulting to true, but we could easily change that
- basic unit tests for build_explicit_models added but it will probably need some more, I can add them later, they're just a lot of work per test to do the calculations by hand and get them formatted correctly

Known Issues:
- inconsistency in list types being used for counting (need to decided whether to go with Counter or defaultdict and stick with it)
- severe performance issues in build_explicit_models being caused by call to NLP, suggest trying an implementation with metapy or NLTK

* Used the v1 vectorization implementation as a base and made the following modifications:

- Rearranged looping to be over features instead of sections - results in many fewer loops in most cases

- Pulled a few repetitive steps out of the looping:
	- In E-step, numerator for background hidden parameters is calculated only once as part of initialization (doesn't change throughout optimization)
	- In M-step, c(w,s)*(1-P(z_sw = B)) is calculated only once at beginning of step since it is not depended on the feature

- Using power vectorized function instead of replacing zeros with 1's in E-step, allows us to keep that division in a sparse matrix

- Changed review binary calculation in intialization to

Also added some test logic in import data to use existing parse and model methods, still need to determine best way to integrate those - add in call to constructor? Or make part of class?

Need to make the following changes to parse_and_model:
	- Topic model should be dense array, not sparse

Still need to write some tests also

* Renamed em vector by feature

* Removing extra em_vector_v2 file

* Fixed bug in M-step causing divide by zero error

Added some diagnostic print statements to EM

Reorganized ParseAndModel constructor so that it can handle all three steps given the correct arguments

Copied over the test cases for EM feature - still need to do hand calculations to get test cases

* Added prototype file lines parser, still needs the sentence tokenizer but nltk has a ton of options - potentially try Spacy and see if it's going to be too slow here

* Reorganized Parse and Model code back to Object Oriented format, fixed all the unit tests.

* Added constructor test for parse and model

Fixed model feature matrix to be dense array as it should be

Adjusted em feature to use new constructor

Em feature test skeleton is alive, still needs actual tests

* Added additional parse and model test files

* Commented TODO. Updated main to run on current configuration.",hewilder,hewample@mtu.edu,nfreundlich,norbiein@gmail.com,2018-12-05 05:49:48-05:00,18000,2018-12-05 11:49:48+01:00,-3600,True,False,"['__init__.py', 'em_base.py', 'em_vector_by_feature.py', 'parse_and_model.py', 'fourLineTest.txt', 'simpleTests.txt', 'threeLineTest.txt', 'twoLineTest.txt', 'test_ParseAndModel.py', 'test_expectationMaximizationVector_feature.py']",['58cc883a4b0952bc775f99dd9f5aecc7913805ae'],109,474,583,10,0.0,0.7784431137724551,0.2634730538922156
f119f937274bf9387e702cd9dadd5d6eeb06477b,Updated testing project. Step1,nfreundlich,norbert4@illinois.edu,nfreundlich,norbert4@illinois.edu,2018-12-05 12:34:47+01:00,-3600,2018-12-05 12:34:47+01:00,-3600,True,False,"['__init__.py', 'core.py', 'em_vector_by_feature.py', 'helpers.py', 'test_EmVectorByFeature.py', 'test_expectationMaximizationOriginal.py', 'test_expectationMaximizationVector.py']",['fd33627ee492310e382c14a5b29c392488b93419'],71,44,115,7,0.2,0.2,0.0
205072bb16788d518af6fcda6e51b456c092641e,Renamed Original and Vector tests,nfreundlich,norbert4@illinois.edu,nfreundlich,norbert4@illinois.edu,2018-12-05 12:36:19+01:00,-3600,2018-12-05 12:36:19+01:00,-3600,True,False,"['test_ExpectationMaximizationOriginal.py', 'test_ExpectationMaximizationVector.py']",['f119f937274bf9387e702cd9dadd5d6eeb06477b'],0,0,0,2,,,
b1349e280a79b2c870f6b35e146c2282cf4a1f96,Renamed test class to avoid duplication and added setUp and tearDown methods.,nfreundlich,norbert4@illinois.edu,nfreundlich,norbert4@illinois.edu,2018-12-05 12:40:01+01:00,-3600,2018-12-05 12:40:01+01:00,-3600,True,False,"['test_EmVectorByFeature.py', 'test_ExpectationMaximizationVector.py']",['205072bb16788d518af6fcda6e51b456c092641e'],10,27,37,2,1.0,1.0,0.7142857142857143
5d1350c9bfd324c295e8f3960a12a1821bf34b6d,Start pypi creation,nfreundlich,norbert4@illinois.edu,nfreundlich,norbert4@illinois.edu,2018-12-05 14:55:31+01:00,-3600,2018-12-05 14:55:31+01:00,-3600,True,False,"['.gitignore', 'LICENSE', 'README.md', '__init__.py', 'em_gflm.py', 'em_vector_by_feature.py', 'readFiles_test.py', 'requirements.txt', 'setup.py', 'docCounts.data', 'model_background.data', 'model_topic.data', 'sample_dataset_1_feature_mapping.csv', 'sample_dataset_1_features.csv', 'sample_dataset_1_text.csv']",['b1349e280a79b2c870f6b35e146c2282cf4a1f96'],175,95,270,15,1.0,1.0,1.0
8c55e1af412af23754d5037aadcb22982fc41325,Created upload to pypi script.,nfreundlich,norbert4@illinois.edu,nfreundlich,norbert4@illinois.edu,2018-12-05 16:10:28+01:00,-3600,2018-12-05 16:10:28+01:00,-3600,True,False,"['.gitignore', '__init__.py', 'setup.py', 'update_pip.sh']",['5d1350c9bfd324c295e8f3960a12a1821bf34b6d'],5,61,66,4,,,
a9f7cd834d134aeea31f7a3a220ccffb61fd8cd4,"Nfr (#15)

* H - test commit

* H test commit 2

* Still trying to figure out how to commit.

* Testing commit from local

* Updated project structure and .gitignore

* Testing commit from PyCharm

* Project code tests - Spacy (finally) successfully loaded

* Project code tests - sentence tokenizing and some basic counting

* Working counts on sample document set 1

* Adding sample data and sample background/topic models and sentence counts for testing, will clean up code and add unit tests, but seems to be working for the moment.

* Adding sample data and sample background/topic models and sentence counts for testing, will clean up code and add unit tests, but seems to be working for the moment.

* Trying to get Pycharm and GitHub to play nice.

* Topic model building converted to function format and documented (now callable with three required data frames)

Still need to add test cases and separate this code off into a permanent file

* Rewrote Santu_s original e-step and added tests.

* Vectorized E-Step. HP compute still to be validated. Chain to be validated.

* Transform existing data in matrices. Commit before major update of vectorised e-step

* Problem with huge matrices. Freeze this as is, then start the fix.

* E-Step sparse matrix implementation for one sentence.

* Created class structure for EM. Migrated EM_E Original to em_original.

* Created class structure for EM. Migrated EM_E Original to em_original.

* Created class structure for EM. Migrated EM_E Original to em_original. Added em_base

* Updated methods structure for em_vector. Updated test_advanced for em_original. Minor cleaning.

* Implement em_vector e_step.

* Update .gitignore with .idea

* Updated real tests for em_vector. First review OK in e_step.

* Added two functions:
format_feature_list - takes in a nested list and returns a data frame with ids for each feature

read_annotated_data - reads in Santu's annotated input files, returns DataFrames with the annotation information as well as a somewhat cleaned set of section text, including ids - can be passed into the build_models function

* Work in progress for background parameters.

* E-step background parameters OK (for one sentence).

* Deleted obsolete em.py.

* Renamed nw in v

* Renamed na in f

* Renamed all aspects to features

* Added specific test classes for EM Original and Vector

* Deleted unused tests from test_advanced file.

* Recommitting - didn't get contents of parse_and_model the first time for some reason

Cleaned up code (renamed based on agreed upon collection > document > section > word naming convention)

Moved into separate file

Still to do:
 - Performance issues in model building function, need to investigate and fix
 - Reformat version of output for model building into matrices to be passed off to EM

* Now included -

Formatting for EM as specified in em_vector.

Note: performance on build_explicit_models is crappy so that's going to need some more work, but it should work for testing EM for the moment.

Also cleaned up readFiles_test, not quite ready to be deleted yet, but it will be eventually.

* Updated cost and test.

* Update test files.

* Added test skeletons for parse_and_model. Test for test_format_feature_list.

* Code from pull request #9 merged into branch.

Wrote tests for feature_list and read_annotated_data.

build_explicit_models still to go.

Found the slow spot in build_explicit_models - the nlp call is to blame. I will try swapping it out with either nltk or metapy to see if I can get better performance.

Also added a ""main"" as requested.

* Compute m_step 1 sentence, vectorized. Added tests for new methods.

* Start minor optimization.

* Start minor optimization - slight improvement.

* Update all for passing over e-m code.

* Comments from Pull Request #8 have been addressed, including the following:

- Swapped to dense arrays for the return, although not sure those conversions are currently in the optimal place
- section_word_counts has been removed
- renamed all ""array"" variable names to ""matrix"" (at least I think I got all of them)
- main function added

Also -
- bug in lemmatization flag for build_explicit_models found in testing and fixed, currently defaulting to true, but we could easily change that
- basic unit tests for build_explicit_models added but it will probably need some more, I can add them later, they're just a lot of work per test to do the calculations by hand and get them formatted correctly

Known Issues:
- inconsistency in list types being used for counting (need to decided whether to go with Counter or defaultdict and stick with it)
- severe performance issues in build_explicit_models being caused by call to NLP, suggest trying an implementation with metapy or NLTK

* Used the v1 vectorization implementation as a base and made the following modifications:

- Rearranged looping to be over features instead of sections - results in many fewer loops in most cases

- Pulled a few repetitive steps out of the looping:
	- In E-step, numerator for background hidden parameters is calculated only once as part of initialization (doesn't change throughout optimization)
	- In M-step, c(w,s)*(1-P(z_sw = B)) is calculated only once at beginning of step since it is not depended on the feature

- Using power vectorized function instead of replacing zeros with 1's in E-step, allows us to keep that division in a sparse matrix

- Changed review binary calculation in intialization to

Also added some test logic in import data to use existing parse and model methods, still need to determine best way to integrate those - add in call to constructor? Or make part of class?

Need to make the following changes to parse_and_model:
	- Topic model should be dense array, not sparse

Still need to write some tests also

* Created class wrapper around parse_and_model.

* Improved execution speed for parse_and_model

* Renamed em vector by feature

* Removing extra em_vector_v2 file

* Optimize test for 12 cores; added timing, merged Hannah branch.

* Updated testing project. Step1

* Renamed Original and Vector tests

* Renamed test class to avoid duplication and added setUp and tearDown methods.

* Start pypi creation

* Created upload to pypi script.",nfreundlich,norbiein@gmail.com,hewilder,hewample@mtu.edu,2018-12-06 01:40:26+01:00,-3600,2018-12-05 19:40:26-05:00,18000,True,False,"['.gitignore', 'LICENSE', 'README.md', '__init__.py', 'core.py', 'em_gflm.py', 'em_vector_by_feature.py', 'helpers.py', 'readFiles_test.py', 'requirements.txt', 'setup.py', 'docCounts.data', 'model_background.data', 'model_topic.data', 'sample_dataset_1_feature_mapping.csv', 'sample_dataset_1_features.csv', 'sample_dataset_1_text.csv', 'test_EmVectorByFeature.py', 'test_ExpectationMaximizationOriginal.py', 'test_ExpectationMaximizationVector.py', 'test_expectationMaximizationOriginal.py', 'test_expectationMaximizationVector_feature.py', 'update_pip.sh']",['20c988e0d284353914a642a959f29243079099cc'],321,287,608,23,1.0,1.0,0.0
93c5533a745cfaa7e8a4ef2eaf3c1a1c673882ae,"Preliminary implementation of GFLM-word and GFLM-sentence.

Still needs unit tests written.",hwilder3,hwilder3@illinois.edu,hwilder3,hwilder3@illinois.edu,2018-12-06 22:31:05-05:00,18000,2018-12-06 22:31:05-05:00,18000,True,False,"['em_gflm.py', 'test_expectationMaximizationOriginal.py']",['62b46f78937776a9c76b9d98c899dae40d3a41a6'],32,104,136,2,1.0,1.0,0.6153846153846154
e15a16d18e78db22d5743aa3ae189edce5b6de9a,"Updated members in GFLM, comments and main.",nfreundlich,norbert4@illinois.edu,nfreundlich,norbert4@illinois.edu,2018-12-07 15:44:21+01:00,-3600,2018-12-07 15:44:21+01:00,-3600,True,False,['em_gflm.py'],['0a333e89da97207dd89a7093be4c112b7b273449'],20,43,63,1,0.0,1.0,0.0
acd6264885b2feb5583d2bfba26170e01322a0d1,"Constructor edits for EM feature, prelim GFLM word/section (#17)

* H - test commit

* H test commit 2

* Still trying to figure out how to commit.

* Testing commit from local

* Testing commit from PyCharm

* Project code tests - Spacy (finally) successfully loaded

* Project code tests - sentence tokenizing and some basic counting

* Working counts on sample document set 1

* Adding sample data and sample background/topic models and sentence counts for testing, will clean up code and add unit tests, but seems to be working for the moment.

* Adding sample data and sample background/topic models and sentence counts for testing, will clean up code and add unit tests, but seems to be working for the moment.

* Trying to get Pycharm and GitHub to play nice.

* Topic model building converted to function format and documented (now callable with three required data frames)

Still need to add test cases and separate this code off into a permanent file

* Added two functions:
format_feature_list - takes in a nested list and returns a data frame with ids for each feature

read_annotated_data - reads in Santu's annotated input files, returns DataFrames with the annotation information as well as a somewhat cleaned set of section text, including ids - can be passed into the build_models function

* Recommitting - didn't get contents of parse_and_model the first time for some reason

Cleaned up code (renamed based on agreed upon collection > document > section > word naming convention)

Moved into separate file

Still to do:
 - Performance issues in model building function, need to investigate and fix
 - Reformat version of output for model building into matrices to be passed off to EM

* Now included -

Formatting for EM as specified in em_vector.

Note: performance on build_explicit_models is crappy so that's going to need some more work, but it should work for testing EM for the moment.

Also cleaned up readFiles_test, not quite ready to be deleted yet, but it will be eventually.

* Code from pull request #9 merged into branch.

Wrote tests for feature_list and read_annotated_data.

build_explicit_models still to go.

Found the slow spot in build_explicit_models - the nlp call is to blame. I will try swapping it out with either nltk or metapy to see if I can get better performance.

Also added a ""main"" as requested.

* Comments from Pull Request #8 have been addressed, including the following:

- Swapped to dense arrays for the return, although not sure those conversions are currently in the optimal place
- section_word_counts has been removed
- renamed all ""array"" variable names to ""matrix"" (at least I think I got all of them)
- main function added

Also -
- bug in lemmatization flag for build_explicit_models found in testing and fixed, currently defaulting to true, but we could easily change that
- basic unit tests for build_explicit_models added but it will probably need some more, I can add them later, they're just a lot of work per test to do the calculations by hand and get them formatted correctly

Known Issues:
- inconsistency in list types being used for counting (need to decided whether to go with Counter or defaultdict and stick with it)
- severe performance issues in build_explicit_models being caused by call to NLP, suggest trying an implementation with metapy or NLTK

* Used the v1 vectorization implementation as a base and made the following modifications:

- Rearranged looping to be over features instead of sections - results in many fewer loops in most cases

- Pulled a few repetitive steps out of the looping:
	- In E-step, numerator for background hidden parameters is calculated only once as part of initialization (doesn't change throughout optimization)
	- In M-step, c(w,s)*(1-P(z_sw = B)) is calculated only once at beginning of step since it is not depended on the feature

- Using power vectorized function instead of replacing zeros with 1's in E-step, allows us to keep that division in a sparse matrix

- Changed review binary calculation in intialization to

Also added some test logic in import data to use existing parse and model methods, still need to determine best way to integrate those - add in call to constructor? Or make part of class?

Need to make the following changes to parse_and_model:
	- Topic model should be dense array, not sparse

Still need to write some tests also

* Renamed em vector by feature

* Removing extra em_vector_v2 file

* Fixed bug in M-step causing divide by zero error

Added some diagnostic print statements to EM

Reorganized ParseAndModel constructor so that it can handle all three steps given the correct arguments

Copied over the test cases for EM feature - still need to do hand calculations to get test cases

* Added prototype file lines parser, still needs the sentence tokenizer but nltk has a ton of options - potentially try Spacy and see if it's going to be too slow here

* Reorganized Parse and Model code back to Object Oriented format, fixed all the unit tests.

* Added constructor test for parse and model

Fixed model feature matrix to be dense array as it should be

Adjusted em feature to use new constructor

Em feature test skeleton is alive, still needs actual tests

* Added additional parse and model test files

* Commented TODO. Updated main to run on current configuration.

* Preliminary implementation of GFLM-word and GFLM-sentence.

Still needs unit tests written.

* Updated members in GFLM, comments and main.",hewilder,hewample@mtu.edu,nfreundlich,norbiein@gmail.com,2018-12-07 10:30:20-05:00,18000,2018-12-07 16:30:20+01:00,-3600,True,False,"['em_base.py', 'em_gflm.py', 'em_vector_by_feature.py', 'test_expectationMaximizationOriginal.py', 'test_expectationMaximizationVector_feature.py']",['a9f7cd834d134aeea31f7a3a220ccffb61fd8cd4'],38,279,317,5,0.5916666666666667,1.0,0.5666666666666667
80784f333ef350ad51a5893f09e8df72493b1723,"Merge branches 'hannah' and 'nfr' of https://github.com/nfreundlich/CS410_CourseProject into nfr

# Conflicts:
#	feature_mining/em_vector_by_feature.py
#	tests/test_expectationMaximizationOriginal.py
#	tests/test_expectationMaximizationVector_feature.py",nfreundlich,norbert4@illinois.edu,nfreundlich,norbert4@illinois.edu,2018-12-07 22:49:25+01:00,-3600,2018-12-07 22:49:25+01:00,-3600,True,False,"['test_expectationMaximizationOriginal.py', 'test_expectationMaximizationVector_feature.py']",['7aa53fe2e403f53f298eee86b833f858530dc3e8'],70,1,71,2,0.42105263157894735,0.0,0.0
921c3df8925101bbb672b7c67a375d0c797257f3,Checking that commits still go through okay,hwilder3,hwilder3@illinois.edu,hwilder3,hwilder3@illinois.edu,2018-12-08 10:13:13-05:00,18000,2018-12-08 10:13:13-05:00,18000,True,False,['em_gflm.py'],['80784f333ef350ad51a5893f09e8df72493b1723'],2,2,4,1,,,
3887b83b2e6f84d3363ef491fb32335932c924e7,"Added additional testing to compare directly against results of original code

Main bug found so far in original code was that titles were getting counted in word and section counts but were not included in the actual models

Found in new code - switched code to default to ln instead of log 2 by default to match old implementation. Confirmed correct calculation of word feature counts (one per occurrence, not one per section) and switched that accordingly.

Trying to get all the way through EM with a single set of results and then will add additional test cases.",hwilder3,hwilder3@illinois.edu,hwilder3,hwilder3@illinois.edu,2018-12-09 01:01:10-05:00,18000,2018-12-09 01:01:10-05:00,18000,True,False,"['em_gflm.py', 'parse_and_model.py', 'test_original_1_background_model.data', 'test_original_1_hidden_background_params_it1.data', 'test_original_1_hidden_background_params_it2.data', 'test_original_1_hidden_params_it1.data', 'test_original_1_hidden_params_it2.data', 'test_original_1_pi_init.data', 'test_original_1_pi_params_it1.data', 'test_original_1_pi_params_it2.data', 'test_original_1_runInfo.data', 'test_original_1_section_word_counts.data', 'test_original_1_topic_model.data', 'test_GFLM.py', 'test_ParseAndModel.py']",['921c3df8925101bbb672b7c67a375d0c797257f3'],37,193,230,15,0.0,0.2116788321167883,0.6715328467153284
9304786d06c775490a4167d883eb68856a694b63,E step tests are passing but there is still a discrepancy in the M step,hwilder3,hwilder3@illinois.edu,hwilder3,hwilder3@illinois.edu,2018-12-09 02:19:23-05:00,18000,2018-12-09 02:19:23-05:00,18000,True,False,['test_EmVectorByFeature.py'],['3887b83b2e6f84d3363ef491fb32335932c924e7'],8,182,190,1,0.0,0.0,1.0
53757a3fb6123a0a7cf658710b7970e6ae467390,"M-Step bug fixed!

Subtracting where I should have been adding",hwilder3,hwilder3@illinois.edu,hwilder3,hwilder3@illinois.edu,2018-12-09 02:32:21-05:00,18000,2018-12-09 02:32:21-05:00,18000,True,False,"['em_vector_by_feature.py', 'test_EmVectorByFeature.py']",['9304786d06c775490a4167d883eb68856a694b63'],71,111,182,2,0.0,0.0,1.0
522d32e85e64c454b8149dbcde84c937f30bd744,Added pi delta tests and working on cleaning up/commenting code,hwilder3,hwilder3@illinois.edu,hwilder3,hwilder3@illinois.edu,2018-12-09 17:48:00-05:00,18000,2018-12-09 17:48:00-05:00,18000,True,False,"['em_base.py', 'em_vector_by_feature.py', 'parse_and_model.py', 'test_original_1_hidden_background_params_it1.data', 'test_original_1_hidden_background_params_it2.data', 'test_original_1_hidden_params_it1.data', 'test_original_1_hidden_params_it2.data', 'test_original_1_pi_init.data', 'test_original_1_pi_params_it1.data', 'test_original_1_pi_params_it2.data', 'test_EmVectorByFeature.py', 'test_ParseAndModel.py']",['53757a3fb6123a0a7cf658710b7970e6ae467390'],341,368,709,12,0.0,0.34615384615384615,1.0
f14b933f1fb5e4864ce690108782005afad0046b,More testing files,hwilder3,hwilder3@illinois.edu,hwilder3,hwilder3@illinois.edu,2018-12-09 17:48:47-05:00,18000,2018-12-09 17:48:47-05:00,18000,True,False,"['test_original_1_gflm_sentence_probs.data', 'test_original_1_gflm_sentence_results.data', 'test_original_1_gflm_word_probs.data', 'test_original_1_gflm_word_results.data', 'test_original_1_pi_delta_it1.data', 'test_original_1_pi_delta_it2.data']",['522d32e85e64c454b8149dbcde84c937f30bd744'],0,2,2,6,,,
d53a0577874e16797b2face5a2f90487d6fc76df,Cleaned up and fully commented em vector by feature file,hwilder3,hwilder3@illinois.edu,hwilder3,hwilder3@illinois.edu,2018-12-09 19:20:01-05:00,18000,2018-12-09 19:20:01-05:00,18000,True,False,"['em_vector_by_feature.py', 'parse_and_model.py']",['f14b933f1fb5e4864ce690108782005afad0046b'],186,71,257,2,1.0,0.9473684210526315,0.0
3db976eaed65e893f026f193f1e978a17545df43,Renaming GFLM,hwilder3,hwilder3@illinois.edu,hwilder3,hwilder3@illinois.edu,2018-12-09 19:46:29-05:00,18000,2018-12-09 19:46:29-05:00,18000,True,False,"['em_vector_by_feature.py', 'gflm_tagger.py', 'test_original_1_gflm_sentence_probs.data', 'test_original_1_gflm_word_probs.data', 'test_original_1_gflm_word_results.data', 'test_original_1_hidden_background_params_it1.data', 'test_original_1_hidden_background_params_it2.data', 'test_original_1_hidden_background_params_it50.data', 'test_original_1_hidden_params_it1.data', 'test_original_1_hidden_params_it2.data', 'test_original_1_hidden_params_it50.data', 'test_original_1_pi_delta_it1.data', 'test_original_1_pi_delta_it2.data', 'test_original_1_pi_delta_it50.data', 'test_original_1_pi_init.data', 'test_original_1_pi_params_it1.data', 'test_original_1_pi_params_it2.data', 'test_original_1_pi_params_it50.data', 'test_EmVectorByFeature.py', 'test_GFLM.py']",['d53a0577874e16797b2face5a2f90487d6fc76df'],30,424,454,20,0.011857707509881422,0.2490118577075099,0.9209486166007905
7a7d6c2f799c4a2ce22734f5799709574d2fe2f1,Deleted old gflm file,hwilder3,hwilder3@illinois.edu,hwilder3,hwilder3@illinois.edu,2018-12-09 19:49:34-05:00,18000,2018-12-09 19:49:34-05:00,18000,True,False,"['em_gflm.py', 'test_GFLM.py']",['3db976eaed65e893f026f193f1e978a17545df43'],117,1,118,2,0.7346938775510204,0.0,0.3877551020408163
99d3e42110f6d0394f547e4db53cd6b13ce57c31,Changed remove stopwords default in build explicit model to True and also altered tests as needed,hwilder3,hwilder3@illinois.edu,hwilder3,hwilder3@illinois.edu,2018-12-09 19:58:23-05:00,18000,2018-12-09 19:58:23-05:00,18000,True,False,"['parse_and_model.py', 'test_EmVectorByFeature.py', 'test_ParseAndModel.py']",['7a7d6c2f799c4a2ce22734f5799709574d2fe2f1'],10,13,23,3,0.0,0.0,1.0
39aaf4f01d081cd8a0904a7013997df9a198dc9d,"Added GFLM tests based on Santu's implementation.

Numerical calculations passing.

Still have to check the tagging - I think there's something off there in the data coming from Santu's copy.",hwilder3,hwilder3@illinois.edu,hwilder3,hwilder3@illinois.edu,2018-12-09 21:26:59-05:00,18000,2018-12-09 21:26:59-05:00,18000,True,False,"['gflm_tagger.py', 'test_original_1_gflm_sentence_probs.data', 'test_original_1_gflm_sentence_results.data', 'test_original_1_gflm_word_probs.data', 'test_original_1_gflm_word_results.data', 'test_original_1_hidden_background_params_it1.data', 'test_original_1_hidden_background_params_it2.data', 'test_original_1_hidden_background_params_it50.data', 'test_original_1_hidden_params_it1.data', 'test_original_1_hidden_params_it2.data', 'test_original_1_hidden_params_it50.data', 'test_original_1_pi_delta_it1.data', 'test_original_1_pi_delta_it2.data', 'test_original_1_pi_delta_it50.data', 'test_original_1_pi_init.data', 'test_original_1_pi_params_it1.data', 'test_original_1_pi_params_it2.data', 'test_original_1_pi_params_it50.data', 'test_EmVectorByFeature.py', 'test_GFLM.py']",['99d3e42110f6d0394f547e4db53cd6b13ce57c31'],151,145,296,20,1.0,1.0,0.0
940a73a95a874ac06c1dded935db93e5a958380c,"Added a new data reading method that can read plain data formatted as one doc per line.

Includes simple sentence parsing.

Added the argument in the parse and model constructor to handle it and some test cases to make sure it's working.",hwilder3,hwilder3@illinois.edu,hwilder3,hwilder3@illinois.edu,2018-12-09 22:12:19-05:00,18000,2018-12-09 22:12:19-05:00,18000,True,False,"['parse_and_model.py', 'oneLinePerDoc.txt', 'test_ParseAndModel.py']",['39aaf4f01d081cd8a0904a7013997df9a198dc9d'],143,90,233,3,1.0,0.1,1.0
a7afc1ae95ba0c96032e2248236323926b93801e,"Nfr (#18)

* H - test commit

* H test commit 2

* Still trying to figure out how to commit.

* Testing commit from local

* Updated project structure and .gitignore

* Testing commit from PyCharm

* Project code tests - Spacy (finally) successfully loaded

* Project code tests - sentence tokenizing and some basic counting

* Working counts on sample document set 1

* Adding sample data and sample background/topic models and sentence counts for testing, will clean up code and add unit tests, but seems to be working for the moment.

* Adding sample data and sample background/topic models and sentence counts for testing, will clean up code and add unit tests, but seems to be working for the moment.

* Trying to get Pycharm and GitHub to play nice.

* Topic model building converted to function format and documented (now callable with three required data frames)

Still need to add test cases and separate this code off into a permanent file

* Rewrote Santu_s original e-step and added tests.

* Vectorized E-Step. HP compute still to be validated. Chain to be validated.

* Transform existing data in matrices. Commit before major update of vectorised e-step

* Problem with huge matrices. Freeze this as is, then start the fix.

* E-Step sparse matrix implementation for one sentence.

* Created class structure for EM. Migrated EM_E Original to em_original.

* Created class structure for EM. Migrated EM_E Original to em_original.

* Created class structure for EM. Migrated EM_E Original to em_original. Added em_base

* Updated methods structure for em_vector. Updated test_advanced for em_original. Minor cleaning.

* Implement em_vector e_step.

* Update .gitignore with .idea

* Updated real tests for em_vector. First review OK in e_step.

* Added two functions:
format_feature_list - takes in a nested list and returns a data frame with ids for each feature

read_annotated_data - reads in Santu's annotated input files, returns DataFrames with the annotation information as well as a somewhat cleaned set of section text, including ids - can be passed into the build_models function

* Work in progress for background parameters.

* E-step background parameters OK (for one sentence).

* Deleted obsolete em.py.

* Renamed nw in v

* Renamed na in f

* Renamed all aspects to features

* Added specific test classes for EM Original and Vector

* Deleted unused tests from test_advanced file.

* Recommitting - didn't get contents of parse_and_model the first time for some reason

Cleaned up code (renamed based on agreed upon collection > document > section > word naming convention)

Moved into separate file

Still to do:
 - Performance issues in model building function, need to investigate and fix
 - Reformat version of output for model building into matrices to be passed off to EM

* Now included -

Formatting for EM as specified in em_vector.

Note: performance on build_explicit_models is crappy so that's going to need some more work, but it should work for testing EM for the moment.

Also cleaned up readFiles_test, not quite ready to be deleted yet, but it will be eventually.

* Updated cost and test.

* Update test files.

* Added test skeletons for parse_and_model. Test for test_format_feature_list.

* Code from pull request #9 merged into branch.

Wrote tests for feature_list and read_annotated_data.

build_explicit_models still to go.

Found the slow spot in build_explicit_models - the nlp call is to blame. I will try swapping it out with either nltk or metapy to see if I can get better performance.

Also added a ""main"" as requested.

* Compute m_step 1 sentence, vectorized. Added tests for new methods.

* Start minor optimization.

* Start minor optimization - slight improvement.

* Update all for passing over e-m code.

* Comments from Pull Request #8 have been addressed, including the following:

- Swapped to dense arrays for the return, although not sure those conversions are currently in the optimal place
- section_word_counts has been removed
- renamed all ""array"" variable names to ""matrix"" (at least I think I got all of them)
- main function added

Also -
- bug in lemmatization flag for build_explicit_models found in testing and fixed, currently defaulting to true, but we could easily change that
- basic unit tests for build_explicit_models added but it will probably need some more, I can add them later, they're just a lot of work per test to do the calculations by hand and get them formatted correctly

Known Issues:
- inconsistency in list types being used for counting (need to decided whether to go with Counter or defaultdict and stick with it)
- severe performance issues in build_explicit_models being caused by call to NLP, suggest trying an implementation with metapy or NLTK

* Used the v1 vectorization implementation as a base and made the following modifications:

- Rearranged looping to be over features instead of sections - results in many fewer loops in most cases

- Pulled a few repetitive steps out of the looping:
	- In E-step, numerator for background hidden parameters is calculated only once as part of initialization (doesn't change throughout optimization)
	- In M-step, c(w,s)*(1-P(z_sw = B)) is calculated only once at beginning of step since it is not depended on the feature

- Using power vectorized function instead of replacing zeros with 1's in E-step, allows us to keep that division in a sparse matrix

- Changed review binary calculation in intialization to

Also added some test logic in import data to use existing parse and model methods, still need to determine best way to integrate those - add in call to constructor? Or make part of class?

Need to make the following changes to parse_and_model:
	- Topic model should be dense array, not sparse

Still need to write some tests also

* Created class wrapper around parse_and_model.

* Improved execution speed for parse_and_model

* Renamed em vector by feature

* Removing extra em_vector_v2 file

* Optimize test for 12 cores; added timing, merged Hannah branch.

* Fixed bug in M-step causing divide by zero error

Added some diagnostic print statements to EM

Reorganized ParseAndModel constructor so that it can handle all three steps given the correct arguments

Copied over the test cases for EM feature - still need to do hand calculations to get test cases

* Added prototype file lines parser, still needs the sentence tokenizer but nltk has a ton of options - potentially try Spacy and see if it's going to be too slow here

* Reorganized Parse and Model code back to Object Oriented format, fixed all the unit tests.

* Added constructor test for parse and model

Fixed model feature matrix to be dense array as it should be

Adjusted em feature to use new constructor

Em feature test skeleton is alive, still needs actual tests

* Added additional parse and model test files

* Commented TODO. Updated main to run on current configuration.

* Updated testing project. Step1

* Renamed Original and Vector tests

* Renamed test class to avoid duplication and added setUp and tearDown methods.

* Start pypi creation

* Created upload to pypi script.

* Preliminary implementation of GFLM-word and GFLM-sentence.

Still needs unit tests written.

* Updated members in GFLM, comments and main.

* Merge branches 'hannah' and 'nfr' of https://github.com/nfreundlich/CS410_CourseProject into nfr

# Conflicts:
#	feature_mining/em_vector_by_feature.py
#	tests/test_expectationMaximizationOriginal.py
#	tests/test_expectationMaximizationVector_feature.py",nfreundlich,norbiein@gmail.com,hewilder,hewample@mtu.edu,2018-12-10 04:13:59+01:00,-3600,2018-12-09 22:13:59-05:00,18000,True,False,"['em_vector_by_feature.py', 'test_EmVectorByFeature.py', 'test_ExpectationMaximizationOriginal.py', 'test_ExpectationMaximizationVector.py', 'test_advanced.py', 'test_basic.py', 'test_expectationMaximizationOriginal.py', 'test_expectationMaximizationVector_feature.py']",['acd6264885b2feb5583d2bfba26170e01322a0d1'],127,55,182,8,0.0,0.0,0.08
1517fe3ce7476982d2c96d78d5ebfe2ac260e87d,"Merge branches 'hannah' and 'nfr' of https://github.com/nfreundlich/CS410_CourseProject into nfr

# Conflicts:
#	feature_mining/em_vector_by_feature.py
#	tests/test_expectationMaximizationOriginal.py
#	tests/test_expectationMaximizationVector_feature.py",nfreundlich,norbert4@illinois.edu,nfreundlich,norbert4@illinois.edu,2018-12-10 11:58:21+01:00,-3600,2018-12-10 11:58:21+01:00,-3600,True,False,"['em_vector_by_feature.py', 'parse_and_model.py', 'requirements.txt', 'test_ParseAndModel.py']",['34981307714385792f9294d8fe0a379421ab3107'],43,49,92,4,0.0,0.0,0.0
1fc55604904bc4a4831af09ea981b0cc43373b6c,"Weekend Work (#20)

* H - test commit

* H test commit 2

* Still trying to figure out how to commit.

* Testing commit from local

* Updated project structure and .gitignore

* Testing commit from PyCharm

* Project code tests - Spacy (finally) successfully loaded

* Project code tests - sentence tokenizing and some basic counting

* Working counts on sample document set 1

* Adding sample data and sample background/topic models and sentence counts for testing, will clean up code and add unit tests, but seems to be working for the moment.

* Adding sample data and sample background/topic models and sentence counts for testing, will clean up code and add unit tests, but seems to be working for the moment.

* Trying to get Pycharm and GitHub to play nice.

* Topic model building converted to function format and documented (now callable with three required data frames)

Still need to add test cases and separate this code off into a permanent file

* Rewrote Santu_s original e-step and added tests.

* Vectorized E-Step. HP compute still to be validated. Chain to be validated.

* Transform existing data in matrices. Commit before major update of vectorised e-step

* Problem with huge matrices. Freeze this as is, then start the fix.

* E-Step sparse matrix implementation for one sentence.

* Created class structure for EM. Migrated EM_E Original to em_original.

* Created class structure for EM. Migrated EM_E Original to em_original.

* Created class structure for EM. Migrated EM_E Original to em_original. Added em_base

* Updated methods structure for em_vector. Updated test_advanced for em_original. Minor cleaning.

* Implement em_vector e_step.

* Update .gitignore with .idea

* Updated real tests for em_vector. First review OK in e_step.

* Added two functions:
format_feature_list - takes in a nested list and returns a data frame with ids for each feature

read_annotated_data - reads in Santu's annotated input files, returns DataFrames with the annotation information as well as a somewhat cleaned set of section text, including ids - can be passed into the build_models function

* Work in progress for background parameters.

* E-step background parameters OK (for one sentence).

* Deleted obsolete em.py.

* Renamed nw in v

* Renamed na in f

* Renamed all aspects to features

* Added specific test classes for EM Original and Vector

* Deleted unused tests from test_advanced file.

* Recommitting - didn't get contents of parse_and_model the first time for some reason

Cleaned up code (renamed based on agreed upon collection > document > section > word naming convention)

Moved into separate file

Still to do:
 - Performance issues in model building function, need to investigate and fix
 - Reformat version of output for model building into matrices to be passed off to EM

* Now included -

Formatting for EM as specified in em_vector.

Note: performance on build_explicit_models is crappy so that's going to need some more work, but it should work for testing EM for the moment.

Also cleaned up readFiles_test, not quite ready to be deleted yet, but it will be eventually.

* Updated cost and test.

* Update test files.

* Added test skeletons for parse_and_model. Test for test_format_feature_list.

* Code from pull request #9 merged into branch.

Wrote tests for feature_list and read_annotated_data.

build_explicit_models still to go.

Found the slow spot in build_explicit_models - the nlp call is to blame. I will try swapping it out with either nltk or metapy to see if I can get better performance.

Also added a ""main"" as requested.

* Compute m_step 1 sentence, vectorized. Added tests for new methods.

* Start minor optimization.

* Start minor optimization - slight improvement.

* Update all for passing over e-m code.

* Comments from Pull Request #8 have been addressed, including the following:

- Swapped to dense arrays for the return, although not sure those conversions are currently in the optimal place
- section_word_counts has been removed
- renamed all ""array"" variable names to ""matrix"" (at least I think I got all of them)
- main function added

Also -
- bug in lemmatization flag for build_explicit_models found in testing and fixed, currently defaulting to true, but we could easily change that
- basic unit tests for build_explicit_models added but it will probably need some more, I can add them later, they're just a lot of work per test to do the calculations by hand and get them formatted correctly

Known Issues:
- inconsistency in list types being used for counting (need to decided whether to go with Counter or defaultdict and stick with it)
- severe performance issues in build_explicit_models being caused by call to NLP, suggest trying an implementation with metapy or NLTK

* Used the v1 vectorization implementation as a base and made the following modifications:

- Rearranged looping to be over features instead of sections - results in many fewer loops in most cases

- Pulled a few repetitive steps out of the looping:
	- In E-step, numerator for background hidden parameters is calculated only once as part of initialization (doesn't change throughout optimization)
	- In M-step, c(w,s)*(1-P(z_sw = B)) is calculated only once at beginning of step since it is not depended on the feature

- Using power vectorized function instead of replacing zeros with 1's in E-step, allows us to keep that division in a sparse matrix

- Changed review binary calculation in intialization to

Also added some test logic in import data to use existing parse and model methods, still need to determine best way to integrate those - add in call to constructor? Or make part of class?

Need to make the following changes to parse_and_model:
	- Topic model should be dense array, not sparse

Still need to write some tests also

* Created class wrapper around parse_and_model.

* Improved execution speed for parse_and_model

* Renamed em vector by feature

* Removing extra em_vector_v2 file

* Optimize test for 12 cores; added timing, merged Hannah branch.

* Fixed bug in M-step causing divide by zero error

Added some diagnostic print statements to EM

Reorganized ParseAndModel constructor so that it can handle all three steps given the correct arguments

Copied over the test cases for EM feature - still need to do hand calculations to get test cases

* Added prototype file lines parser, still needs the sentence tokenizer but nltk has a ton of options - potentially try Spacy and see if it's going to be too slow here

* Reorganized Parse and Model code back to Object Oriented format, fixed all the unit tests.

* Added constructor test for parse and model

Fixed model feature matrix to be dense array as it should be

Adjusted em feature to use new constructor

Em feature test skeleton is alive, still needs actual tests

* Added additional parse and model test files

* Commented TODO. Updated main to run on current configuration.

* Updated testing project. Step1

* Renamed Original and Vector tests

* Renamed test class to avoid duplication and added setUp and tearDown methods.

* Start pypi creation

* Created upload to pypi script.

* Preliminary implementation of GFLM-word and GFLM-sentence.

Still needs unit tests written.

* Updated members in GFLM, comments and main.

* Merge branches 'hannah' and 'nfr' of https://github.com/nfreundlich/CS410_CourseProject into nfr

# Conflicts:
#	feature_mining/em_vector_by_feature.py
#	tests/test_expectationMaximizationOriginal.py
#	tests/test_expectationMaximizationVector_feature.py

* Checking that commits still go through okay

* Added additional testing to compare directly against results of original code

Main bug found so far in original code was that titles were getting counted in word and section counts but were not included in the actual models

Found in new code - switched code to default to ln instead of log 2 by default to match old implementation. Confirmed correct calculation of word feature counts (one per occurrence, not one per section) and switched that accordingly.

Trying to get all the way through EM with a single set of results and then will add additional test cases.

* E step tests are passing but there is still a discrepancy in the M step

* M-Step bug fixed!

Subtracting where I should have been adding

* Added pi delta tests and working on cleaning up/commenting code

* More testing files

* Cleaned up and fully commented em vector by feature file

* Renaming GFLM

* Deleted old gflm file

* Changed remove stopwords default in build explicit model to True and also altered tests as needed

* Added GFLM tests based on Santu's implementation.

Numerical calculations passing.

Still have to check the tagging - I think there's something off there in the data coming from Santu's copy.

* Added a new data reading method that can read plain data formatted as one doc per line.

Includes simple sentence parsing.

Added the argument in the parse and model constructor to handle it and some test cases to make sure it's working.

* Merge branches 'hannah' and 'nfr' of https://github.com/nfreundlich/CS410_CourseProject into nfr

# Conflicts:
#	feature_mining/em_vector_by_feature.py
#	tests/test_expectationMaximizationOriginal.py
#	tests/test_expectationMaximizationVector_feature.py",hewilder,hewample@mtu.edu,nfreundlich,norbiein@gmail.com,2018-12-10 06:02:18-05:00,18000,2018-12-10 12:02:18+01:00,-3600,True,False,"['em_base.py', 'em_vector_by_feature.py', 'gflm_tagger.py', 'parse_and_model.py', 'requirements.txt', 'oneLinePerDoc.txt', 'test_original_1_background_model.data', 'test_original_1_gflm_sentence_probs.data', 'test_original_1_gflm_sentence_results.data', 'test_original_1_gflm_word_probs.data', 'test_original_1_gflm_word_results.data', 'test_original_1_hidden_background_params_it1.data', 'test_original_1_hidden_background_params_it2.data', 'test_original_1_hidden_background_params_it50.data', 'test_original_1_hidden_params_it1.data', 'test_original_1_hidden_params_it2.data', 'test_original_1_hidden_params_it50.data', 'test_original_1_pi_delta_it1.data', 'test_original_1_pi_delta_it2.data', 'test_original_1_pi_delta_it50.data', 'test_original_1_pi_init.data', 'test_original_1_pi_params_it1.data', 'test_original_1_pi_params_it2.data', 'test_original_1_pi_params_it50.data', 'test_original_1_runInfo.data', 'test_original_1_section_word_counts.data', 'test_original_1_topic_model.data', 'test_EmVectorByFeature.py', 'test_GFLM.py', 'test_ParseAndModel.py']",['a7afc1ae95ba0c96032e2248236323926b93801e'],593,1105,1698,30,0.0,0.02564102564102564,1.0
bad3eb11fec32bb85ff2447ab375da6da399c4ed,Updated setup.py. Dynamic download of spacy en model.,nfreundlich,norbert4@illinois.edu,nfreundlich,norbert4@illinois.edu,2018-12-10 15:07:13+01:00,-3600,2018-12-10 15:07:13+01:00,-3600,True,False,"['README.md', 'parse_and_model.py', 'requirements.txt', 'setup.py']",['1517fe3ce7476982d2c96d78d5ebfe2ac260e87d'],9,49,58,4,,,
bf3243f2bd998b49de53a168e3c86da3a8d009ed,Additional spacy lang import if first failed.,nfreundlich,norbert4@illinois.edu,nfreundlich,norbert4@illinois.edu,2018-12-10 15:31:41+01:00,-3600,2018-12-10 15:31:41+01:00,-3600,True,False,"['parse_and_model.py', 'setup.py']",['bad3eb11fec32bb85ff2447ab375da6da399c4ed'],1,6,7,2,,,
47f491ebe81506492f83558521506e50a1ec920e,Created the tutorial. Minor updates throughout the package.,nfreundlich,norbert4@illinois.edu,nfreundlich,norbert4@illinois.edu,2018-12-10 18:05:42+01:00,-3600,2018-12-10 18:05:42+01:00,-3600,True,False,"['__init__.py', 'em_base.py', 'em_vector_by_feature.py', 'parse_and_model.py', 'setup.py', 'tutorial.ipynb']",['bf3243f2bd998b49de53a168e3c86da3a8d009ed'],10,264,274,6,0.3333333333333333,1.0,0.5
b40d273465d11f73ba732cce8c719358f2d0aa35,Update tutorial and package __init__.py,nfreundlich,norbert4@illinois.edu,nfreundlich,norbert4@illinois.edu,2018-12-10 19:04:54+01:00,-3600,2018-12-10 19:04:54+01:00,-3600,True,False,"['__init__.py', 'gflm_tagger.py', 'setup.py', 'tutorial.ipynb']",['47f491ebe81506492f83558521506e50a1ec920e'],44,227,271,4,0.0,1.0,0.0
6b61301a6d141f56df0a22b0b63fe5a69ae9c5bf,Intermediate work for saving data with the package.,nfreundlich,norbert4@illinois.edu,nfreundlich,norbert4@illinois.edu,2018-12-11 12:12:56+01:00,-3600,2018-12-11 12:12:56+01:00,-3600,True,False,"['__init__.py', 'iPod.final', 'em_base.py', 'fm.py', 'parse_and_model.py', 'setup.py']",['b40d273465d11f73ba732cce8c719358f2d0aa35'],10,10498,10508,6,0.734375,0.984375,0.671875
ca3c552ac193604ac738156c78394fdd99757dbb,Working package upload with data files!,nfreundlich,norbert4@illinois.edu,nfreundlich,norbert4@illinois.edu,2018-12-11 12:24:51+01:00,-3600,2018-12-11 12:24:51+01:00,-3600,True,False,"['fm.py', 'setup.py']",['6b61301a6d141f56df0a22b0b63fe5a69ae9c5bf'],6,16,22,2,,,
6c26c2c1162b4ed130ac36a674c9a028b79a4486,Updated tutorial and readme.md file,nfreundlich,norbert4@illinois.edu,nfreundlich,norbert4@illinois.edu,2018-12-11 13:22:13+01:00,-3600,2018-12-11 13:22:13+01:00,-3600,True,False,"['README.md', 'fm.py', 'setup.py', 'tutorial.ipynb']",['ca3c552ac193604ac738156c78394fdd99757dbb'],199,261,460,4,,,
85320b47a1779ccd8e13d6b6b3e862d905681388,Update gitignore for ipynb,nfreundlich,norbert4@illinois.edu,nfreundlich,norbert4@illinois.edu,2018-12-11 13:23:09+01:00,-3600,2018-12-11 13:23:09+01:00,-3600,True,False,['.gitignore'],['6c26c2c1162b4ed130ac36a674c9a028b79a4486'],0,1,1,1,,,
30477af3bda3482f1bbda83c87f62385ac35cdcc,Added params to wrapper,nfreundlich,norbert4@illinois.edu,nfreundlich,norbert4@illinois.edu,2018-12-11 23:00:52+01:00,-3600,2018-12-11 23:00:52+01:00,-3600,True,False,"['em_vector_by_feature.py', 'fm.py', 'tutorial.ipynb']",['85320b47a1779ccd8e13d6b6b3e862d905681388'],37,35,72,3,0.0,1.0,0.0
c3fc00312fdf498985f838123011928216d7466e,"Nfr (#21)

* H - test commit

* H test commit 2

* Still trying to figure out how to commit.

* Testing commit from local

* Updated project structure and .gitignore

* Testing commit from PyCharm

* Project code tests - Spacy (finally) successfully loaded

* Project code tests - sentence tokenizing and some basic counting

* Working counts on sample document set 1

* Adding sample data and sample background/topic models and sentence counts for testing, will clean up code and add unit tests, but seems to be working for the moment.

* Adding sample data and sample background/topic models and sentence counts for testing, will clean up code and add unit tests, but seems to be working for the moment.

* Trying to get Pycharm and GitHub to play nice.

* Topic model building converted to function format and documented (now callable with three required data frames)

Still need to add test cases and separate this code off into a permanent file

* Rewrote Santu_s original e-step and added tests.

* Vectorized E-Step. HP compute still to be validated. Chain to be validated.

* Transform existing data in matrices. Commit before major update of vectorised e-step

* Problem with huge matrices. Freeze this as is, then start the fix.

* E-Step sparse matrix implementation for one sentence.

* Created class structure for EM. Migrated EM_E Original to em_original.

* Created class structure for EM. Migrated EM_E Original to em_original.

* Created class structure for EM. Migrated EM_E Original to em_original. Added em_base

* Updated methods structure for em_vector. Updated test_advanced for em_original. Minor cleaning.

* Implement em_vector e_step.

* Update .gitignore with .idea

* Updated real tests for em_vector. First review OK in e_step.

* Added two functions:
format_feature_list - takes in a nested list and returns a data frame with ids for each feature

read_annotated_data - reads in Santu's annotated input files, returns DataFrames with the annotation information as well as a somewhat cleaned set of section text, including ids - can be passed into the build_models function

* Work in progress for background parameters.

* E-step background parameters OK (for one sentence).

* Deleted obsolete em.py.

* Renamed nw in v

* Renamed na in f

* Renamed all aspects to features

* Added specific test classes for EM Original and Vector

* Deleted unused tests from test_advanced file.

* Recommitting - didn't get contents of parse_and_model the first time for some reason

Cleaned up code (renamed based on agreed upon collection > document > section > word naming convention)

Moved into separate file

Still to do:
 - Performance issues in model building function, need to investigate and fix
 - Reformat version of output for model building into matrices to be passed off to EM

* Now included -

Formatting for EM as specified in em_vector.

Note: performance on build_explicit_models is crappy so that's going to need some more work, but it should work for testing EM for the moment.

Also cleaned up readFiles_test, not quite ready to be deleted yet, but it will be eventually.

* Updated cost and test.

* Update test files.

* Added test skeletons for parse_and_model. Test for test_format_feature_list.

* Code from pull request #9 merged into branch.

Wrote tests for feature_list and read_annotated_data.

build_explicit_models still to go.

Found the slow spot in build_explicit_models - the nlp call is to blame. I will try swapping it out with either nltk or metapy to see if I can get better performance.

Also added a ""main"" as requested.

* Compute m_step 1 sentence, vectorized. Added tests for new methods.

* Start minor optimization.

* Start minor optimization - slight improvement.

* Update all for passing over e-m code.

* Comments from Pull Request #8 have been addressed, including the following:

- Swapped to dense arrays for the return, although not sure those conversions are currently in the optimal place
- section_word_counts has been removed
- renamed all ""array"" variable names to ""matrix"" (at least I think I got all of them)
- main function added

Also -
- bug in lemmatization flag for build_explicit_models found in testing and fixed, currently defaulting to true, but we could easily change that
- basic unit tests for build_explicit_models added but it will probably need some more, I can add them later, they're just a lot of work per test to do the calculations by hand and get them formatted correctly

Known Issues:
- inconsistency in list types being used for counting (need to decided whether to go with Counter or defaultdict and stick with it)
- severe performance issues in build_explicit_models being caused by call to NLP, suggest trying an implementation with metapy or NLTK

* Used the v1 vectorization implementation as a base and made the following modifications:

- Rearranged looping to be over features instead of sections - results in many fewer loops in most cases

- Pulled a few repetitive steps out of the looping:
	- In E-step, numerator for background hidden parameters is calculated only once as part of initialization (doesn't change throughout optimization)
	- In M-step, c(w,s)*(1-P(z_sw = B)) is calculated only once at beginning of step since it is not depended on the feature

- Using power vectorized function instead of replacing zeros with 1's in E-step, allows us to keep that division in a sparse matrix

- Changed review binary calculation in intialization to

Also added some test logic in import data to use existing parse and model methods, still need to determine best way to integrate those - add in call to constructor? Or make part of class?

Need to make the following changes to parse_and_model:
	- Topic model should be dense array, not sparse

Still need to write some tests also

* Created class wrapper around parse_and_model.

* Improved execution speed for parse_and_model

* Renamed em vector by feature

* Removing extra em_vector_v2 file

* Optimize test for 12 cores; added timing, merged Hannah branch.

* Fixed bug in M-step causing divide by zero error

Added some diagnostic print statements to EM

Reorganized ParseAndModel constructor so that it can handle all three steps given the correct arguments

Copied over the test cases for EM feature - still need to do hand calculations to get test cases

* Added prototype file lines parser, still needs the sentence tokenizer but nltk has a ton of options - potentially try Spacy and see if it's going to be too slow here

* Reorganized Parse and Model code back to Object Oriented format, fixed all the unit tests.

* Added constructor test for parse and model

Fixed model feature matrix to be dense array as it should be

Adjusted em feature to use new constructor

Em feature test skeleton is alive, still needs actual tests

* Added additional parse and model test files

* Commented TODO. Updated main to run on current configuration.

* Updated testing project. Step1

* Renamed Original and Vector tests

* Renamed test class to avoid duplication and added setUp and tearDown methods.

* Start pypi creation

* Created upload to pypi script.

* Preliminary implementation of GFLM-word and GFLM-sentence.

Still needs unit tests written.

* Updated members in GFLM, comments and main.

* Merge branches 'hannah' and 'nfr' of https://github.com/nfreundlich/CS410_CourseProject into nfr

# Conflicts:
#	feature_mining/em_vector_by_feature.py
#	tests/test_expectationMaximizationOriginal.py
#	tests/test_expectationMaximizationVector_feature.py

* Checking that commits still go through okay

* Added additional testing to compare directly against results of original code

Main bug found so far in original code was that titles were getting counted in word and section counts but were not included in the actual models

Found in new code - switched code to default to ln instead of log 2 by default to match old implementation. Confirmed correct calculation of word feature counts (one per occurrence, not one per section) and switched that accordingly.

Trying to get all the way through EM with a single set of results and then will add additional test cases.

* E step tests are passing but there is still a discrepancy in the M step

* M-Step bug fixed!

Subtracting where I should have been adding

* Added pi delta tests and working on cleaning up/commenting code

* More testing files

* Cleaned up and fully commented em vector by feature file

* Renaming GFLM

* Deleted old gflm file

* Changed remove stopwords default in build explicit model to True and also altered tests as needed

* Added GFLM tests based on Santu's implementation.

Numerical calculations passing.

Still have to check the tagging - I think there's something off there in the data coming from Santu's copy.

* Added a new data reading method that can read plain data formatted as one doc per line.

Includes simple sentence parsing.

Added the argument in the parse and model constructor to handle it and some test cases to make sure it's working.

* Merge branches 'hannah' and 'nfr' of https://github.com/nfreundlich/CS410_CourseProject into nfr

# Conflicts:
#	feature_mining/em_vector_by_feature.py
#	tests/test_expectationMaximizationOriginal.py
#	tests/test_expectationMaximizationVector_feature.py

* Updated setup.py. Dynamic download of spacy en model.

* Additional spacy lang import if first failed.

* Created the tutorial. Minor updates throughout the package.

* Update tutorial and package __init__.py

* Intermediate work for saving data with the package.

* Working package upload with data files!

* Updated tutorial and readme.md file

* Update gitignore for ipynb

* Added params to wrapper",nfreundlich,norbiein@gmail.com,hewilder,hewample@mtu.edu,2018-12-11 23:42:32+01:00,-3600,2018-12-11 17:42:32-05:00,18000,True,False,"['.gitignore', 'README.md', '__init__.py', 'iPod.final', 'em_base.py', 'em_vector_by_feature.py', 'fm.py', 'gflm_tagger.py', 'parse_and_model.py', 'requirements.txt', 'setup.py', 'tutorial.ipynb']",['1fc55604904bc4a4831af09ea981b0cc43373b6c'],33,11074,11107,12,0.45454545454545453,0.987012987012987,0.5194805194805194
633b603e48bfee9e2c046547f109706bf59f398a,Adding HTML pydoc files,hwilder3,hwilder3@illinois.edu,hwilder3,hwilder3@illinois.edu,2018-12-11 22:26:23-05:00,18000,2018-12-11 22:26:23-05:00,18000,True,False,"['feature_mining.em_base.html', 'feature_mining.em_original.html', 'feature_mining.em_vector.html', 'feature_mining.em_vector_by_feature.html', 'feature_mining.gflm_tagger.html', 'feature_mining.html', 'feature_mining.parse_and_model.html', 'tests.context.html', 'tests.html', 'tests.test_EmVectorByFeature.html', 'tests.test_ExpectationMaximizationVector.html', 'tests.test_GFLM.html', 'tests.test_ParseAndModel.html', 'tests.test_advanced.html', 'tests.test_expectationMaximizationOriginal.html']",['1517fe3ce7476982d2c96d78d5ebfe2ac260e87d'],0,3348,3348,15,,,
edab6d8f94fbaa5c6e6243098c57856c15aae436,"Adding links

Added temp links to pydocs and Jupyter notebook but should probably be updated when moved to master - they're pointing to branch specific locations at the moment.",hewilder,hwilder3@illinois.edu,GitHub,noreply@github.com,2018-12-11 22:35:53-05:00,18000,2018-12-11 22:35:53-05:00,18000,True,False,['README.md'],['c3fc00312fdf498985f838123011928216d7466e'],1,7,8,1,,,
6ac3b3e59fc0a3f4541a63f8e1358805dafcbc35,Merge,nfreundlich,norbert4@illinois.edu,nfreundlich,norbert4@illinois.edu,2018-12-12 10:11:29+01:00,-3600,2018-12-12 10:11:29+01:00,-3600,True,False,"['README.md', 'feature_mining.em_base.html', 'feature_mining.em_original.html', 'feature_mining.em_vector.html', 'feature_mining.em_vector_by_feature.html', 'feature_mining.gflm_tagger.html', 'feature_mining.html', 'feature_mining.parse_and_model.html', 'tests.context.html', 'tests.html', 'tests.test_EmVectorByFeature.html', 'tests.test_ExpectationMaximizationVector.html', 'tests.test_GFLM.html', 'tests.test_ParseAndModel.html', 'tests.test_advanced.html', 'tests.test_expectationMaximizationOriginal.html']",['30477af3bda3482f1bbda83c87f62385ac35cdcc'],1,3355,3356,16,,,
4956ed74f301bbf1a76fb7b105794b31a1f16cf9,Added joins. To be checked,nfreundlich,norbert4@illinois.edu,nfreundlich,norbert4@illinois.edu,2018-12-12 12:26:48+01:00,-3600,2018-12-12 12:26:48+01:00,-3600,True,False,['fm.py'],['7cff3a8b58da6030ea4a140203482154b60832bd'],1,49,50,1,0.0,1.0,1.0
c4c809dc86f71b80e743ad74f04e55b08296b980,Minor update to docs.,nfreundlich,norbert4@illinois.edu,nfreundlich,norbert4@illinois.edu,2018-12-12 13:10:31+01:00,-3600,2018-12-12 13:10:31+01:00,-3600,True,False,['readme.md'],['4956ed74f301bbf1a76fb7b105794b31a1f16cf9'],2,5,7,1,,,
39f7a306bf5ff268a88993a8e030a362563119f6,Update fm for results printing.,nfreundlich,norbert4@illinois.edu,nfreundlich,norbert4@illinois.edu,2018-12-12 14:47:29+01:00,-3600,2018-12-12 14:47:29+01:00,-3600,True,False,"['fm.py', 'tutorial.ipynb']",['c4c809dc86f71b80e743ad74f04e55b08296b980'],46,71,117,2,1.0,0.0,0.0
71723acdbb71184717078b9d3cb1988e1c82b4b8,"Nfr (#23)

* Updated setup.py. Dynamic download of spacy en model.

* Additional spacy lang import if first failed.

* Created the tutorial. Minor updates throughout the package.

* Update tutorial and package __init__.py

* Intermediate work for saving data with the package.

* Working package upload with data files!

* Updated tutorial and readme.md file

* Update gitignore for ipynb

* Added params to wrapper

* Merge

* Added joins. To be checked

* Minor update to docs.

* Update fm for results printing.",nfreundlich,norbiein@gmail.com,hewilder,hewample@mtu.edu,2018-12-12 15:04:49+01:00,-3600,2018-12-12 09:04:49-05:00,18000,True,False,"['readme.md', 'fm.py', 'tutorial.ipynb']",['9bab1fbd98e223ff9e2bb2d6be182d097e3c5181'],30,106,136,3,0.0,1.0,1.0
b32bdbe21177a5f7198f2d752f1140f9bf222e3c,Update for deploy and tutorial.,nfreundlich,norbert4@illinois.edu,nfreundlich,norbert4@illinois.edu,2018-12-12 16:28:54+01:00,-3600,2018-12-12 16:28:54+01:00,-3600,True,False,"['fm.py', 'setup.py', 'tutorial.ipynb']",['39f7a306bf5ff268a88993a8e030a362563119f6'],195,80,275,3,1.0,0.0,0.0
4753ffbf9331afcbaced2954d4355018927ccbd7,"Nfr (#24)

* Updated setup.py. Dynamic download of spacy en model.

* Additional spacy lang import if first failed.

* Created the tutorial. Minor updates throughout the package.

* Update tutorial and package __init__.py

* Intermediate work for saving data with the package.

* Working package upload with data files!

* Updated tutorial and readme.md file

* Update gitignore for ipynb

* Added params to wrapper

* Merge

* Added joins. To be checked

* Minor update to docs.

* Update fm for results printing.

* Update for deploy and tutorial.",nfreundlich,norbiein@gmail.com,hewilder,hewample@mtu.edu,2018-12-12 19:54:03+01:00,-3600,2018-12-12 13:54:03-05:00,18000,True,False,"['README.md', 'fm.py', 'setup.py', 'tutorial.ipynb']",['71723acdbb71184717078b9d3cb1988e1c82b4b8'],196,85,281,4,1.0,0.0,0.0
57d5e4f6830c9ed7cb05ed6dd69048ced0ceb9db,Update README with slides link,hewilder,hwilder3@illinois.edu,GitHub,noreply@github.com,2018-12-12 21:47:37-05:00,18000,2018-12-12 21:47:37-05:00,18000,True,False,['README.md'],['4753ffbf9331afcbaced2954d4355018927ccbd7'],0,3,3,1,,,
803bdbb19f344b70962e93de8772ea63f0e126ea,Updated with dev copy of pydoc link,hewilder,hwilder3@illinois.edu,GitHub,noreply@github.com,2018-12-12 21:49:53-05:00,18000,2018-12-12 21:49:53-05:00,18000,True,False,['README.md'],['57d5e4f6830c9ed7cb05ed6dd69048ced0ceb9db'],1,2,3,1,,,
7e5217266079c8a5c4fc2ffbc860ee9d25c85a8d,Formatting change,hewilder,hwilder3@illinois.edu,GitHub,noreply@github.com,2018-12-12 21:50:19-05:00,18000,2018-12-12 21:50:19-05:00,18000,True,False,['README.md'],['803bdbb19f344b70962e93de8772ea63f0e126ea'],0,1,1,1,,,
7db7fa7e9a447cbf80061e769de453fcebbc2628,Added pdf slides and updated readme,nfreundlich,norbert4@illinois.edu,nfreundlich,norbert4@illinois.edu,2018-12-13 11:28:24+01:00,-3600,2018-12-13 11:28:24+01:00,-3600,True,False,"['README.md', 'CS_410_GFLM_Slides.pdf']",['dc83eba0ccfae3eec4b62a9a68b8a745093d5c89'],0,6,6,2,,,
07ffddc632668dc36b2ab5cc901c5a7d27e677a5,Update pdf slides link,nfreundlich,norbert4@illinois.edu,nfreundlich,norbert4@illinois.edu,2018-12-13 11:50:20+01:00,-3600,2018-12-13 11:50:20+01:00,-3600,True,False,['README.md'],['c1d6a331a9a12087e680fcf6445795034f98a015'],1,1,2,1,,,
4523b78f10d7d61cbfeea95a6a7c7fa76c21760d,Add known issue to readme,hewilder,hwilder3@illinois.edu,GitHub,noreply@github.com,2018-12-13 09:06:54-05:00,18000,2018-12-13 09:06:54-05:00,18000,True,False,['README.md'],['91ed4938390b16e8bb51cf3dbb197cdac3bfa4f7'],0,4,4,1,,,
8925973a373d5b5f95fc018a14d913cfcf83edcb,"Explicit feature bug fixed, tests edited and added",hwilder3,hwilder3@illinois.edu,hwilder3,hwilder3@illinois.edu,2018-12-16 22:55:29-05:00,18000,2018-12-16 22:55:29-05:00,18000,True,False,"['gflm_tagger.py', 'parse_and_model.py', 'test_GFLM.py']",['4523b78f10d7d61cbfeea95a6a7c7fa76c21760d'],22,105,127,3,0.0,0.36666666666666664,0.8333333333333334
0063e5e0a5b5086994328dc625afb8d1c87aae19,Update default workflow (fm and ipynb),nfreundlich,norbert4@illinois.edu,nfreundlich,norbert4@illinois.edu,2019-01-29 14:32:45+01:00,-3600,2019-01-29 14:32:45+01:00,-3600,True,False,"['fm.py', 'tutorial.ipynb']",['8925973a373d5b5f95fc018a14d913cfcf83edcb'],12,11,23,2,1.0,1.0,0.0
