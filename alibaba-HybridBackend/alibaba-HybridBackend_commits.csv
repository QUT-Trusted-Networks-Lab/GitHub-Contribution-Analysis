Hash,Commit Message,Author Name,Author Email,Committor Name,Committor Email,Author Date,Author Timezone,Committor Date,Committor Timezone,in_main_branch,merge,modified_files,parents,deletions,insertions,lines,files,dmm_unit_size,dmm_unit_complexity,dmm_unit_interfacing
bc4d93b84b4cb04a52d23122f2678aa14f92008f,Initial commit,Alibaba OSS,opensource@alibaba-inc.com,GitHub,noreply@github.com,2021-12-01 14:51:25+08:00,-28800,2021-12-01 14:51:25+08:00,-28800,True,False,['LICENSE'],[],0,201,201,1,,,
5c2d003a89bcb42735ecc9ee156d4001d0097fac,[CI] Add project skeleton.,"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2021-12-01 17:37:07+08:00,-28800,2021-12-01 17:37:07+08:00,-28800,True,False,"['.clang-format', '.gitignore', '.pylintrc', 'NOTICE', '.helmignore', 'Chart.yaml', 'Dockerfile.tensorflow-1.14.0-py3', 'Dockerfile.tensorflow-1.15.5-py3', 'format', 'lint', 'pip.conf', 'run', 'sources.list', 'tfjob.yaml', 'upload', 'values.yaml', '__init__.py', '__init__.py', '__init__.py', 'setup.py']",['bc4d93b84b4cb04a52d23122f2678aa14f92008f'],0,876,876,20,1.0,1.0,1.0
66adb536c15b3400ef44a383b2723d8b767bfb26,"[IO] Add `ParquetDataset` for reading tabular data.

This patch introduces `ParquetDataset` based on
[Apache Arrow](https://arrow.apache.org/) to support efficient batch reading of
[Parquet](https://parquet.apache.org/) files.

**Example**:

```python
import hybridbackend.tensorflow as hb
ds = hb.data.ParquetDataset(filenames, batch_size=1024)
ds = ds.apply(hb.data.to_sparse())
ds = ds.prefetch()
batch = ds.make_one_shot_iterator().get_next()
...
```","Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2021-12-01 19:47:30+08:00,-28800,2021-12-01 19:47:30+08:00,-28800,True,False,"['.gitmodules', 'Makefile', '.gitignore', 'Makefile', 'build.sh', 'download.sh', 'src', 'thirdparty.list', 'Makefile', 'arrow.cc', 'arrow.h', 'pybind11.cc', 'Makefile', 'arrow.cc', 'arrow.h', 'parquet_batch_reader.cc', 'parquet_batch_reader.h', 'eigen.h', 'dataset.h', 'grendez_broadcast.cc', 'parquet_dataset_ops.cc', '__init__.py', '__init__.py', 'adapter.py', 'dataframe.py', 'parquet.py', 'parquet_dataset.py', 'parquet_dataset_v1.py', 'parquet_dataset_v2.py', 'pywrap.py', 'step_stat_hook.py', 'csv_dataset_benchmark.py', 'mock_data_generator.py', 'parquet_dataset_benchmark.py', 'parquet_dataset_ragged_test.py', 'parquet_dataset_string_test.py', 'parquet_dataset_test.py', 'tfio_parquet_dataset_benchmark.py', 'tfrecord_dataset_benchmark.py']",['5c2d003a89bcb42735ecc9ee156d4001d0097fac'],0,3823,3823,39,0.28761574074074076,0.7685185185185185,0.7320601851851852
d4ab633e357a147b9034f53bc409d622d970a696,[DOC] Add documentation and GitHub hooks.,"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2021-12-02 12:19:10+08:00,-28800,2021-12-02 12:19:10+08:00,-28800,True,False,"['00-enhancement.md', '10-bug.md', '20-documentation.md', '30-other.md', 'tensorflow1.14-py3.6-cibuild.yaml', 'tensorflow1.15-py3.6-cibuild.yaml', '.readthedocs.yaml', 'README.md', 'build.sh', 'download.sh', 'src', 'patch_build', 'architecture.md', 'conf.py', 'hybridbackend.md', 'images', 'index.md', 'requirements.txt', 'data_loading.md', 'tutorials.md', 'bridging_the_gap.png', 'hbarch.png', 'hbperf.png', 'recommenders.png', 'setup.py']",['66adb536c15b3400ef44a383b2723d8b767bfb26'],6,539,545,25,1.0,1.0,1.0
81335635a2cff53905dd0c9d79d8df85bf2198f9,"[IO] Add `hb.data.rebatch` for resizing batches from tabular data.

This patch introduces `hb.data.rebatch` for resizing batches from tabular data.

**Example**:
```python
import tensorflow as tf
import hybridbackend.tensorflow as hb

ds = hb.data.ParquetDataset(filename, micro_batch_size)
ds = ds.apply(hb.data.rebatch(batch_size))
```","Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2021-12-02 13:30:29+08:00,-28800,2021-12-02 13:30:29+08:00,-28800,True,False,"['data_loading.md', 'rebatch_dataset_ops.cc', '__init__.py', 'rebatch.py', 'rebatch_dataset.py', 'rebatch_dataset_v1.py', 'rebatch_dataset_v2.py', 'setup.py', 'parquet_dataset_benchmark.py', 'parquet_dataset_rebatch_test.py']",['d4ab633e357a147b9034f53bc409d622d970a696'],2,1252,1254,10,0.1701093560145808,0.6099635479951397,0.5722964763061968
a90aeda8448971e6ce1bd19e11e1cc381068eb14,[CI] Add build number in package publishing.,"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2021-12-02 16:03:30+08:00,-28800,2021-12-02 16:03:30+08:00,-28800,True,False,"['tensorflow1.14-py3.6-cibuild.yaml', 'tensorflow1.15-py3.6-cibuild.yaml']",['81335635a2cff53905dd0c9d79d8df85bf2198f9'],2,4,6,2,,,
9c58cbc65eb418fd96be6c1a3a4a5c4e67853970,"[IO] Support reading batches from parquet files on Aliyun OSS.

This patch supports environment variables:
- `S3_ENDPOINT`: Endpoint to S3/OSS service.
- `S3_ADDRESSING_STYLE`: For Aliyun OSS, this environment variable must be virtual.","Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2021-12-02 16:59:34+08:00,-28800,2021-12-02 16:59:34+08:00,-28800,True,False,"['build.sh', 's3_enhancements.patch', 'data_loading.md']",['a90aeda8448971e6ce1bd19e11e1cc381068eb14'],0,160,160,3,,,
9c6f764a030f74915079ddf104b47ab44bcd7095,[CI] Build packages on platform manylinux_2_24.,"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2021-12-04 21:50:18+08:00,-28800,2021-12-04 21:50:18+08:00,-28800,True,False,"['tensorflow1.14-py3.6-cibuild.yaml', 'tensorflow1.15-py3.6-cibuild.yaml', 'Makefile', 'README.md', 'auditwheel', 'Dockerfile.tensorflow-1.14.0-manylinux_2_24-py3', 'Dockerfile.tensorflow-1.15.5-manylinux_2_24-py3', 'repair_dist', 'run', 'requirements.txt', 'data_loading.md', '__init__.py', 'Makefile', 'grendez_broadcast.cc', '__init__.py', 'setup.py']",['9c58cbc65eb418fd96be6c1a3a4a5c4e67853970'],315,118,433,16,0.9724770642201835,0.0,0.0
62c3e4eb917cd42ae3fcd38c003eb062c47f3858,[CI] Separate release build and nightly build.,"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2021-12-04 23:20:19+08:00,-28800,2021-12-04 23:20:19+08:00,-28800,True,False,"['20-documentation.md', 'cpu-legacy-nightly.yaml', 'cpu-legacy.yaml', 'cpu-nightly.yaml', 'cpu.yaml', 'README.md']",['9c6f764a030f74915079ddf104b47ab44bcd7095'],34,130,164,6,,,
c0d64a9559e32852b46d5e6868bf9b6b11e34c98,[CI] Replace `git apply` with overwriting in patching `arrow`.,"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2021-12-05 00:31:18+08:00,-28800,2021-12-05 00:31:18+08:00,-28800,True,False,"['Makefile', 'build.sh', 's3fs.cc', 's3fs.h', 's3_enhancements.patch']",['62c3e4eb917cd42ae3fcd38c003eb062c47f3858'],126,2640,2766,5,0.4634296250768285,0.7234173325138291,0.787338660110633
95d0310c5dae623aa90dda2688c4ce46e95cad2f,[CI] Upgrade to v0.5.1.,"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2021-12-05 09:27:08+08:00,-28800,2021-12-05 09:27:08+08:00,-28800,True,False,"['cpu-cibuild.yaml', 'cpu-legacy-nightly.yaml', 'cpu-legacy.yaml', 'cpu-nightly.yaml', 'cpu.yaml', 'README.md', '__init__.py']",['c0d64a9559e32852b46d5e6868bf9b6b11e34c98'],7,48,55,7,,,
84dac3d11d32b173defead393da73633aae401c1,[CI] Fix arrow patching and upgrade to v0.5.2.,"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2021-12-10 12:38:15+08:00,-28800,2021-12-10 12:38:15+08:00,-28800,True,False,"['CONTRIBUTING.md', 'README.md', 'build.sh', '__init__.py', '__init__.py']",['95d0310c5dae623aa90dda2688c4ce46e95cad2f'],22,73,95,5,,,
736c47306e09d187ab2e252138ab11ec4958d32e,Fix interleave support in TensorFlow 1.14.,"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2021-12-18 12:48:40+08:00,-28800,2021-12-18 12:48:40+08:00,-28800,True,False,"['conf.py', 'parquet_dataset_v1.py', 'parquet_dataset_test.py']",['84dac3d11d32b173defead393da73633aae401c1'],11,59,70,3,0.5116279069767442,1.0,1.0
9629a6cfeee595c4032671979628bbae25e36ce2,[CI] Upgrade to v0.5.2fix1.,"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2021-12-20 13:19:19+08:00,-28800,2021-12-20 13:19:19+08:00,-28800,True,False,['__init__.py'],['736c47306e09d187ab2e252138ab11ec4958d32e'],1,1,2,1,,,
fec2c1e82a2be569ad4019556cae380d0c9eb349,[CI] Follow PEP-440 to rename versions.,"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2021-12-20 14:12:00+08:00,-28800,2021-12-20 14:12:00+08:00,-28800,True,False,"['cpu-legacy-nightly.yaml', 'cpu-nightly.yaml', '__init__.py']",['9629a6cfeee595c4032671979628bbae25e36ce2'],3,3,6,3,,,
8e256ac376fa003b6da555a05904c77e901cf53d,[CI] Support building on GPU.,"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2021-12-23 16:58:52+08:00,-28800,2021-12-23 16:58:52+08:00,-28800,True,False,"['cpu-cibuild.yaml', 'cpu-legacy-nightly.yaml', 'cpu-legacy.yaml', 'cpu-nightly.yaml', 'cpu.yaml', 'gpu-nightly.yaml', 'gpu.yaml', 'Makefile', 'auditwheel', 'Dockerfile.tensorflow-1.14.0-manylinux_2_24-py3', 'Dockerfile.tensorflow-1.15.5-manylinux_2_24-py3', 'Dockerfile.tensorflow-1.15.5-manylinux_2_27-py3-cu114', 'patch_manylinux_policy.py', 'repair_dist', 'run', 'tfjob.yaml', 'values.yaml', 'arrow.cc', 'pybind11.cc', 'arrow.cc', 'parquet_batch_reader.cc', 'parquet_batch_reader.h', 'parquet_dataset_ops.cc', 'rebatch_dataset_ops.cc', '__init__.py', 'dataframe.py', 'parquet.py', 'parquet_dataset_v1.py', 'parquet_dataset_v2.py', 'rebatch.py', 'rebatch_dataset_v1.py', 'rebatch_dataset_v2.py', '__init__.py', 'context.py', 'step_stat_hook.py', 'setup.py', 'mock_data_generator.py', 'parquet_dataset_ragged_test.py', 'parquet_dataset_string_test.py', 'tfrecord_dataset_benchmark.py']",['fec2c1e82a2be569ad4019556cae380d0c9eb349'],162,821,983,40,0.3758620689655172,0.4586206896551724,0.45517241379310347
1cee9414265ea2063209b4b24a70021f85fe23e4,"[CI] Refine context, benchmarks and tests.","Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2021-12-30 13:27:25+08:00,-28800,2021-12-30 13:27:25+08:00,-28800,True,False,"['__init__.py', 'dataframe.py', 'parquet_dataset_v2.py', 'context.py', 'random.py', 'step_stat_hook.py', '__init__.py', 'dataset_benchmark.py', 'dataset_mock.py', 'csv_dataset_benchmark.py', 'parquet_dataset_benchmark.py', 'parquet_dataset_ragged_test.py', 'parquet_dataset_rebatch_test.py', 'parquet_dataset_string_test.py', 'parquet_dataset_test.py', 'tfio_parquet_dataset_benchmark.py', 'tfrecord_dataset_benchmark.py']",['8e256ac376fa003b6da555a05904c77e901cf53d'],455,373,828,17,0.0,1.0,0.058823529411764705
31fb0705e77671faa06ee7741154207e6a3dcabb,[CI] Support building on MacOS x86 platform and refine documents.,"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2022-01-13 19:38:44+08:00,-28800,2022-01-13 19:38:44+08:00,-28800,True,False,"['ADOPTERS.md', 'CONTRIBUTING.md', 'Makefile', 'README.md', 'Makefile', 'build.sh', 'download.sh', 'conf.py', 'data_loading.md', 'programming_model.md', 'tutorials.md', 'Makefile', 'arrow.cc', 'env.cc', 'env.h', 'Makefile', 'parquet_batch_reader.cc', 'eigen.h', 'dataset.h', 'rebatch_dataset_ops.cc', 'options.py', 'random.py', 'scope.py', 'hbcommunity.png']",['1cee9414265ea2063209b4b24a70021f85fe23e4'],128,609,737,24,1.0,1.0,0.8947368421052632
b174d7fde5690f31ab045ca9229701197ab13ab3,[CI] Fix typo in documents.,"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2022-01-13 22:38:15+08:00,-28800,2022-01-13 22:38:15+08:00,-28800,True,False,"['README.md', 'tutorials.md', '__init__.py']",['31fb0705e77671faa06ee7741154207e6a3dcabb'],4,4,8,3,,,
9aabf9973fab049a643e0f984cafc75a6e97754b,[DOC] Refine README for building from source.,"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2022-01-14 11:11:30+08:00,-28800,2022-01-14 11:11:30+08:00,-28800,True,False,['README.md'],['b174d7fde5690f31ab045ca9229701197ab13ab3'],2,42,44,1,,,
550fbc888edac77a26a06f3a84b67962cab72501,[CI] Fix build error on macOS.,"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2022-01-15 08:36:40+08:00,-28800,2022-01-15 08:36:40+08:00,-28800,True,False,"['Makefile', 'README.md', 'build.sh', 'data_loading.md', 'arrow.cc', 'adapter.py', 'parquet_dataset_v1.py', 'parquet_dataset_v2.py', 'rebatch_dataset_v1.py', 'rebatch_dataset_v2.py']",['9aabf9973fab049a643e0f984cafc75a6e97754b'],20,26,46,10,1.0,1.0,1.0
2b433e82ea7eaa4298a6a25caf07660eb9bb6535,[DATA] Fix incompatibility with PS mode.,"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2022-01-19 15:46:28+08:00,-28800,2022-01-19 15:46:28+08:00,-28800,True,False,['context.py'],['550fbc888edac77a26a06f3a84b67962cab72501'],10,0,10,1,1.0,0.375,0.375
ad3e09214be7b23f506219b7f29f873e55d3e082,"[CI] Refactor CIBUILD to support more building artifacts.

Support building docker with nvtf 22.01 and DeepRec.","Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2022-02-22 10:50:42+08:00,-28800,2022-02-22 10:50:42+08:00,-28800,True,False,"['cpu-cibuild.yaml', 'cpu-legacy-nightly.yaml', 'cpu-legacy.yaml', 'cpu-nightly.yaml', 'cpu.yaml', 'gpu-nightly.yaml', 'gpu.yaml', 'Makefile', 'baseimagebuild', 'Dockerfile.developer-deeprec-py3.6-cu114-ubuntu18.04', 'Dockerfile.developer-nvtf1-py3.6-cu114-ubuntu18.04', 'Dockerfile.developer-nvtf1-py3.8-cu116-ubuntu20.04', 'Dockerfile.developer-tf1.14-py3.6-manylinux_2_24', 'Dockerfile.developer-tf1.15-py3.6-manylinux_2_24', 'Dockerfile.jinja2', 'imagebuild', 'repair_dist', 'run', 'tfjob.yaml', 'values.yaml']",['2b433e82ea7eaa4298a6a25caf07660eb9bb6535'],58,325,383,20,,,
2430578143faa8f79a633d1f3b7da5be255f89ec,[CI] Refactor cibuild and framework,"Yuan, Man",yuanman.ym@alibaba-inc.com,yuanman.ym,yuanman.ym@alibaba-inc.com,2022-02-27 18:24:15+08:00,-28800,2022-05-08 21:05:37+08:00,-28800,True,False,"['cpu-cibuild.yaml', 'cpu-legacy-nightly.yaml', 'cpu-legacy.yaml', 'cpu-nightly.yaml', 'cpu.yaml', 'gpu-cibuild-deeprec.yaml', 'gpu-cibuild.yaml', 'gpu-nightly.yaml', 'gpu.yaml', '.gitmodules', '.pycodestylerc', '.pylintrc', 'BUILD.md', 'CITATION.cff', 'Makefile', 'README.md', 'ROADMAP.md', '.gitignore', 'Makefile', 'build.sh', 'download.sh', 'src', 'thirdparty.list', '.gitignore', 'build.sh', 's3fs.cc', 's3fs.h', 'auditwheel', 'auditwheel_patch.py', 'bash.bashrc', 'build-developer-image', 'build-image', 'Dockerfile.developer-deeprec-py3.6-cu114-ubuntu18.04', 'Dockerfile.developer-nvtf1-py3.6-cu114-ubuntu18.04', 'Dockerfile.developer-nvtf1-py3.8-cu116-ubuntu20.04', 'Dockerfile.developer-tf1.14-py3.6-manylinux_2_24', 'Dockerfile.developer-tf1.15-py3.6-cu114-ubuntu18.04', 'Dockerfile.developer-tf1.15-py3.6-manylinux_2_24', 'format', 'hbash', 'lint', 'pip.conf', 'run', '.gitignore', 'build.sh', 'values.yaml', 'architecture.md', 'conf.py', 'data.md', 'hybridbackend.md', 'index.md', 'introduction.md', 'requirements.txt', 'programming_model.md', 'tutorials.md', '__init__.py', 'env.cc', 'env.h', 'arrow.h', 'parquet_batch_reader.h', 'parquet_dataset_ops.cc', 'rebatch_dataset_ops.cc', '__init__.py', '__init__.py', 'dataframe.py', 'dataset_benchmark.py', 'dataset_mock.py', 'dataset_ops.py', 'parquet.py', 'parquet_dataset.py', 'parquet_dataset_ragged_test.py', 'parquet_dataset_string_test.py', 'parquet_dataset_test.py', 'parquet_dataset_v1.py', 'parquet_dataset_v2.py', 'rebatch_dataset.py', 'rebatch_dataset_test.py', 'rebatch_dataset_v1.py', 'rebatch_dataset_v2.py', 'context.py', 'device.py', 'ops.py', 'options.py', 'function.py', 'server.py', 'step_stat_hook.py', 'test.py', 'architecture.png', 'bridging_the_gap.png', 'dingtalk.png', 'hbarch.png', 'hbperf.png', 'performance.png', 'recommenders.png', 'wide-and-deep.png', 'setup.py']",['ad3e09214be7b23f506219b7f29f873e55d3e082'],1627,2833,4460,96,0.5772357723577236,0.7317073170731707,0.6097560975609756
53fd96bd2e76f505c038af96fe59a3c6472106ba,[DIST] Support distributed training and evaluation,yuanman.ym,yuanman.ym@alibaba-inc.com,yuanman.ym,yuanman.ym@alibaba-inc.com,2022-04-28 21:06:59+08:00,-28800,2022-05-08 21:05:37+08:00,-28800,True,False,"['distributed.md', 'index.md', 'model.md', 'atomic.cu.h', 'cast.cu.cc', 'cast.h', 'device_functions.h', 'slice_sum.cu.cc', 'slice_sum.h', 'solver.h', 'stream.h', 'nccl.h', 'nccl_allgather.cc', 'nccl_allgatherv.cc', 'nccl_allreduce.cc', 'nccl_alltoall.cc', 'nccl_alltoallv.cc', 'nccl_alltoallw.cc', 'nccl_broadcast.cc', 'nccl_comm.cc', 'nccl_comm.h', 'nccl_create.cc', 'nccl_get_id.cc', 'nccl_group_alltoallv.cc', 'nccl_group_alltoallw.cc', 'nccl_reduce.cc', 'nccl_reduce_scatter.cc', 'floormod_shuffle.cc', 'floormod_shuffle.cu.cc', 'floormod_shuffle.h', 'floormod_shuffle_ops.cc', 'run.py', '__init__.py', '__init__.py', 'communicator.py', 'communicator_allgather_test.py', 'communicator_allgatherv_test.py', 'communicator_allreduce_benchmark.py', 'communicator_allreduce_grad_test.py', 'communicator_allreduce_test.py', 'communicator_alltoall_test.py', 'communicator_alltoallv_test.py', 'communicator_alltoallw_benchmark.py', 'communicator_alltoallw_test.py', 'communicator_broadcast_in_graph_test.py', 'communicator_broadcast_test.py', 'communicator_group_alltoallv_test.py', 'communicator_group_alltoallw_benchmark.py', 'communicator_group_alltoallw_test.py', 'communicator_pool.py', 'communicator_reduce_scatter_test.py', 'communicator_reduce_test.py', 'nccl.py', 'pubsub.py', '__init__.py', 'estimator.py', '__init__.py', 'floormod.py', 'floormod_partition_benchmark.py', 'floormod_shuffle_benchmark.py', 'floormod_shuffle_test.py', 'segment_ops.py', '__init__.py', 'simple_save.py', '__init__.py', 'evaluation.py', 'function.py', 'optimizer.py', 'optimizer_lib.py', 'optimizer_test.py', 'saver.py', 'server.py', 'wraps.py']",['2430578143faa8f79a633d1f3b7da5be255f89ec'],4,12445,12449,73,0.24544465596954038,0.6301332608104433,0.5182213761218385
add5675a8fe834024805e429c8ce07deeaa81792,[DIST] Support coordination of out-of-range,langshi.cls,langshi.cls@alibaba-inc.com,yuanman.ym,yuanman.ym@alibaba-inc.com,2022-04-28 16:53:21+08:00,-28800,2022-05-08 21:05:37+08:00,-28800,True,False,"['detect_end_dataset_ops.cc', 'dataset_ops.py', 'estimator.py', 'detect_end.py', 'detect_end_dataset.py', 'detect_end_dataset_v1.py', 'detect_end_dataset_v2.py', 'detect_end_test.py']",['53fd96bd2e76f505c038af96fe59a3c6472106ba'],12,601,613,8,0.45791245791245794,0.8080808080808081,0.7441077441077442
5355a0ec68909a494587fe00a63cc2c123f49e21,[DIST] Support sharded embedding layer,yuanman.ym,yuanman.ym@alibaba-inc.com,yuanman.ym,yuanman.ym@alibaba-inc.com,2022-04-28 17:20:10+08:00,-28800,2022-05-08 21:05:37+08:00,-28800,True,False,"['advanced.md', 'index.md', 'model.md', '__init__.py', '__init__.py', 'dense_features.py', 'dense_features_benchmark.py', 'dense_features_test.py', 'embedding_backend.py', 'embedding_backend_default.py', 'embedding_backend_paiev.py', 'embedding_backend_paiev_test.py', 'embedding_lookup.py', 'embedding_lookup_coalesced.py', 'feature_column.py', '__init__.py', '__init__.py', '__init__.py']",['add5675a8fe834024805e429c8ce07deeaa81792'],58,3112,3170,18,0.272984441301273,0.8293257897218294,0.6195190947666195
46e2bfd5fa7cb3ddd5697ea5287ccb717c2e8843,[DIST] Support global metrics,langshi.cls,langshi.cls@alibaba-inc.com,yuanman.ym,yuanman.ym@alibaba-inc.com,2022-04-28 17:20:38+08:00,-28800,2022-05-08 21:05:37+08:00,-28800,True,False,"['model.md', 'gauc.cc', '__init__.py', '__init__.py', 'accuracy.py', 'auc.py', 'gauc.py', 'mean.py']",['5355a0ec68909a494587fe00a63cc2c123f49e21'],0,885,885,8,0.04258943781942078,0.46678023850085176,0.07325383304940375
fd385ccf21f45fe77ac47a11e9edc529a4974be0,[DOC] Add simple ranking example,yuanman.ym,yuanman.ym@alibaba-inc.com,yuanman.ym,yuanman.ym@alibaba-inc.com,2022-05-08 21:07:43+08:00,-28800,2022-05-08 21:07:43+08:00,-28800,True,False,"['layers.py', 'optimization.py', 'train_criteo_terabyte_v1.py', 'train_criteo_terabyte_v2.py', 'tutorial.ipynb']",['46e2bfd5fa7cb3ddd5697ea5287ccb717c2e8843'],0,810,810,5,0.18813905930470348,0.6625766871165644,0.5214723926380368
3c0e2a21553612f83b42beff9139d2fff044210c,[CI] Upgrade to 0.6.0a2,yuanman.ym,yuanman.ym@alibaba-inc.com,yuanman.ym,yuanman.ym@alibaba-inc.com,2022-05-08 21:51:12+08:00,-28800,2022-05-08 21:51:12+08:00,-28800,True,False,['__init__.py'],['fd385ccf21f45fe77ac47a11e9edc529a4974be0'],1,1,2,1,,,
fc68a9d2bab48b03b9de47d6ea5511ad194d7b99,[CI] Add cibuild reports,yuanman.ym,yuanman.ym@alibaba-inc.com,yuanman.ym,yuanman.ym@alibaba-inc.com,2022-05-11 00:03:40+08:00,-28800,2022-05-13 10:04:30+08:00,-28800,True,False,"['cibuild.yaml', 'cpu-cibuild.yaml', 'cpu-nightly.yaml', 'gpu-cibuild-deeprec.yaml', 'gpu-cibuild.yaml', 'gpu-nightly.yaml', 'README.md', 'Dockerfile.developer-deeprec-py3.6-cu114-ubuntu18.04', 'Dockerfile.developer-tf1.14-py3.6-manylinux_2_24', 'Dockerfile.developer-tf1.15-py3.6-cu114-ubuntu18.04', 'Dockerfile.developer-tf1.15-py3.6-manylinux_2_24', 'parquet_dataset_ragged_test.py', 'parquet_dataset_string_test.py', 'parquet_dataset_test.py', 'rebatch_dataset_seq_test.py', 'rebatch_dataset_test.py', 'communicator_allgather_test.py', 'communicator_allgatherv_test.py', 'communicator_allreduce_grad_test.py', 'communicator_allreduce_test.py', 'communicator_alltoall_test.py', 'communicator_alltoallv_test.py', 'communicator_alltoallw_test.py', 'communicator_broadcast_in_graph_test.py', 'communicator_broadcast_test.py', 'communicator_group_alltoallv_test.py', 'communicator_group_alltoallw_test.py', 'communicator_reduce_scatter_test.py', 'communicator_reduce_test.py', 'dense_features_test.py', 'embedding_backend_paiev_test.py', 'floormod_shuffle_test.py', 'detect_end_test.py', 'optimizer_test.py', 'test.py']",['3c0e2a21553612f83b42beff9139d2fff044210c'],276,495,771,35,0.826530612244898,1.0,1.0
b888ed5b3d49bb6b61cc31271427d18a66c23f80,[CI] Upgrades CUDA to 11.6 and refines citation,yuanman.ym,yuanman.ym@alibaba-inc.com,yuanman.ym,yuanman.ym@alibaba-inc.com,2022-05-18 18:59:43+08:00,-28800,2022-05-18 20:05:05+08:00,-28800,True,False,"['cibuild.yaml', 'gpu-nightly.yaml', 'gpu.yaml', 'CITATION.cff', 'README.md', 'build-developer-image', 'build-image', 'Dockerfile.developer-deeprec-py3.6-cu114-ubuntu18.04', 'Dockerfile.developer-tf1.15-py3.6-cu116-ubuntu18.04', 'run', 'values.yaml', 'function.py']",['fc68a9d2bab48b03b9de47d6ea5511ad194d7b99'],58,166,224,12,0.0,1.0,0.0
73ef0777050d3f27fafc1ff9b21c66b954b4095d,[DATA] Improve schema parsing in ParquetDataset,"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2022-05-30 12:05:51+08:00,-28800,2022-05-30 12:05:51+08:00,-28800,True,False,"['data.md', 'dataframe.py', 'parquet.py', 'parquet_dataset_ragged_test.py', 'parquet_dataset_reshape_test.py', 'parquet_dataset_string_test.py', 'parquet_dataset_test.py', 'parquet_dataset_v1.py', 'parquet_dataset_v2.py', 'rebatch.py', 'rebatch_dataset_test.py', 'rebatch_dataset_v1.py', 'rebatch_dataset_v2.py']",['b888ed5b3d49bb6b61cc31271427d18a66c23f80'],127,305,432,13,0.18,0.5,0.0
e505f6ab5823be3d47656904687d61b296a8b47c,[CI] Add parallel building flag for arrow,Hailin,hailinfufu@outlook.com,GitHub,noreply@github.com,2022-05-30 13:05:48+08:00,-28800,2022-05-30 13:05:48+08:00,-28800,True,False,['build.sh'],['73ef0777050d3f27fafc1ff9b21c66b954b4095d'],0,2,2,1,,,
ccbb9e6dc3932522fb90a7ac3b2631a037bb668a,[DATA] Fix fixed-length list support,"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2022-06-08 15:25:01+08:00,-28800,2022-06-08 15:25:01+08:00,-28800,True,False,"['arrow.cc', 'arrow.h', 'parquet_batch_reader.cc', 'parquet_batch_reader.h', 'parquet_dataset_ops.cc', 'rebatch_dataset_ops.cc', 'dataframe.py', 'parquet_dataset_reshape_test.py', 'parquet_dataset_v1.py', 'parquet_dataset_v2.py', 'parquet_validate.py', 'rebatch_dataset_test.py']",['e505f6ab5823be3d47656904687d61b296a8b47c'],82,312,394,12,0.011299435028248588,0.0,0.4011299435028249
b17196cba2b7d8ae10e33ced219bfc72839f9986,"[DIST] Support `keep_checkpoint_max`

Co-authored-by: langshi.cls <langshi.cls@alibaba-inc.com>","Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2022-06-08 16:00:29+08:00,-28800,2022-06-08 16:00:29+08:00,-28800,True,False,"['feature_column.py', '__init__.py', 'evaluation.py', 'function.py', 'server.py']",['ccbb9e6dc3932522fb90a7ac3b2631a037bb668a'],24,108,132,5,0.6428571428571429,0.9,0.5285714285714286
498f74038fbc3be4ab1de6a8c3c2ef99f39af5e3,[CI] Refine container image building and buildinfo,"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2022-06-08 18:49:26+08:00,-28800,2022-06-08 18:49:26+08:00,-28800,True,False,"['Makefile', 'build-developer-image', 'build-image', 'Dockerfile.developer-deeprec-py3.6-cu114-ubuntu18.04', 'Dockerfile.developer-tf1.14-py3.6-manylinux_2_24', 'Dockerfile.developer-tf1.15-py3.6-cu116-ubuntu18.04', 'Dockerfile.developer-tf1.15-py3.6-manylinux_2_24', 'Dockerfile.jinja2', 'pybind11.cc', 'Makefile']",['b17196cba2b7d8ae10e33ced219bfc72839f9986'],557,761,1318,10,1.0,1.0,1.0
35abc02e6a7731bf7e76a7a64f0b70558c46ca21,[CI] Sort imports and refine wheel building,"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2022-06-15 19:10:20+08:00,-28800,2022-06-15 19:10:20+08:00,-28800,True,False,"['.gitignore', '.isort.cfg', 'BUILD.md', 'Makefile', 'format', 'lint', '.isort.cfg', 'layers.py', 'train_criteo_terabyte_v1.py', 'train_criteo_terabyte_v2.py', 'pybind11.cc', 'run.py', '__init__.py', '__init__.py', 'dataframe.py', 'dataset_benchmark.py', 'dataset_mock.py', 'parquet.py', 'parquet_dataset.py', 'parquet_dataset_ragged_test.py', 'parquet_dataset_reshape_test.py', 'parquet_dataset_string_test.py', 'parquet_dataset_test.py', 'parquet_validate.py', 'rebatch_dataset.py', 'rebatch_dataset_seq_test.py', 'rebatch_dataset_test.py', '__init__.py', 'communicator_allgather_test.py', 'communicator_allgatherv_test.py', 'communicator_allreduce_benchmark.py', 'communicator_allreduce_grad_test.py', 'communicator_allreduce_test.py', 'communicator_alltoall_test.py', 'communicator_alltoallv_test.py', 'communicator_alltoallw_benchmark.py', 'communicator_alltoallw_test.py', 'communicator_broadcast_in_graph_test.py', 'communicator_broadcast_test.py', 'communicator_group_alltoallv_test.py', 'communicator_group_alltoallw_benchmark.py', 'communicator_group_alltoallw_test.py', 'communicator_pool.py', 'communicator_reduce_scatter_test.py', 'communicator_reduce_test.py', 'nccl.py', '__init__.py', 'estimator.py', '__init__.py', 'dense_features.py', 'dense_features_benchmark.py', 'dense_features_test.py', 'embedding_backend_default.py', 'embedding_backend_paiev.py', 'embedding_backend_paiev_test.py', 'context.py', '__init__.py', '__init__.py', 'floormod_partition_benchmark.py', 'floormod_shuffle_benchmark.py', 'floormod_shuffle_test.py', '__init__.py', 'detect_end.py', 'detect_end_dataset.py', 'detect_end_test.py', 'evaluation.py', 'function.py', 'optimizer_test.py', 'saver.py', 'server.py', 'step_stat_hook.py', 'test.py', 'setup.py']",['498f74038fbc3be4ab1de6a8c3c2ef99f39af5e3'],146,295,441,73,1.0,1.0,0.0
1557edb61876b20ea6584415f4c1dd0121f45a61,[CI] Improve modularity and compatibility,"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2022-06-15 23:38:12+08:00,-28800,2022-06-15 23:38:12+08:00,-28800,True,False,"['Makefile', 'model.md', '__init__.py', 'Makefile', '__init__.py', 'arrow.cc', 'arrow.h', 'atomic.cu.h', 'env.cc', 'env.h', 'logging.cc', 'logging.h', 'macros.h', 'murmur3.cu.h', 'profiler.cc', 'profiler.h', 'pybind11.cc', 'test.py', 'solver.h', 'run.py', 'Makefile', '__init__.py', '__init__.py', 'device_functions.h', 'eigen.h', 'host_functions.h', 'pywrap.py', '__init__.py', 'benchmark.py', 'benchmark_mock.py', 'arrow.cc', 'arrow.h', 'dataset.h', 'iterators.py', '__init__.py', 'batch_reader.cc', 'batch_reader.h', 'dataset.cc', 'dataset.py', 'dataset_v1.py', 'dataset_v2.py', 'parquet_lib.py', 'dataset_ragged_test.py', 'dataset_reshape_test.py', 'dataset_string_test.py', 'dataset_test.py', 'validate.py', '__init__.py', 'dataset.cc', 'dataset.py', 'dataset_v1.py', 'dataset_v2.py', 'dataset_seq_test.py', 'dataset_test.py', '__init__.py', 'dataset.cc', 'dataset.py', 'dataset_v1.py', 'dataset_v2.py', 'hooks.py', 'detect_end_test.py', '__init__.py', 'allreduce_benchmark.py', 'alltoallw_benchmark.py', 'alltoallw_n_benchmark.py', '__init__.py', 'functors.h', 'impl.cu.cc', '__init__.py', 'benchmark.py', 'functors.h', 'impl.cc', 'impl.cu.cc', 'ops.cc', 'ops.py', 'floormod_shuffle_test.py', 'functors.h', 'impl.cu.cc', 'communicator.py', 'communicator_lib.py', '__init__.py', 'allgather.cc', 'allgatherv.cc', 'allreduce.cc', 'alltoall.cc', 'alltoallv.cc', 'alltoallv_n.cc', 'alltoallw.cc', 'alltoallw_n.cc', 'broadcast.cc', 'comm.cc', 'comm.h', 'comm.py', 'create.cc', 'get_id.cc', 'reduce.cc', 'reduce_scatter.cc', 'types.h', 'pubsub.py', 'allgather_test.py', 'allgatherv_test.py', 'allreduce_grad_test.py', 'allreduce_test.py', 'alltoall_test.py', 'alltoallv_n_test.py', 'alltoallv_test.py', 'alltoallw_n_test.py', 'alltoallw_test.py', 'broadcast_in_graph_test.py', 'broadcast_test.py', 'reduce_scatter_test.py', 'reduce_test.py', '__init__.py', 'backend.py', 'buffer_lib.py', 'default.py', 'lookup.py', '__init__.py', 'backend.py', 'paiev_test.py', 'scope.py', 'estimator.py', '__init__.py', 'benchmark.py', 'dense_features.py', 'embedding_lookup.py', 'embedding_lookup_coalesced.py', 'feature_column.py', 'dense_features_test.py', 'context.py', 'options.py', 'auc.py', 'gauc.cc', 'gauc.py', 'mean.py', '__init__.py', 'floormod_shuffle_benchmark.py', 'math_lib.py', '__init__.py', 'eval.py', 'function.py', 'optimizer.py', 'optimizer_lib.py', 'perf.py', 'saver.py', 'server.py', 'optimizer_test.py', 'variables.py']",['35abc02e6a7731bf7e76a7a64f0b70558c46ca21'],1981,2342,4323,148,0.0,0.08888888888888889,0.5611111111111111
521fd4b6dd4dc0e336efb21bb7030fb59776bd4e,[EMB] Refine embedding lookup and saved model export,"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2022-06-16 15:09:07+08:00,-28800,2022-06-16 15:09:07+08:00,-28800,True,False,"['__init__.py', 'lookup.py', 'math_lib.py', 'estimator.py', '__init__.py', 'simple_save.py']",['1557edb61876b20ea6584415f4c1dd0121f45a61'],53,115,168,6,0.0,0.8793103448275862,0.1724137931034483
a9450042052964091a23e333df2648aa125dc652,[TRAIN] Support hb.train.Policy for easier training customization,"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2022-06-16 15:22:57+08:00,-28800,2022-06-16 15:22:57+08:00,-28800,True,False,"['estimator.py', '__init__.py', 'policy.py', 'server.py']",['521fd4b6dd4dc0e336efb21bb7030fb59776bd4e'],0,256,256,4,0.07692307692307693,0.24102564102564103,0.3487179487179487
bb863db05ba8d2d66331dae08234a5db8b24d6a5,[DOC] Refine README,"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2022-07-27 14:42:50+08:00,-28800,2022-07-27 14:42:50+08:00,-28800,True,False,['README.md'],['a9450042052964091a23e333df2648aa125dc652'],31,34,65,1,,,
5ddcae49d061379b32d7f0aade8aec19ffafe4a1,[Data] Fix nested list support,"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2022-08-03 19:42:15+08:00,-28800,2022-08-03 19:42:15+08:00,-28800,True,False,"['arrow.cc', 'dataframe.py', 'parquet_dataset_ragged_nested_test.py']",['bb863db05ba8d2d66331dae08234a5db8b24d6a5'],0,98,98,3,1.0,1.0,1.0
0c96182defccb617fd8739da3c31c89fbdb40d64,[CI] Refactors tools and workflows,"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2022-08-03 20:52:23+08:00,-28800,2022-08-03 20:52:23+08:00,-28800,True,False,"['.helmignore', 'Chart.yaml', 'tfjob.yaml', 'upload', 'values.yaml', 'cibuild.yaml', 'cpu-legacy-nightly.yaml', 'cpu-legacy.yaml', 'cpu-nightly.yaml', 'cpu.yaml', 'gpu-nightly.yaml', 'gpu.yaml', '.gitignore', 'BUILD.md', 'CONTRIBUTING.md', 'Makefile', 'Chart.yaml', 'configure', 'advanced.md', 'distributed.md', 'introduction.md', 'requirements.txt', '.gitignore', 'build.sh', 's3fs.cc', 's3fs.h', 'Dockerfile.developer-deeprec-py3.6-cu114-ubuntu18.04', 'Dockerfile.developer-paitf1.12-py3.6-cu101-ubuntu18.04', 'Dockerfile.developer-tf1.14-py3.6-manylinux_2_24', 'Dockerfile.developer-tf1.15-py3.6-cu100-ubuntu18.04', 'Dockerfile.developer-tf1.15-py3.6-cu114-ubuntu18.04', 'Dockerfile.developer-tf1.15-py3.6-manylinux_2_24', 'Dockerfile.developer-tf1.15-py3.8-cu114-ubuntu20.04', 'Dockerfile.jinja2', 'auditwheel_patch.py', 'bash.bashrc', 'hbash', 'sources.list', 'run', '.gitignore', 'build.sh', '__init__.py', 'env.cc', 'env.h', 'run.py', '__init__.py', 'arrow.cc', 'arrow.h', 'cast.cu.cc', 'cast.h', 'dataset.h', 'device_functions.h', 'fusion_helper.cu.cc', 'fusion_helper.cu.h', 'slice_sum.cu.cc', 'slice_sum.h', 'benchmark.py', 'benchmark_mock.py', 'dataset_v1.py', 'dataset_v2.py', 'parquet_batch_reader.cc', 'parquet_dataset.cc', 'schema.py', 'rebatch_dataset.cc', 'parquet_dataset_ragged_test.py', 'parquet_dataset_reshape_test.py', 'parquet_dataset_string_test.py', 'parquet_dataset_test.py', 'rebatch_dataset_seq_test.py', 'rebatch_dataset_test.py', 'dataset.cc', 'hooks.py', 'detect_end_test.py', '__init__.py', 'nccl_allgather.cc', 'nccl_allgatherv.cc', 'nccl_allreduce.cc', 'nccl_alltoall.cc', 'nccl_alltoallv.cc', 'nccl_alltoallv_n.cc', 'nccl_alltoallw.cc', 'nccl_alltoallw_n.cc', 'nccl_broadcast.cc', 'nccl_comm.cc', 'nccl_create.cc', 'nccl_get_id.cc', 'nccl_reduce.cc', 'nccl_reduce_scatter.cc', 'allgather_test.py', 'allgatherv_test.py', 'allreduce_grad_test.py', 'allreduce_test.py', 'alltoall_test.py', 'alltoallv_n_test.py', 'alltoallv_test.py', 'alltoallw_n_test.py', 'alltoallw_test.py', 'broadcast_in_graph_test.py', 'broadcast_test.py', 'reduce_scatter_test.py', 'reduce_test.py', '__init__.py', 'backend.py', 'benchmark.py', 'default.py', 'lookup.py', 'math_lib.py', '__init__.py', 'estimator.py', '__init__.py', 'benchmark.py', 'dense_features.py', 'feature_column.py', 'dense_features_test.py', 'ops.py', 'version.py', '__init__.py', '__init__.py', 'benchmark.py', 'floormod_shuffle_functors.cc', 'floormod_shuffle_functors.cu.cc', 'floormod_shuffle_ops.cc', 'functors.h', 'ops.py', 'floormod_shuffle_test.py', '__init__.py', '__init__.py', 'ev.py', 'ev_test.py', '__init__.py', 'eval.py', 'function.py', 'optimizer.py', 'optimizer_lib.py', 'saved_model.py', 'optimizer_test.py', 'build-container', 'build-developer-container', 'distbuild', 'distcheck', 'format', 'lint', 'repair']",['5ddcae49d061379b32d7f0aade8aec19ffafe4a1'],670,1749,2419,143,0.345679012345679,0.35185185185185186,0.691358024691358
911f8ca18bb9bb2305f9160b01cd2aee4000ceab,[CI] Fixes GitHub workflows,"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2022-08-04 07:24:46+08:00,-28800,2022-08-04 07:24:46+08:00,-28800,True,False,"['Makefile', 'Dockerfile.jinja2', 'train_criteo_terabyte_v2.py', 'hooks.py', '__init__.py', 'communicator_pool.py', 'comm.py', 'pubsub.py', 'buffer_lib.py', 'lookup.py', 'auc.py', 'mean.py', 'optimizer.py', 'optimizer_lib.py']",['0c96182defccb617fd8739da3c31c89fbdb40d64'],339,150,489,14,0.8791946308724832,0.5906040268456376,0.4228187919463087
7f5ddb382cb268e8193dc19282d5be3571841196,"[DATA] Supports `hb.data.Iterator`

This patch introduces `hb.data.Iterator`, which optimizes cross-device
transfers of inputs.

Example:

```
iterator = tf.data.make_one_shot_iterator(ds)
  iterator = hb.data.Iterator(iterator)
  features = iterator.get_next()
  hooks.append(hb.data.Iterator.Hook())
```","Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2022-08-04 11:00:26+08:00,-28800,2022-08-04 11:00:26+08:00,-28800,True,False,"['train_criteo_terabyte.py', 'tutorial.ipynb', '__init__.py', '__init__.py', 'buffer.cc', 'ops.py', 'scope.py', 'pywrap.py']",['911f8ca18bb9bb2305f9160b01cd2aee4000ceab'],183,781,964,8,0.26382978723404255,0.4319148936170213,0.3617021276595745
fe8ba0a91499faa7f27092bdd0415f80e5025782,[DIST] Support hybrid parallelism using embedding_lookup_* API,"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2022-09-28 22:15:51+08:00,-28800,2022-09-28 22:15:51+08:00,-28800,True,False,"['Makefile', 'README.md', 'advanced.md', 'data.md', 'distributed.md', 'high_level_api.md', 'index.md', 'quickstart.ipynb', '__init__.py', 'prep.py', 'spec.json', 'train_dcn.py', 'train_dlrm.py', 'train_mp.py', 'train_mp_estimator.py', 'data.py', 'model.py', 'optimization.py', 'prep_1_backbone.py', 'prep_2_bahavior.py', 'prep_3_merge.py', 'prep_4_sort.py', 'spec.json', 'stats.py', 'to_tfrecord.py', 'train_dcn.py', 'train_dcn_dp.py', 'train_dcn_mp.py', 'train_dcn_tfr.py', 'Dockerfile.developer-deeprec-py3.6-cu114-ubuntu18.04', 'Dockerfile.developer-paitf1.12-py3.6-cu101-ubuntu18.04', 'Dockerfile.developer-tf1.14-py3.6-manylinux_2_24', 'Dockerfile.developer-tf1.15-py3.6-cu100-ubuntu18.04', 'Dockerfile.developer-tf1.15-py3.6-cu114-ubuntu18.04', 'Dockerfile.developer-tf1.15-py3.6-manylinux_2_24', 'Dockerfile.developer-tf1.15-py3.8-cu114-ubuntu20.04', 'Dockerfile.jinja2', 'run', '.isort.cfg', 'layers.py', '__init__.py', 'env.cc', 'env.h', 'pybind11.cc', 'test.py', 'run.py', 'Makefile', '__init__.py', '__init__.py', 'dataframe.py', 'dataset_v1.py', 'dataset_v2.py', 'parquet_batch_reader.cc', 'buffer.cc', 'ops.py', 'parquet_dataset_ragged_nested_test.py', 'parquet_dataset_ragged_test.py', 'parquet_dataset_reshape_test.py', 'parquet_dataset_string_test.py', 'rebatch_dataset_test.py', 'hooks.py', 'communicator_pool.py', 'embedding.py', 'gradient.py', '__init__.py', 'backend.py', 'benchmark.py', 'buffer_lib.py', 'lookup.py', 'estimator.py', 'benchmark.py', 'feature_column.py', 'auc.py', 'mean.py', 'floormod_shuffle_functors.cu.cc', 'floormod_shuffle_ops.cc', '__init__.py', 'ev.py', 'ev_test.py', '__init__.py', 'config.py', 'embedding.py', 'eval.py', 'function.py', 'optimizer.py', 'optimizer_lib.py', 'saver.py', 'server.py', 'session.py', 'variables.py', 'setup.py', 'build-container', 'build-developer-container', 'distbuild']",['7f5ddb382cb268e8193dc19282d5be3571841196'],1184,5394,6578,94,0.27788554801163917,0.55819592628516,0.6629485935984482
49989f3074346c70928ef8e9d61a3c68f55189dc,[DIST] Support data sync and evaluation using embedding_lookup_* API,"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2022-10-21 11:48:52+08:00,-28800,2022-10-21 11:48:52+08:00,-28800,True,False,"['distributed.md', 'high_level_api.md', 'images', 'architecture.png', 'dingtalk.png', 'performance.png', 'wide-and-deep.png', 'index.md', 'quickstart.ipynb', 'train.py', 'train_dcn.py', 'train_dlrm.py', 'train_estimator.py', 'train_keras.py', 'train_mp.py', 'train_mp_estimator.py', 'data.py', 'train.py', 'train_dcn.py', 'train_dcn_dp.py', 'train_dcn_mp.py', 'train_dcn_tfr.py', 'train_estimator.py', 'train_keras.py', '__init__.py', '__init__.py', '__init__.py', '__init__.py', 'dataset.py', 'dataset_v1.py', 'dataset_v2.py', 'detect_end_dataset.cc', 'iterators.py', 'benchmark.py', 'validate.py', 'ops.py', 'detect_end_dataset_test.py', 'parquet_dataset_ragged_nested_test.py', 'parquet_dataset_ragged_test.py', 'parquet_dataset_reshape_test.py', 'parquet_dataset_string_test.py', 'parquet_dataset_test.py', 'rebatch_dataset_seq_test.py', 'rebatch_dataset_test.py', 'hooks.py', 'allreduce_benchmark.py', 'alltoallw_benchmark.py', 'alltoallw_n_benchmark.py', 'communicator_pool.py', 'gradient.py', 'pubsub.py', 'allgather_test.py', 'allgatherv_test.py', 'allreduce_grad_test.py', 'allreduce_test.py', 'broadcast_in_graph_test.py', 'broadcast_test.py', 'reduce_scatter_test.py', 'reduce_test.py', '__init__.py', 'benchmark.py', 'estimator.py', '__init__.py', 'backend.py', 'benchmark.py', 'default.py', 'dense_features.py', 'feature_column.py', 'lookup.py', 'math_lib.py', 'dense_features_test.py', 'context.py', 'ops.py', 'rewriting.py', '__init__.py', 'model.py', 'benchmark.py', 'floormod_shuffle_test.py', '__init__.py', 'ev.py', 'ev_test.py', '__init__.py', 'embedding.py', 'evaluation.py', 'function.py', 'hooks.py', 'optimizer.py', 'perf.py', 'saved_model.py', 'saver.py', 'server.py', 'session.py', 'optimizer_test.py', 'variables.py']",['fe8ba0a91499faa7f27092bdd0415f80e5025782'],3003,3529,6532,94,0.5482546201232033,1.0,0.08213552361396304
51a507d0eee9d61263cb9945f602b97a21a53382,[CI] Refactors directory layout (#80),"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2022-10-21 13:16:38+08:00,-28800,2022-10-21 13:16:38+08:00,-28800,True,False,"['cpu-legacy-nightly.yaml', 'cpu-legacy.yaml', 'cpu-nightly.yaml', 'cpu.yaml', 'gpu-nightly.yaml', 'gpu.yaml', '.gitignore', 'BUILD.md', 'CONTRIBUTING.md', 'Makefile', 'README.md', '.gitignore', 'build.sh', 's3fs.cc', 's3fs.h', 'Dockerfile.developer-deeprec-py3.6-cu114-ubuntu18.04', 'Dockerfile.developer-paitf1.12-py3.6-cu101-ubuntu18.04', 'Dockerfile.developer-tf1.14-py3.6-manylinux_2_24', 'Dockerfile.developer-tf1.15-py3.6-cu100-ubuntu18.04', 'Dockerfile.developer-tf1.15-py3.6-cu114-ubuntu18.04', 'Dockerfile.developer-tf1.15-py3.6-manylinux_2_24', 'Dockerfile.developer-tf1.15-py3.8-cu114-ubuntu20.04', 'Dockerfile.jinja2', 'auditwheel_patch.py', 'bash.bashrc', 'hbash', 'sources.list', 'run', '.gitignore', 'build.sh', 'build-container', 'build-developer-container', 'distbuild', 'distcheck', 'format', 'lint']",['49989f3074346c70928ef8e9d61a3c68f55189dc'],50,59,109,36,,,
0d9ce31c4839ab5dc86f8bb888eea82bf972bb7e,"[DIST] Support loading weights and Functional API in Keras. (#83)

This patch closes #81 #82 
1) Support loading weights by name with options of skipping mismatched variables.
2) Support using functional API to create `hb.keras.Model`.
3) Multiple other supports such as using `tf.data.Dataset` as arguments in `model.fit`.",Langshi Chen,langshi.cls@alibaba-inc.com,GitHub,noreply@github.com,2022-11-02 13:23:10+08:00,-28800,2022-11-02 13:23:10+08:00,-28800,True,False,"['train_keras.py', 'train_keras.py', 'model.py', 'saver.py']",['51a507d0eee9d61263cb9945f602b97a21a53382'],91,305,396,4,0.4576271186440678,0.3785310734463277,0.6892655367231638
a832b4e1da3f60ddaf3d7f358cf09b370568ff34,[DIST] Multiple enhancement in `hb.keras`.  (#91),Langshi Chen,langshi.cls@alibaba-inc.com,GitHub,noreply@github.com,2022-11-28 10:47:40+08:00,-28800,2022-11-28 10:47:40+08:00,-28800,True,False,"['train_keras.py', 'model.py']",['0d9ce31c4839ab5dc86f8bb888eea82bf972bb7e'],21,66,87,2,0.02702702702702703,0.05405405405405406,0.2972972972972973
c895fb978b1efdea46b2f958d24b78f4943f8647,[CI] Upgrades third-party libraries,"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2023-02-24 17:18:07+08:00,-28800,2023-02-24 17:18:07+08:00,-28800,True,False,"['values.yaml', 'cibuild.yaml', 'cpu-legacy-nightly.yaml', 'cpu-legacy.yaml', 'cpu-nightly.yaml', 'cpu.yaml', 'gpu-nightly.yaml', 'gpu.yaml', '.gitignore', 'BUILD.md', 'CONTRIBUTING.md', 'Makefile', 'README.md', 'build.sh', 's3fs.cc', 's3fs.h', 'docker-build', 'docker-build-dev', 'Dockerfile.developer-deeprec-py3.6-cu114-ubuntu18.04', 'Dockerfile.developer-deeprec2208-py3.6-cu114-ubuntu18.04', 'Dockerfile.developer-tf1.14-py3.6-manylinux_2_24', 'Dockerfile.developer-tf1.15-py3.6-cu100-ubuntu18.04', 'Dockerfile.developer-tf1.15-py3.6-cu114-ubuntu18.04', 'Dockerfile.developer-tf1.15-py3.6-manylinux_2_24', 'Dockerfile.developer-tf1.15-py3.8-cu116-ubuntu20.04', 'Dockerfile.developer-tf1.15-py3.8-cu118-ubuntu20.04', 'Dockerfile.developer-tf1.15-py3.8-ubuntu20.04', 'Dockerfile.jinja2', 'auditwheel_patch.py', 'format', 'install', 'lint', 'repair', 'run', 'build.sh']",['a832b4e1da3f60ddaf3d7f358cf09b370568ff34'],661,1526,2187,35,0.05583756345177665,0.07106598984771574,1.0
37250831db15d593584a749f2a177bcc65ff6db7,[DATA] Support skipping corrupted data,"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2023-02-24 17:43:49+08:00,-28800,2023-02-24 17:43:49+08:00,-28800,True,False,"['arrow.cc', 'arrow.h', 'dataframe.py', 'dataset_v1.py', 'dataset_v2.py', 'parquet_batch_reader.cc', 'parquet_dataset.cc']",['c895fb978b1efdea46b2f958d24b78f4943f8647'],160,258,418,7,0.0,0.5483870967741935,0.21505376344086022
d8198c4e47e8c0641fa18d8f48a82b07781b0900,[DIST] Support sync training of imbalanced data across devices,"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2023-02-24 21:00:10+08:00,-28800,2023-02-24 21:00:10+08:00,-28800,True,False,"['cibuild.yaml', '__init__.py', 'sync_replicas_optimizer.py']",['37250831db15d593584a749f2a177bcc65ff6db7'],3,553,556,3,0.19533527696793002,0.6530612244897959,0.2536443148688047
085749a2f171db2e25ff252f14a46028dc37058f,[DATA] Introduce new tabular dataset API with row-wise shuffling,"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2023-02-27 21:56:05+08:00,-28800,2023-02-27 21:56:05+08:00,-28800,True,False,"['arrow.cc', 'env.cc', 'env.h', 'data_benchmark_csv.py', 'data_benchmark_parquet.py', 'data_benchmark_tfrecord.py', 'arrow.cc', 'dataset.h', '__init__.py', 'dataframe.py', 'benchmark.py', 'benchmark_mock.py', 'dataset_v1.py', 'dataset_v2.py', 'rebatch_dataset.cc', '__init__.py', 'dataset.py', 'dataset_v1.py', 'dataset_v2.py', 'queue.h', 'rectify_dataset.cc', 'rectify_queue.cc', '__init__.py', 'core.py', 'dataset.py', 'dataset_v1.py', 'dataset_v2.py', 'config.py', 'context.py', 'ops.py', 'rewriting.py', 'view.py', 'build-container', 'build-developer-container', 'format', 'lint']",['d8198c4e47e8c0641fa18d8f48a82b07781b0900'],502,2880,3382,36,0.15795454545454546,0.49318181818181817,0.18920454545454546
7fcffe6a9877ea2e4f882c27debc8f74f3d219fa,[DOC] Refines documentation for new tabular dataset API,"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2023-03-06 21:01:22+08:00,-28800,2023-03-06 21:01:22+08:00,-28800,True,False,"['cibuild.yaml', 'README.md', 'Dockerfile.developer-paitf1.12-py3.6-cu101-ubuntu18.04', 'Dockerfile.developer-tf1.15-py3.8-cu114-ubuntu20.04', 'data.md', 'distributed.md', 'high_level_api.md', 'dingtalk.png', 'quickstart.ipynb', 'train.py', 'train_estimator.py', 'train_keras.py', 'data.py', 'din_layers.py', 'model.py', 'spec.json', 'train.py', 'train_estimator.py', 'train_keras.py', 'train_keras_din.py', 'train_ps.py', '__init__.py', 'device_functions.h', 'fusion_helper.cu.cc', 'slice_sum.cu.cc', 'stream.cc', 'stream.h']",['085749a2f171db2e25ff252f14a46028dc37058f'],765,1610,2375,27,0.39118825100133514,0.46862483311081443,0.4672897196261682
9b3c00de673db5e43f106ec9ee2eeb46bda91eb4,[DATA] Introduce new RebatchDataset to replace rebatch and rectify,"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2023-03-06 22:41:56+08:00,-28800,2023-03-06 22:41:56+08:00,-28800,True,False,"['README.md', '__init__.py', 'run.py', 'data_benchmark_parquet.py', 'slice_sum.cu.cc', '__init__.py', 'buffer.h', 'dataset.py', 'dataset_v1.py', 'dataset_v2.py', 'rebatch_buffer.cc', 'rebatch_dataset.cc', 'rebatch_dataset_v2.cc', '__init__.py', 'dataset.py', 'dataset_v1.py', 'dataset_v2.py', 'queue.h', 'rectify_queue.cc', 'core.py', 'dataset.py', 'dataset_v1.py', 'dataset_v2.py', 'parquet_dataset_ragged_nested_test.py', 'parquet_dataset_ragged_test.py', 'parquet_dataset_reshape_test.py', 'parquet_dataset_string_test.py', 'parquet_dataset_test.py', 'rebatch_dataset_test.py']",['7fcffe6a9877ea2e4f882c27debc8f74f3d219fa'],2086,947,3033,29,0.9698375870069605,0.7424593967517401,0.5881670533642691
d70c104613c705ceb00c6d0dec9ffdb4e2052a23,[DIST] Support Non-intrusive embedding APIs,"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2023-03-07 08:32:47+08:00,-28800,2023-03-07 08:32:47+08:00,-28800,True,False,"['Makefile', 'train.py', 'train.py', '__init__.py', 'collective_benchmark.py', 'embedding_benchmark_tier1.py', 'partition_by_dual_modulo_benchmark.py', 'partition_by_modulo_benchmark.py', 'slice_sum.cu.cc', 'iterators.py', '__init__.py', 'allreduce_benchmark.py', 'alltoallw_benchmark.py', 'alltoallw_n_benchmark.py', 'collective.h', 'collective.py', 'communicator.py', 'communicator_pool.py', 'embedding.py', 'collective.h', 'comm.h', 'comm.py', 'nccl_allgather.cc', 'nccl_allgatherv.cc', 'nccl_allreduce.cc', 'nccl_alltoall.cc', 'nccl_alltoallv.cc', 'nccl_alltoallv_n.cc', 'nccl_alltoallw.cc', 'nccl_alltoallw_n.cc', 'nccl_broadcast.cc', 'nccl_collective.cc', 'nccl_comm.cc', 'nccl_create.cc', 'nccl_get_id.cc', 'nccl_reduce.cc', 'nccl_reduce_scatter.cc', 'types.h', 'ops.py', '__init__.py', 'modulo_functors.h', 'ops.py', 'partition_by_modulo_functors.cc', 'partition_by_modulo_functors.cu.cc', 'partition_by_modulo_ops.cc', 'pubsub.py', 'rpc.py', 'allgather_test.py', 'allgatherv_test.py', 'allreduce_grad_test.py', 'allreduce_test.py', 'alltoall_test.py', 'alltoallv_n_test.py', 'alltoallv_test.py', 'alltoallw_n_test.py', 'alltoallw_test.py', 'broadcast_in_graph_test.py', 'broadcast_test.py', 'partition_test.py', 'reduce_scatter_test.py', 'reduce_test.py', 'estimator.py', '__init__.py', 'backend.py', 'benchmark.py', 'default.py', 'dense_features.py', 'feature_column.py', 'lookup.py', 'math_lib.py', 'dense_features_test.py', 'helper.cc', 'helper.h', 'linearization.cc', 'linearization.h', 'packing.cc', 'packing.h', 'relocation.cc', 'relocation.h', 'replacing.cc', 'replacing.h', 'rewriting.cc', 'rewriting.h', 'op_optimization.cc', 'op_optimization.h', 'optimize_collective.cc', 'optimize_partition_by_modulo.cc', '__init__.py', 'model.py', 'auc.py', 'mean.py', '__init__.py', '__init__.py', 'ev.py', 'ev_test.py', '__init__.py', 'config.py', 'embedding.py', 'evaluation.py', 'gradient.py', 'optimizer.py', 'saver.py', 'server.py', 'session.py', 'variables.py', 'setup.py']",['9b3c00de673db5e43f106ec9ee2eeb46bda91eb4'],10318,6800,17118,106,0.6641561109209175,0.25059910989387196,0.4519000342348511
d8d1514efef431191c27a2febb177f8e1b92ef54,[DATA] Refines data transfer prefetching and synchronization,"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2023-03-07 10:23:22+08:00,-28800,2023-03-07 10:23:22+08:00,-28800,True,False,"['hbash', '__init__.py', 'iterators.py', 'buffer.cc', 'iterator.py', 'prefetch.cc', '__init__.py', 'dataset.py', 'dataset_v1.py', 'dataset_v2.py', 'hook.py', 'sync_replicas_dataset.cc', 'sync_replicas_dataset_test.py', 'optimize_prefetch.cc', 'gpu_device_factory.cc']",['d70c104613c705ceb00c6d0dec9ffdb4e2052a23'],487,1223,1710,15,0.3538135593220339,0.6885593220338984,0.3326271186440678
bf5432d44dfc29387235391e99b087bf356aa29d,[DIST] Refactor directories of embedding sharding,"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2023-03-07 15:44:12+08:00,-28800,2023-03-07 15:44:12+08:00,-28800,True,False,"['bash.bashrc', '__init__.py', '__init__.py', 'deeprecev.py', 'sharding.py', 'deeprecev_test.py', 'variables.py', '__init__.py', '__init__.py', 'optimizer.py', 'sync_replicas_optimizer.py', 'variables.py']",['d8d1514efef431191c27a2febb177f8e1b92ef54'],750,695,1445,12,,,
57ebcf6a728bb616d16d0ea030bb9fd6cc1bdb2b,"[DIST] Support pipeline-based semi-synchronous training. (#114)

1. Use `data_batch_count` within `hb.scope()` to support multiple micro batches in sem-sync training.
2. Use the function annotation `hb.pipeline.compute_pipeline` to mark the function that computes a loss from inputs.",Langshi Chen,langshi.cls@alibaba-inc.com,GitHub,noreply@github.com,2023-03-07 19:52:09+08:00,-28800,2023-03-07 19:52:09+08:00,-28800,True,False,"['train_semi_sync.py', 'train_semi_sync.py', '__init__.py', '__init__.py', 'benchmark.py', 'pipeline_lib.py']",['bf5432d44dfc29387235391e99b087bf356aa29d'],0,878,878,6,0.35018050541516244,0.6696750902527075,0.8176895306859205
eec8e175918b6cb52b18bf247a42d395d4f5e483,"[DIST] Support standalone evaluation and prediction in `hb.Estimator`.  (#115)

Support the usage of estimator's evaluate and predict methods.",Langshi Chen,langshi.cls@alibaba-inc.com,GitHub,noreply@github.com,2023-03-08 10:04:47+08:00,-28800,2023-03-08 10:04:47+08:00,-28800,True,False,"['train_estimator.py', 'train_estimator.py', 'estimator.py']",['57ebcf6a728bb616d16d0ea030bb9fd6cc1bdb2b'],46,153,199,3,0.06896551724137931,0.6091954022988506,0.39080459770114945
d6a7cb2d0e69fbe37ce6e7917ff2c26cccee9c2b,[CI] Fix GitHub workflow files,"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2023-03-09 00:57:55+08:00,-28800,2023-03-09 00:57:55+08:00,-28800,True,False,"['cpu-legacy-nightly.yaml', 'cpu-legacy.yaml', 'cpu-nightly.yaml', 'cpu.yaml', 'gpu-nightly.yaml', 'gpu.yaml']",['eec8e175918b6cb52b18bf247a42d395d4f5e483'],117,42,159,6,,,
3a4f69b877b5a6ae9099b639fc7f4398df0c9069,"[DIST] Fix: Shared embedding shape rewriting. (#123)

1. patching shared embedding get_shape method by using TensorShape to be compatible with init_from_checkpoint.
2. patching the `get_shape` method of embeddings created by `tf.contrib.feature_column` API in distributed training. (#122)",Langshi Chen,langshi.cls@alibaba-inc.com,GitHub,noreply@github.com,2023-03-29 14:42:49+08:00,-28800,2023-03-29 14:42:49+08:00,-28800,True,False,"['train_keras.py', 'sharding.py']",['d6a7cb2d0e69fbe37ce6e7917ff2c26cccee9c2b'],22,86,108,2,0.0,0.6666666666666666,0.2222222222222222
b177707e2f487c4c9c2157b0aebc3f201142842e,"[DIST] Support a standalone evaluation in `hb.keras`. (#124，#118)

1. support a standalone usage of `evaluate` method in `hb.keras`.",Langshi Chen,langshi.cls@alibaba-inc.com,GitHub,noreply@github.com,2023-03-29 14:59:19+08:00,-28800,2023-03-29 14:59:19+08:00,-28800,True,False,"['train_keras.py', 'train_keras.py', 'model.py']",['3a4f69b877b5a6ae9099b639fc7f4398df0c9069'],39,73,112,3,0.0,0.9032258064516129,0.5806451612903226
e170f8121f81a8067b1de05bad29dfffa695428c,"[DIST] Refine naming of deeprecev variables in unsharded cases. (#126)

1. Remove additional partition related naming of deeprecev in non-sharded cases.",Langshi Chen,langshi.cls@alibaba-inc.com,GitHub,noreply@github.com,2023-04-06 15:59:37+08:00,-28800,2023-04-06 15:59:37+08:00,-28800,True,False,"['deeprecev.py', 'variables.py']",['b177707e2f487c4c9c2157b0aebc3f201142842e'],4,5,9,2,0.0,0.0,0.0
bf47fc96c604e9195becea19b2eadc83cd2f9be5,"[DIST] Use variable_scope with partitioner for sharded deeprecev. (#127)

1. Make EV variables of deeprec to use variable_scope + partitioner for sharding.",Langshi Chen,langshi.cls@alibaba-inc.com,GitHub,noreply@github.com,2023-04-07 18:39:36+08:00,-28800,2023-04-07 18:39:36+08:00,-28800,True,False,"['train.py', 'train_semi_sync.py', 'train.py', 'train_estimator.py', 'train_keras_din.py', 'train_semi_sync.py', 'deeprecev.py', 'optimizer.py', 'saver.py']",['e170f8121f81a8067b1de05bad29dfffa695428c'],86,58,144,9,0.17391304347826086,0.8695652173913043,1.0
a2c2df05e57766992795f9619b7977d8a8d023af,[CI] Upgrade DeepRec (#119),"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2023-04-09 13:12:13+08:00,-28800,2023-04-09 13:12:13+08:00,-28800,True,False,"['cibuild.yaml', 'Makefile', 'README.md', 'build.sh', 'Dockerfile.developer-deeprec2212-py3.6-cu114-ubuntu18.04', 'Dockerfile.developer-tf1.15-py3.8-cu118-ubuntu20.04', '__init__.py', 'context.py']",['bf47fc96c604e9195becea19b2eadc83cd2f9be5'],21,52,73,8,0.0,0.0,0.0
cc925c0bb5c8138487fd7f033387116648fbe3a8,[DATA] Support ORC format and data deduplication (#128),"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2023-04-10 11:23:36+08:00,-28800,2023-04-10 11:23:36+08:00,-28800,True,False,"['data.md', 'arrow.cc', 'arrow.h', 'pybind11.cc', 'data_benchmark_deduplication.py', 'embedding_benchmark_tier1.py', 'arrow.cc', 'arrow.h', '__init__.py', 'dataframe.py', '__init__.py', 'dataset.py', 'dataset.py', 'dataset_v1.py', 'dataset_v2.py', 'parquet_batch_reader.cc', 'schema.py', 'dataset.cc', 'dataset.py', 'dataset_v1.py', 'dataset_v2.py', 'orc.cc', 'orc.h', 'parquet.cc', 'parquet.h', 'table.cc', 'table.h', 'table.py', 'parquet_dataset_deduplicate_test.py', 'parquet_dataset_ragged_nested_test.py', 'parquet_dataset_test.py', 'validate.py']",['a2c2df05e57766992795f9619b7977d8a8d023af'],1175,2381,3556,32,0.30902348578491967,0.688504326328801,0.34857849196538937
a67ed006d250c71eb739fcee5565e729756768e1,[DATA] Support transfer optimization (#129),"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2023-04-10 11:38:26+08:00,-28800,2023-04-10 11:38:26+08:00,-28800,True,False,"['transfer_benchmark.py', 'fusion.cc', 'fusion.h', 'pruning.cc', 'pruning.h']",['cc925c0bb5c8138487fd7f033387116648fbe3a8'],0,1441,1441,5,0.12903225806451613,0.23118279569892472,0.6086021505376344
23b5efab804ac2d70c29838c4aad8d440fedc939,"[DIST] Implement a hierarchical embedding lookup. (#130)

1. Implement a hierarchical embedding lookup to mitigate the communication overhead across cluster nodes.
2. Implement a `partition_by_dual_modulo` op, which is utilized in the hierarchical embedding lookup.
3. Implement auto-packing of `floormod_shuffle` op and auto-packing of `partition_by_dual_modulo` op.
    
Embedding lookup benchmark (using 8days Taobao dataset) results on a 2x8xA100 testbed (intra-node communication via nvswitch and inter-node communication via  32Gbps Ethernet.)
- bs=5120,  hierarchical embedding lookup improves throughput by 2.78x
- bs=10240, hierarchical embedding lookup improves throughput by 5.16x",Langshi Chen,langshi.cls@alibaba-inc.com,GitHub,noreply@github.com,2023-04-10 14:09:32+08:00,-28800,2023-04-10 14:09:32+08:00,-28800,True,False,"['sharding.py', 'optimize_floormod_shuffle.cc', 'optimize_partition_by_dual_modulo.cc', '__init__.py', 'benchmark.py', 'functors.h', 'ops.py', 'partition_by_dual_modulo_functors.cc', 'partition_by_dual_modulo_functors.cu.cc', 'partition_by_dual_modulo_ops.cc', '__init__.py']",['a67ed006d250c71eb739fcee5565e729756768e1'],5,1506,1511,11,0.19754768392370572,0.7111716621253406,0.17983651226158037
1d042a5bd4e983ee6a295bca6143de27bb9ca6fa,[EMB] Add experimental support for embedding service acceleration (#131),"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2023-04-10 20:27:34+08:00,-28800,2023-04-10 20:27:34+08:00,-28800,True,False,"['data.md', 'dual_modulo_functors.h', 'ops.py', 'partition_by_dual_modulo_functors.cc', 'partition_by_dual_modulo_functors.cu.cc', 'partition_by_dual_modulo_ops.cc', 'lookup_functors.cu.cc', 'lookup_functors.h', 'lookup_ops.cc', 'service.py', 'sharding.py', 'optimize_lookup.cc', 'optimize_memory.cc', 'optimize_transfer.cc', '__init__.py', 'benchmark.py', 'ops.py', 'functors.h', 'prefetched_transfer.cc', 'transfer.cc', 'transfer_functors.cu.cc', '__init__.py']",['23b5efab804ac2d70c29838c4aad8d440fedc939'],328,1877,2205,22,0.20353982300884957,0.6788874841972187,0.3691529709228824
f140da44a6fadd438d677a3a29d130655ea08ec7,[CI] Upgrade to 1.0.0 (#132),"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2023-04-12 09:28:31+08:00,-28800,2023-04-12 09:28:31+08:00,-28800,True,False,"['Dockerfile.developer-tf1.14-py3.6-manylinux_2_24', 'Dockerfile.developer-tf1.15-py3.8-cu116-ubuntu20.04', 'Dockerfile.developer-tf1.15-py3.8-cu118-ubuntu20.04', 'Dockerfile.developer-tf1.15-py3.8-ubuntu20.04', 'lint', 'din_layers.py', '__init__.py', 'collective_benchmark.py', 'transfer_benchmark.py', 'dataset.py', 'dataset.py', 'dataset.py', 'view.py', 'optimize_transfer.cc', 'model.py', 'pyproject.toml']",['1d042a5bd4e983ee6a295bca6143de27bb9ca6fa'],551,38,589,16,1.0,0.0,1.0
acaa0fca08e52643cd245c5d6a7aa5fa44986f76,"[DIST] Using empty data at the end of SyncReplicasDataset. (#133)

1. set `data_sync_drop_remainder=False` by defaults.
2. Use empty data when any of the workers reaches the end of training data in SyncReplicasDataset. (close #121)",Langshi Chen,langshi.cls@alibaba-inc.com,GitHub,noreply@github.com,2023-04-12 16:12:50+08:00,-28800,2023-04-12 16:12:50+08:00,-28800,True,False,"['__init__.py', 'iterators.py', 'dataset_v1.py', 'dataset_v2.py', 'sync_replicas_dataset.cc', 'utils.py', 'sync_replicas_dataset_test.py', 'ops.py']",['f140da44a6fadd438d677a3a29d130655ea08ec7'],27,164,191,8,0.41379310344827586,0.8045977011494253,0.06896551724137931
9c4bfe0ef49d508b7f95fa3f99a054619a2a334c,[DIST] Refines NCCL logging messages for debugging (#134),"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2023-04-13 14:17:23+08:00,-28800,2023-04-13 14:17:23+08:00,-28800,True,False,"['nccl_allgather.cc', 'nccl_allgatherv.cc', 'nccl_allreduce.cc', 'nccl_alltoall.cc', 'nccl_alltoallv.cc', 'nccl_broadcast.cc']",['acaa0fca08e52643cd245c5d6a7aa5fa44986f76'],60,156,216,6,0.0,0.0,0.28125
08baaa5ef7d27509f32a698fd55d55f5be988297,"[DATA] Refine data deduplication and add example. (#135)

1. Refine to fix cornercases in data deduplication.
2. Add a script to prepare deduplication data files.
3. Test data deduplication on Dcnv2 model with taobao dataset.

End-to-end performance on a single A100 GPU with one day of Taobao dataset and a batch size of 64000 obtains an improvement of training throughput around 1.3x.",Langshi Chen,langshi.cls@alibaba-inc.com,GitHub,noreply@github.com,2023-04-14 13:53:59+08:00,-28800,2023-04-14 13:53:59+08:00,-28800,True,False,"['deduplicate.py', 'train.py', 'dataframe.py']",['9c4bfe0ef49d508b7f95fa3f99a054619a2a334c'],2,197,199,3,0.0,0.2028985507246377,0.7536231884057971
53a4b72672ac84a34229ab5d24ec563cb85447b6,[CI] Refines logging and cibuild (#136),"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2023-04-16 14:33:54+08:00,-28800,2023-04-16 14:33:54+08:00,-28800,True,False,"['cibuild.yaml', 'Dockerfile.developer-deeprec2212-py3.6-cu114-ubuntu18.04', 'Dockerfile.developer-tf1-py3.9-cu118-ubuntu20.04', 'Dockerfile.developer-tf1.15-py3.6-cu100-ubuntu18.04', 'Dockerfile.developer-tf1.15-py3.6-manylinux_2_24', 'Dockerfile.developer-tf1.15-py3.8-cu118-ubuntu20.04', 'lint', 'arrow.cc', 'collective.h', 'nccl_allgather.cc', 'nccl_allgatherv.cc', 'nccl_allreduce.cc', 'nccl_alltoall.cc', 'nccl_alltoallv.cc', 'nccl_broadcast.cc', 'nccl_create.cc']",['08baaa5ef7d27509f32a698fd55d55f5be988297'],263,273,536,16,0.23943661971830985,0.647887323943662,0.39436619718309857
1a78bf7defe485c4ae44f0130f785a982ea37a1d,"[DIST] Rewrite NanTensorHook for SyncReplicasDataset. (#137)

Rewrite NanTensorHook to be compatible with the returned empty tensor from SyncReplicasDataset.",Langshi Chen,langshi.cls@alibaba-inc.com,GitHub,noreply@github.com,2023-04-17 11:07:11+08:00,-28800,2023-04-17 11:07:11+08:00,-28800,True,False,['iterators.py'],['53a4b72672ac84a34229ab5d24ec563cb85447b6'],3,48,51,1,0.0,1.0,0.8571428571428571
ad3fc6225d609b67498a0b438089a194409d9ba1,[CI] Add more build information (#139),"Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2023-04-17 18:00:54+08:00,-28800,2023-04-17 18:00:54+08:00,-28800,True,False,"['Makefile', 'pybind11.cc']",['1a78bf7defe485c4ae44f0130f785a982ea37a1d'],0,5,5,2,1.0,1.0,1.0
d65f685811b79e8d535728249a352f41172acd09,"[CI] Upgrade DeepRec docker to 2302 (#141)

Signed-off-by: yuanman.ym <yuanman.ym@alibaba-inc.com>","Yuan, Man",yuanman.ym@alibaba-inc.com,GitHub,noreply@github.com,2023-04-24 12:06:27+08:00,-28800,2023-04-24 12:06:27+08:00,-28800,True,False,"['values.yaml', 'cibuild.yaml', 'gpu-nightly.yaml', 'gpu.yaml', 'BUILD.md', 'Makefile', 'README.md', 'build.sh', 'docker-build', 'docker-build-dev', 'Dockerfile.developer-deeprec-py3.6-cu114-ubuntu18.04', 'Dockerfile.developer-deeprec-py3.9-cu118-ubuntu20.04', 'Dockerfile.developer-tf1.15-py3.6-cu100-ubuntu18.04', 'Dockerfile.developer-tf1.15-py3.6-manylinux_2_24', 'Dockerfile.developer-tf1.15-py3.8-cu121-ubuntu20.04', 'run', '.gitignore', 'build.sh', 'deeprecev_test.py', 'prefetched_transfer.cc']",['ad3fc6225d609b67498a0b438089a194409d9ba1'],190,169,359,20,1.0,0.0,1.0
0545159ad3dbc029a8fb97d2bba2d23dcc161bec,"[DIST] Set data_sync_drop_remainder as true by default. (#143)

1. set data_sync_drop_remainder to true by default.

Signed-off-by: langshi.cls <langshi.cls@alibaba-inc.com>",Langshi Chen,langshi.cls@alibaba-inc.com,GitHub,noreply@github.com,2023-04-24 16:18:51+08:00,-28800,2023-04-24 16:18:51+08:00,-28800,True,False,"['train.py', 'train.py', '__init__.py', 'sync_replicas_dataset_test.py', 'estimator.py', 'model.py']",['d65f685811b79e8d535728249a352f41172acd09'],22,30,52,6,0.375,1.0,1.0
02a714b43be591ef980911df21fa38c8b167f596,"[DATA] Implement zero-copied string dtype and accelerate shuffle. (#149)

    1. Implement a zero-copied approach to read string data from Arrow to TF.
    2. Accelerate the shuffle operation of string type in ParquetDataset.
    
    preliminary benchmarking results
    - col=300, `batch_size`=1000
    - `Intel(R) Xeon(R) Platinum 8369B CPU @ 2.90GHz` with 128 logical cores.
    
    | Dataset            | list type | shuffling | throughput (samples/s) | speedup over TFRecord |
    | ---                | ---       | ---       | ---                    | ---                   |
    | TFRecord           | N         | N         | 1404.23                | 1.0                   |
    | HbParquet          | N         | N         | 41137.53               | 29.3                  |
    | HbParquet-ZeroCopy | N         | N         | 51335.40               | 36.56                 |
    | TFRecord           | N         | Y         | 1343.10                | 1.0                   |
    | HbParquet          | N         | Y         | 6629.60                | 4.9                   |
    | HbParquet-ZeroCopy | N         | Y         | 10941.25               | 8.1                   |
    | TFRecord           | Y         | N         | 1352.05                | 1.0                   |
    | HbParquet          | Y         | N         | 2307.33                | 1.71                  |
    | HbParquet-ZeroCopy | Y         | N         | 2869.98                | 2.12                  |
    | TFRecord           | Y         | Y         | 1367.96                | 1.0                   |
    | HbParquet          | Y         | Y         | 1080.03                | 0.79                  |
    | HbParquet-ZeroCopy | Y         | Y         | 1454.02                | 1.06                  |

Signed-off-by: langshi.cls <langshi.cls@alibaba-inc.com>",Langshi Chen,langshi.cls@alibaba-inc.com,GitHub,noreply@github.com,2023-05-29 11:49:01+08:00,-28800,2023-05-29 11:49:01+08:00,-28800,True,False,"['Dockerfile.developer-tf1.15-py3.6-cu100-ubuntu18.04', 'Dockerfile.developer-tf1.15-py3.8-cu121-ubuntu20.04', 'data_benchmark_parquet.py', 'data_benchmark_tfrecord.py', 'arrow.cc', 'arrow.h', 'buffer.h', 'rebatch_buffer.cc', 'rebatch_dataset_v2.cc', 'parquet_dataset_string_test.py']",['0545159ad3dbc029a8fb97d2bba2d23dcc161bec'],167,639,806,10,0.08860759493670886,0.028481012658227847,0.3639240506329114
4486ba138515a1dbdb6f7d542d7ad23a27476524,"[DOC] Add user docs for data deduplication and so forth. (#150)

    1. data deduplication.
    2 the usage of `hb.embedding_scope`
    3. DataSyncReplicas
    4. `hb.keras` API.

Signed-off-by: langshi.cls <langshi.cls@alibaba-inc.com>",Langshi Chen,langshi.cls@alibaba-inc.com,GitHub,noreply@github.com,2023-05-29 12:46:16+08:00,-28800,2023-05-29 12:46:16+08:00,-28800,True,False,"['data.md', 'distributed.md', 'high_level_api.md']",['02a714b43be591ef980911df21fa38c8b167f596'],21,314,335,3,,,
